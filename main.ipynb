{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Supervised Learning a. Classification \n",
    "    • Project: Credit Risk Assessment \n",
    "        ○ Skills: Binary classification, model evaluation, handling imbalanced data\n",
    "        ○ Tools: Scikit-learn, XGBoost, LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "# Settings the warnings to be ignored \n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "import pandas as pd\n",
    "\n",
    "%pip install sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pip install imblearn\n",
    "# Import the necessary libraries\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Handling missing values using an imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "%pip install statsmodels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature Name\t               |         Description                                |\n",
    "|------------------------------|----------------------------------------------------|\n",
    "|person_age\t                   |         Age                                     \n",
    "|person_income\t               |         Annual Income\n",
    "|person_home_ownership         |         Home ownership\n",
    "|person_emp_length\t           |         Employment length (in years)\n",
    "|loan_intent\t               |         Loan intent\n",
    "|loan_amnt\t                   |         Loan amount\n",
    "|loan_int_rate\t               |         Interest rate\n",
    "|loan_status\t               |         Loan status (0 is non default 1 is default)\n",
    "|loan_percent_income\t       |         Percent income\n",
    "|cb_person_default_on_file\t   |         Historical default\n",
    "|cb_preson_cred_hist_length\t   |         Credit history length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>59000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>123.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>35000</td>\n",
       "      <td>16.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9600</td>\n",
       "      <td>OWN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>9600</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>5500</td>\n",
       "      <td>12.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>65500</td>\n",
       "      <td>RENT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>35000</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>54400</td>\n",
       "      <td>RENT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>35000</td>\n",
       "      <td>14.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.55</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          22          59000                  RENT              123.0   \n",
       "1          21           9600                   OWN                5.0   \n",
       "2          25           9600              MORTGAGE                1.0   \n",
       "3          23          65500                  RENT                4.0   \n",
       "4          24          54400                  RENT                8.0   \n",
       "\n",
       "  loan_intent  loan_amnt  loan_int_rate  loan_status  loan_percent_income  \\\n",
       "0    PERSONAL      35000          16.02            1                 0.59   \n",
       "1   EDUCATION       1000          11.14            0                 0.10   \n",
       "2     MEDICAL       5500          12.87            1                 0.57   \n",
       "3     MEDICAL      35000          15.23            1                 0.53   \n",
       "4     MEDICAL      35000          14.27            1                 0.55   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "0                         Y                           3  \n",
       "1                         N                           2  \n",
       "2                         N                           3  \n",
       "3                         N                           2  \n",
       "4                         Y                           4  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"credit_risk_dataset.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32581.000000</td>\n",
       "      <td>3.258100e+04</td>\n",
       "      <td>31686.000000</td>\n",
       "      <td>32581.000000</td>\n",
       "      <td>29465.000000</td>\n",
       "      <td>32581.000000</td>\n",
       "      <td>32581.000000</td>\n",
       "      <td>32581.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.734600</td>\n",
       "      <td>6.607485e+04</td>\n",
       "      <td>4.789686</td>\n",
       "      <td>9589.371106</td>\n",
       "      <td>11.011695</td>\n",
       "      <td>0.218164</td>\n",
       "      <td>0.170203</td>\n",
       "      <td>5.804211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.348078</td>\n",
       "      <td>6.198312e+04</td>\n",
       "      <td>4.142630</td>\n",
       "      <td>6322.086646</td>\n",
       "      <td>3.240459</td>\n",
       "      <td>0.413006</td>\n",
       "      <td>0.106782</td>\n",
       "      <td>4.055001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.850000e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.500000e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>10.990000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>7.920000e+04</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>12200.000000</td>\n",
       "      <td>13.470000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>6.000000e+06</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>23.220000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person_age  person_income  person_emp_length     loan_amnt  \\\n",
       "count  32581.000000   3.258100e+04       31686.000000  32581.000000   \n",
       "mean      27.734600   6.607485e+04           4.789686   9589.371106   \n",
       "std        6.348078   6.198312e+04           4.142630   6322.086646   \n",
       "min       20.000000   4.000000e+03           0.000000    500.000000   \n",
       "25%       23.000000   3.850000e+04           2.000000   5000.000000   \n",
       "50%       26.000000   5.500000e+04           4.000000   8000.000000   \n",
       "75%       30.000000   7.920000e+04           7.000000  12200.000000   \n",
       "max      144.000000   6.000000e+06         123.000000  35000.000000   \n",
       "\n",
       "       loan_int_rate   loan_status  loan_percent_income  \\\n",
       "count   29465.000000  32581.000000         32581.000000   \n",
       "mean       11.011695      0.218164             0.170203   \n",
       "std         3.240459      0.413006             0.106782   \n",
       "min         5.420000      0.000000             0.000000   \n",
       "25%         7.900000      0.000000             0.090000   \n",
       "50%        10.990000      0.000000             0.150000   \n",
       "75%        13.470000      0.000000             0.230000   \n",
       "max        23.220000      1.000000             0.830000   \n",
       "\n",
       "       cb_person_cred_hist_length  \n",
       "count                32581.000000  \n",
       "mean                     5.804211  \n",
       "std                      4.055001  \n",
       "min                      2.000000  \n",
       "25%                      3.000000  \n",
       "50%                      4.000000  \n",
       "75%                      8.000000  \n",
       "max                     30.000000  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_age                       0\n",
       "person_income                    0\n",
       "person_home_ownership            0\n",
       "person_emp_length              895\n",
       "loan_intent                      0\n",
       "loan_amnt                        0\n",
       "loan_int_rate                 3116\n",
       "loan_status                      0\n",
       "loan_percent_income              0\n",
       "cb_person_default_on_file        0\n",
       "cb_person_cred_hist_length       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values using an imputer\n",
    "imputer = SimpleImputer(strategy='mean')  # You can choose 'mean', 'median', or 'most_frequent'\n",
    "\n",
    "# Apply imputer only on 'person_emp_length' and 'loan_int_rate' columns\n",
    "df[['person_emp_length', 'loan_int_rate']] = pd.DataFrame(\n",
    "    imputer.fit_transform(df[['person_emp_length', 'loan_int_rate']]), \n",
    "    columns=['person_emp_length', 'loan_int_rate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_age                    0\n",
       "person_income                 0\n",
       "person_home_ownership         0\n",
       "person_emp_length             0\n",
       "loan_intent                   0\n",
       "loan_amnt                     0\n",
       "loan_int_rate                 0\n",
       "loan_status                   0\n",
       "loan_percent_income           0\n",
       "cb_person_default_on_file     0\n",
       "cb_person_cred_hist_length    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>144</td>\n",
       "      <td>250000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>4800</td>\n",
       "      <td>13.570000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>144</td>\n",
       "      <td>200000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.860000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>123</td>\n",
       "      <td>80004</td>\n",
       "      <td>RENT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>20400</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>123</td>\n",
       "      <td>78000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>7.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>20000</td>\n",
       "      <td>11.011695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32297</th>\n",
       "      <td>144</td>\n",
       "      <td>6000000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>12.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>5000</td>\n",
       "      <td>12.730000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>N</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "81            144         250000                  RENT                4.0   \n",
       "183           144         200000              MORTGAGE                4.0   \n",
       "575           123          80004                  RENT                2.0   \n",
       "747           123          78000                  RENT                7.0   \n",
       "32297         144        6000000              MORTGAGE               12.0   \n",
       "\n",
       "      loan_intent  loan_amnt  loan_int_rate  loan_status  loan_percent_income  \\\n",
       "81        VENTURE       4800      13.570000            0                 0.02   \n",
       "183     EDUCATION       6000      11.860000            0                 0.03   \n",
       "575     EDUCATION      20400      10.250000            0                 0.25   \n",
       "747       VENTURE      20000      11.011695            0                 0.26   \n",
       "32297    PERSONAL       5000      12.730000            0                 0.00   \n",
       "\n",
       "      cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "81                            N                           3  \n",
       "183                           N                           2  \n",
       "575                           N                           3  \n",
       "747                           N                           4  \n",
       "32297                         N                          25  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cases with persone age above 100 years( very rare cases)\n",
    "df[df['person_age']>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['RENT', 'OWN', 'MORTGAGE', 'OTHER'], dtype=object)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking groups in home ownership\n",
    "df['person_home_ownership'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>59000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>123.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>35000</td>\n",
       "      <td>16.02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.59</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>21</td>\n",
       "      <td>192000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>123.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>20000</td>\n",
       "      <td>6.54</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0            22          59000                  RENT              123.0   \n",
       "210          21         192000              MORTGAGE              123.0   \n",
       "\n",
       "    loan_intent  loan_amnt  loan_int_rate  loan_status  loan_percent_income  \\\n",
       "0      PERSONAL      35000          16.02            1                 0.59   \n",
       "210     VENTURE      20000           6.54            0                 0.10   \n",
       "\n",
       "    cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "0                           Y                           3  \n",
       "210                         N                           4  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incorrect employment length above 50 years\n",
    "df[df['person_emp_length']>50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30049</th>\n",
       "      <td>42</td>\n",
       "      <td>2039784</td>\n",
       "      <td>RENT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>8450</td>\n",
       "      <td>12.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Y</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32297</th>\n",
       "      <td>144</td>\n",
       "      <td>6000000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>12.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>5000</td>\n",
       "      <td>12.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>N</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "30049          42        2039784                  RENT                0.0   \n",
       "32297         144        6000000              MORTGAGE               12.0   \n",
       "\n",
       "      loan_intent  loan_amnt  loan_int_rate  loan_status  loan_percent_income  \\\n",
       "30049     VENTURE       8450          12.29            0                  0.0   \n",
       "32297    PERSONAL       5000          12.73            0                  0.0   \n",
       "\n",
       "      cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "30049                         Y                          15  \n",
       "32297                         N                          25  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Incorrect income, Above 2,000,000\n",
    "df[df['person_income']>2000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PERSONAL', 'EDUCATION', 'MEDICAL', 'VENTURE', 'HOMEIMPROVEMENT',\n",
       "       'DEBTCONSOLIDATION'], dtype=object)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding cases of loan intent\n",
    "df['loan_intent'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Understanding cases of loan status \n",
    "df['loan_status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Y', 'N'], dtype=object)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cases of cb_person_default_on_file\n",
    "df['cb_person_default_on_file'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing cases above 100 years\n",
    "df2 = df[df['person_age']<100]\n",
    "\n",
    "# removing incorrect employment length\n",
    "df3 = df2[df2['person_emp_length']<60]\n",
    "\n",
    "# Remove incorrect income\n",
    "df4 = df3[df3['person_income']<2000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>9600</td>\n",
       "      <td>OWN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>1000</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>9600</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>5500</td>\n",
       "      <td>12.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.57</td>\n",
       "      <td>N</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>65500</td>\n",
       "      <td>RENT</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>35000</td>\n",
       "      <td>15.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>54400</td>\n",
       "      <td>RENT</td>\n",
       "      <td>8.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>35000</td>\n",
       "      <td>14.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0.55</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>21</td>\n",
       "      <td>9900</td>\n",
       "      <td>OWN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>VENTURE</td>\n",
       "      <td>2500</td>\n",
       "      <td>7.14</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "1          21           9600                   OWN                5.0   \n",
       "2          25           9600              MORTGAGE                1.0   \n",
       "3          23          65500                  RENT                4.0   \n",
       "4          24          54400                  RENT                8.0   \n",
       "5          21           9900                   OWN                2.0   \n",
       "\n",
       "  loan_intent  loan_amnt  loan_int_rate  loan_status  loan_percent_income  \\\n",
       "1   EDUCATION       1000          11.14            0                 0.10   \n",
       "2     MEDICAL       5500          12.87            1                 0.57   \n",
       "3     MEDICAL      35000          15.23            1                 0.53   \n",
       "4     MEDICAL      35000          14.27            1                 0.55   \n",
       "5     VENTURE       2500           7.14            1                 0.25   \n",
       "\n",
       "  cb_person_default_on_file  cb_person_cred_hist_length  \n",
       "1                         N                           2  \n",
       "2                         N                           3  \n",
       "3                         N                           2  \n",
       "4                         Y                           4  \n",
       "5                         N                           2  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Subplots ---\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "# First subplot: Histogram for 'person_age'\n",
    "axs[0, 0].hist(df4['person_age'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axs[0, 0].set_title('person_age Histogram')\n",
    "axs[0, 0].set_xlabel('Value')\n",
    "axs[0, 0].set_ylabel('Frequency')\n",
    "axs[0, 0].grid(True)\n",
    "\n",
    "# Second subplot: Histogram for 'person_income'\n",
    "axs[0, 1].hist(df4['person_income'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axs[0, 1].set_title('person_income Histogram')\n",
    "axs[0, 1].set_xlabel('Value')\n",
    "axs[0, 1].set_ylabel('Frequency')\n",
    "axs[0, 1].grid(True)\n",
    "\n",
    "# Third subplot: You can plot another relevant variable, e.g., 'person_emp_length'\n",
    "axs[1, 0].hist(df4['person_emp_length'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axs[1, 0].set_title('person_emp_length Histogram')\n",
    "axs[1, 0].set_xlabel('Value')\n",
    "axs[1, 0].set_ylabel('Frequency')\n",
    "axs[1, 0].grid(True)\n",
    "\n",
    "# Fourth subplot: Another variable, e.g., 'loan_amnt'\n",
    "axs[1, 1].hist(df4['loan_amnt'], bins=100, edgecolor='black', alpha=0.7)\n",
    "axs[1, 1].set_title('loan_amnt Histogram')\n",
    "axs[1, 1].set_xlabel('Value')\n",
    "axs[1, 1].set_ylabel('Frequency')\n",
    "axs[1, 1].grid(True)\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# looking at cb_person_default_on_file\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(df4['cb_person_default_on_file'], bins=2, edgecolor='black', alpha=0.7)\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'Y': 5743\n",
      "Number of rows with 'N': 26830\n"
     ]
    }
   ],
   "source": [
    "# Count rows where cb_person_default_on_file == 'Y'\n",
    "count_Y = df4[df4['cb_person_default_on_file'] == 'Y'].shape[0]\n",
    "\n",
    "# Count rows where cb_person_default_on_file == 'N'\n",
    "count_N = df4[df4['cb_person_default_on_file'] == 'N'].shape[0]\n",
    "\n",
    "print(f\"Number of rows with 'Y': {count_Y}\")\n",
    "print(f\"Number of rows with 'N': {count_N}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows imbalance data. To deal with the imbalance data, we need to use:\n",
    "- Metrics like Percision, Recall,F1 Score\n",
    "- Over sampling or under sampling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over sampling the 'Y': 5627 Class\n",
    "Random Oversampling: Randomly duplicate examples in the minority class.\n",
    "In the first step we need to split data into train and test and then over sample train data to avoid ddata leakage. \n",
    "Almost all feature engineering like standardization, Normalisation etc should be done after the train test split.\n",
    "Here is order of things:\n",
    "1. Train and Test Split\n",
    "2. One-Hot-Encoding\n",
    "3. Over samoling of train data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into X and Y\n",
    "X = df4.drop('cb_person_default_on_file', axis =1)\n",
    "Y = df4['cb_person_default_on_file'] # traget variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split The data into train and test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, shuffle=True, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26081</th>\n",
       "      <td>28</td>\n",
       "      <td>96000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>HOMEIMPROVEMENT</td>\n",
       "      <td>11250</td>\n",
       "      <td>17.580000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>25</td>\n",
       "      <td>22776</td>\n",
       "      <td>RENT</td>\n",
       "      <td>4.789686</td>\n",
       "      <td>HOMEIMPROVEMENT</td>\n",
       "      <td>7000</td>\n",
       "      <td>9.910000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.31</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>22</td>\n",
       "      <td>40000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>9875</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30916</th>\n",
       "      <td>40</td>\n",
       "      <td>70000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>HOMEIMPROVEMENT</td>\n",
       "      <td>12000</td>\n",
       "      <td>5.790000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.17</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>24</td>\n",
       "      <td>35000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>10000</td>\n",
       "      <td>11.011695</td>\n",
       "      <td>0</td>\n",
       "      <td>0.29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "26081          28          96000              MORTGAGE           5.000000   \n",
       "6778           25          22776                  RENT           4.789686   \n",
       "4038           22          40000              MORTGAGE           6.000000   \n",
       "30916          40          70000              MORTGAGE          16.000000   \n",
       "10569          24          35000                  RENT           1.000000   \n",
       "\n",
       "             loan_intent  loan_amnt  loan_int_rate  loan_status  \\\n",
       "26081    HOMEIMPROVEMENT      11250      17.580000            0   \n",
       "6778     HOMEIMPROVEMENT       7000       9.910000            1   \n",
       "4038             MEDICAL       9875       7.900000            0   \n",
       "30916    HOMEIMPROVEMENT      12000       5.790000            0   \n",
       "10569  DEBTCONSOLIDATION      10000      11.011695            0   \n",
       "\n",
       "       loan_percent_income  cb_person_cred_hist_length  \n",
       "26081                 0.12                           5  \n",
       "6778                  0.31                           4  \n",
       "4038                  0.25                           4  \n",
       "30916                 0.17                          14  \n",
       "10569                 0.29                           4  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number train data set: 26058\n",
      "Number test data set: 6515\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number train data set: {X_train.shape[0]}\")\n",
    "print(f\"Number test data set: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale X_train and X_test : This is important because many machine learning algorithms, including logistic regression, can be sensitive to the scale of the input features.\n",
    "We are scaling them seperatly to avoid data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# List of numerical columns to scale\n",
    "numeric_features = ['person_age', 'person_income', 'person_emp_length', \n",
    "                    'loan_amnt', 'loan_int_rate', 'loan_percent_income', \n",
    "                    'cb_person_cred_hist_length']\n",
    "# Create a ColumnTransformer\n",
    "ct = ColumnTransformer([\n",
    "    ('scaler', StandardScaler(), numeric_features)\n",
    "], remainder='passthrough')\n",
    "\n",
    "# Fit the scaler on the training data and transform both train and test\n",
    "X_train_scaled_array = ct.fit_transform(X_train)\n",
    "X_test_scaled_array = ct.transform(X_test)\n",
    "\n",
    "# Get the order of columns after transformation\n",
    "scaled_columns = numeric_features\n",
    "passthrough_columns = [col for col in X_train.columns if col not in numeric_features]\n",
    "all_columns = scaled_columns + passthrough_columns\n",
    "\n",
    "# Convert the scaled arrays back to DataFrames\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled_array, columns=all_columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled_array, columns=all_columns, index=X_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26081</th>\n",
       "      <td>0.044733</td>\n",
       "      <td>0.566818</td>\n",
       "      <td>0.051877</td>\n",
       "      <td>0.26198</td>\n",
       "      <td>2.13065</td>\n",
       "      <td>-0.468325</td>\n",
       "      <td>-0.198934</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>HOMEIMPROVEMENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6778</th>\n",
       "      <td>-0.438408</td>\n",
       "      <td>-0.820763</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>-0.410159</td>\n",
       "      <td>-0.358777</td>\n",
       "      <td>1.309578</td>\n",
       "      <td>-0.445348</td>\n",
       "      <td>RENT</td>\n",
       "      <td>HOMEIMPROVEMENT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4038</th>\n",
       "      <td>-0.921549</td>\n",
       "      <td>-0.494371</td>\n",
       "      <td>0.302143</td>\n",
       "      <td>0.044523</td>\n",
       "      <td>-1.011156</td>\n",
       "      <td>0.748135</td>\n",
       "      <td>-0.445348</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30916</th>\n",
       "      <td>1.977298</td>\n",
       "      <td>0.074123</td>\n",
       "      <td>2.804808</td>\n",
       "      <td>0.380592</td>\n",
       "      <td>-1.695992</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>2.018796</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>HOMEIMPROVEMENT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10569</th>\n",
       "      <td>-0.599455</td>\n",
       "      <td>-0.58912</td>\n",
       "      <td>-0.949189</td>\n",
       "      <td>0.064292</td>\n",
       "      <td>-0.001204</td>\n",
       "      <td>1.12243</td>\n",
       "      <td>-0.445348</td>\n",
       "      <td>RENT</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      person_age person_income person_emp_length loan_amnt loan_int_rate  \\\n",
       "26081   0.044733      0.566818          0.051877   0.26198       2.13065   \n",
       "6778   -0.438408     -0.820763         -0.000758 -0.410159     -0.358777   \n",
       "4038   -0.921549     -0.494371          0.302143  0.044523     -1.011156   \n",
       "30916   1.977298      0.074123          2.804808  0.380592     -1.695992   \n",
       "10569  -0.599455      -0.58912         -0.949189  0.064292     -0.001204   \n",
       "\n",
       "      loan_percent_income cb_person_cred_hist_length person_home_ownership  \\\n",
       "26081           -0.468325                  -0.198934              MORTGAGE   \n",
       "6778             1.309578                  -0.445348                  RENT   \n",
       "4038             0.748135                  -0.445348              MORTGAGE   \n",
       "30916           -0.000456                   2.018796              MORTGAGE   \n",
       "10569             1.12243                  -0.445348                  RENT   \n",
       "\n",
       "             loan_intent loan_status  \n",
       "26081    HOMEIMPROVEMENT           0  \n",
       "6778     HOMEIMPROVEMENT           1  \n",
       "4038             MEDICAL           0  \n",
       "30916    HOMEIMPROVEMENT           0  \n",
       "10569  DEBTCONSOLIDATION           0  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. One-Hot-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the categorical variables in X_train_scaled and X_test_scaled\n",
    "# We specify `sparse=False` to return a dense array\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Fit and transform on train data\n",
    "X_train_encoded = pd.DataFrame(encoder.fit_transform(X_train_scaled[['person_home_ownership', 'loan_intent']]), \n",
    "                               columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Transform test data (without fitting again)\n",
    "X_test_encoded = pd.DataFrame(encoder.transform(X_test_scaled[['person_home_ownership', 'loan_intent']]), \n",
    "                              columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Drop original columns and concatenate encoded ones\n",
    "X_train = X_train_scaled.drop(columns=['person_home_ownership', 'loan_intent']).reset_index(drop=True)\n",
    "X_train = pd.concat([X_train, X_train_encoded], axis=1)\n",
    "\n",
    "X_test = X_test_scaled.drop(columns=['person_home_ownership', 'loan_intent']).reset_index(drop=True)\n",
    "X_test = pd.concat([X_test, X_test_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>person_home_ownership_MORTGAGE</th>\n",
       "      <th>person_home_ownership_OTHER</th>\n",
       "      <th>person_home_ownership_OWN</th>\n",
       "      <th>person_home_ownership_RENT</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044733</td>\n",
       "      <td>0.566818</td>\n",
       "      <td>0.051877</td>\n",
       "      <td>0.26198</td>\n",
       "      <td>2.13065</td>\n",
       "      <td>-0.468325</td>\n",
       "      <td>-0.198934</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.438408</td>\n",
       "      <td>-0.820763</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>-0.410159</td>\n",
       "      <td>-0.358777</td>\n",
       "      <td>1.309578</td>\n",
       "      <td>-0.445348</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.921549</td>\n",
       "      <td>-0.494371</td>\n",
       "      <td>0.302143</td>\n",
       "      <td>0.044523</td>\n",
       "      <td>-1.011156</td>\n",
       "      <td>0.748135</td>\n",
       "      <td>-0.445348</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.977298</td>\n",
       "      <td>0.074123</td>\n",
       "      <td>2.804808</td>\n",
       "      <td>0.380592</td>\n",
       "      <td>-1.695992</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>2.018796</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.599455</td>\n",
       "      <td>-0.58912</td>\n",
       "      <td>-0.949189</td>\n",
       "      <td>0.064292</td>\n",
       "      <td>-0.001204</td>\n",
       "      <td>1.12243</td>\n",
       "      <td>-0.445348</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  person_age person_income person_emp_length loan_amnt loan_int_rate  \\\n",
       "0   0.044733      0.566818          0.051877   0.26198       2.13065   \n",
       "1  -0.438408     -0.820763         -0.000758 -0.410159     -0.358777   \n",
       "2  -0.921549     -0.494371          0.302143  0.044523     -1.011156   \n",
       "3   1.977298      0.074123          2.804808  0.380592     -1.695992   \n",
       "4  -0.599455      -0.58912         -0.949189  0.064292     -0.001204   \n",
       "\n",
       "  loan_percent_income cb_person_cred_hist_length loan_status  \\\n",
       "0           -0.468325                  -0.198934           0   \n",
       "1            1.309578                  -0.445348           1   \n",
       "2            0.748135                  -0.445348           0   \n",
       "3           -0.000456                   2.018796           0   \n",
       "4             1.12243                  -0.445348           0   \n",
       "\n",
       "   person_home_ownership_MORTGAGE  person_home_ownership_OTHER  \\\n",
       "0                             1.0                          0.0   \n",
       "1                             0.0                          0.0   \n",
       "2                             1.0                          0.0   \n",
       "3                             1.0                          0.0   \n",
       "4                             0.0                          0.0   \n",
       "\n",
       "   person_home_ownership_OWN  person_home_ownership_RENT  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         1.0   \n",
       "2                        0.0                         0.0   \n",
       "3                        0.0                         0.0   \n",
       "4                        0.0                         1.0   \n",
       "\n",
       "   loan_intent_DEBTCONSOLIDATION  loan_intent_EDUCATION  \\\n",
       "0                            0.0                    0.0   \n",
       "1                            0.0                    0.0   \n",
       "2                            0.0                    0.0   \n",
       "3                            0.0                    0.0   \n",
       "4                            1.0                    0.0   \n",
       "\n",
       "   loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n",
       "0                          1.0                  0.0                   0.0   \n",
       "1                          1.0                  0.0                   0.0   \n",
       "2                          0.0                  1.0                   0.0   \n",
       "3                          1.0                  0.0                   0.0   \n",
       "4                          0.0                  0.0                   0.0   \n",
       "\n",
       "   loan_intent_VENTURE  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>person_home_ownership_MORTGAGE</th>\n",
       "      <th>person_home_ownership_OTHER</th>\n",
       "      <th>person_home_ownership_OWN</th>\n",
       "      <th>person_home_ownership_RENT</th>\n",
       "      <th>loan_intent_DEBTCONSOLIDATION</th>\n",
       "      <th>loan_intent_EDUCATION</th>\n",
       "      <th>loan_intent_HOMEIMPROVEMENT</th>\n",
       "      <th>loan_intent_MEDICAL</th>\n",
       "      <th>loan_intent_PERSONAL</th>\n",
       "      <th>loan_intent_VENTURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.921549</td>\n",
       "      <td>-0.210124</td>\n",
       "      <td>0.302143</td>\n",
       "      <td>0.538743</td>\n",
       "      <td>0.920016</td>\n",
       "      <td>0.654561</td>\n",
       "      <td>-0.691763</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.760502</td>\n",
       "      <td>-0.304873</td>\n",
       "      <td>0.55241</td>\n",
       "      <td>-0.726459</td>\n",
       "      <td>-0.138072</td>\n",
       "      <td>-0.655473</td>\n",
       "      <td>-0.938177</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.277361</td>\n",
       "      <td>0.642617</td>\n",
       "      <td>1.553476</td>\n",
       "      <td>0.775968</td>\n",
       "      <td>-0.673607</td>\n",
       "      <td>-0.281178</td>\n",
       "      <td>-0.691763</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.277361</td>\n",
       "      <td>1.665907</td>\n",
       "      <td>0.051877</td>\n",
       "      <td>0.443852</td>\n",
       "      <td>0.264391</td>\n",
       "      <td>-0.842621</td>\n",
       "      <td>-0.445348</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.277361</td>\n",
       "      <td>0.642617</td>\n",
       "      <td>0.55241</td>\n",
       "      <td>-0.331084</td>\n",
       "      <td>-0.874838</td>\n",
       "      <td>-0.936195</td>\n",
       "      <td>-0.691763</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  person_age person_income person_emp_length loan_amnt loan_int_rate  \\\n",
       "0  -0.921549     -0.210124          0.302143  0.538743      0.920016   \n",
       "1  -0.760502     -0.304873           0.55241 -0.726459     -0.138072   \n",
       "2  -0.277361      0.642617          1.553476  0.775968     -0.673607   \n",
       "3  -0.277361      1.665907          0.051877  0.443852      0.264391   \n",
       "4  -0.277361      0.642617           0.55241 -0.331084     -0.874838   \n",
       "\n",
       "  loan_percent_income cb_person_cred_hist_length loan_status  \\\n",
       "0            0.654561                  -0.691763           0   \n",
       "1           -0.655473                  -0.938177           0   \n",
       "2           -0.281178                  -0.691763           0   \n",
       "3           -0.842621                  -0.445348           0   \n",
       "4           -0.936195                  -0.691763           0   \n",
       "\n",
       "   person_home_ownership_MORTGAGE  person_home_ownership_OTHER  \\\n",
       "0                             1.0                          0.0   \n",
       "1                             0.0                          0.0   \n",
       "2                             0.0                          0.0   \n",
       "3                             1.0                          0.0   \n",
       "4                             1.0                          0.0   \n",
       "\n",
       "   person_home_ownership_OWN  person_home_ownership_RENT  \\\n",
       "0                        0.0                         0.0   \n",
       "1                        0.0                         1.0   \n",
       "2                        0.0                         1.0   \n",
       "3                        0.0                         0.0   \n",
       "4                        0.0                         0.0   \n",
       "\n",
       "   loan_intent_DEBTCONSOLIDATION  loan_intent_EDUCATION  \\\n",
       "0                            0.0                    0.0   \n",
       "1                            0.0                    1.0   \n",
       "2                            0.0                    0.0   \n",
       "3                            0.0                    0.0   \n",
       "4                            1.0                    0.0   \n",
       "\n",
       "   loan_intent_HOMEIMPROVEMENT  loan_intent_MEDICAL  loan_intent_PERSONAL  \\\n",
       "0                          0.0                  0.0                   1.0   \n",
       "1                          0.0                  0.0                   0.0   \n",
       "2                          0.0                  0.0                   1.0   \n",
       "3                          0.0                  1.0                   0.0   \n",
       "4                          0.0                  0.0                   0.0   \n",
       "\n",
       "   loan_intent_VENTURE  \n",
       "0                  0.0  \n",
       "1                  0.0  \n",
       "2                  0.0  \n",
       "3                  0.0  \n",
       "4                  0.0  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Y_train and Y_test from 'Y'/'N' to 1/0\n",
    "Y_train = Y_train.map({'Y': 1, 'N': 0}).reset_index(drop=True)\n",
    "Y_test = Y_test.map({'Y': 1, 'N': 0}).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes ----> Person default on file ---->1\n",
    "\n",
    "No ----> Person default on file ---->0\n",
    "\n",
    "True positive -----> Correctly classified as default\n",
    "\n",
    "False Positive ------> Incorrectly classified as default\n",
    "\n",
    "True Negative -----> Correctly classified as non default\n",
    "\n",
    "### False Negative -----> Incorrectly classified as non default (This is what we are mostly worried about in a default case)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "26053    0\n",
       "26054    0\n",
       "26055    0\n",
       "26056    0\n",
       "26057    0\n",
       "Name: cb_person_default_on_file, Length: 26058, dtype: int64"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To apply oversampling using SMOTE (Synthetic Minority Over-sampling Technique) on X_train and Y_train, you'll need to ensure that the categorical variables have been encoded and that SMOTE is applied only to the training set. SMOTE works by creating synthetic examples for the minority class, but it only works with numerical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to oversample the minority class in the training set\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Ensure X_train is in numerical format \n",
    "X_train_resampled, Y_train_resampled = smote.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21459, 21459)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of data in each category after over sampling\n",
    "sum(Y_train_resampled==1), sum(Y_train_resampled==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest method to detect multicollinearity in data is by using the Variance Inflation Factor (VIF). VIF measures the correlation between independent variables and quantifies the extent of this correlation. Also it is only applicable on numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for multicolinearity\n",
    "%pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# columns to check VIF for\n",
    "X = X_train_resampled[['person_age', 'person_income', 'person_emp_length', 'loan_amnt',\n",
    "       'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n",
    "       'loan_status', 'person_home_ownership_MORTGAGE',\n",
    "       'person_home_ownership_OTHER', 'person_home_ownership_OWN',\n",
    "       'person_home_ownership_RENT', 'loan_intent_DEBTCONSOLIDATION',\n",
    "       'loan_intent_EDUCATION', 'loan_intent_HOMEIMPROVEMENT',\n",
    "       'loan_intent_MEDICAL', 'loan_intent_PERSONAL', 'loan_intent_VENTURE']]\n",
    "\n",
    "#Create an empty dataframe\n",
    "vif = pd.DataFrame()\n",
    "\n",
    "#copy features of x in datafram\n",
    "vif[\"features\"] =  X.columns\n",
    "\n",
    "#change data format to numeric\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Calculate VIF for all the variables\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>VIF Factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>person_age</td>\n",
       "      <td>4.792174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>person_income</td>\n",
       "      <td>1.924042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>person_emp_length</td>\n",
       "      <td>1.117076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loan_amnt</td>\n",
       "      <td>2.805556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loan_int_rate</td>\n",
       "      <td>1.171630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>loan_percent_income</td>\n",
       "      <td>2.887062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cb_person_cred_hist_length</td>\n",
       "      <td>4.721714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>loan_status</td>\n",
       "      <td>1.433451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>person_home_ownership_MORTGAGE</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>person_home_ownership_OTHER</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>person_home_ownership_OWN</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>person_home_ownership_RENT</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>loan_intent_DEBTCONSOLIDATION</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>loan_intent_EDUCATION</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>loan_intent_HOMEIMPROVEMENT</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>loan_intent_MEDICAL</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>loan_intent_PERSONAL</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>loan_intent_VENTURE</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          features  VIF Factor\n",
       "0                       person_age    4.792174\n",
       "1                    person_income    1.924042\n",
       "2                person_emp_length    1.117076\n",
       "3                        loan_amnt    2.805556\n",
       "4                    loan_int_rate    1.171630\n",
       "5              loan_percent_income    2.887062\n",
       "6       cb_person_cred_hist_length    4.721714\n",
       "7                      loan_status    1.433451\n",
       "8   person_home_ownership_MORTGAGE         inf\n",
       "9      person_home_ownership_OTHER         inf\n",
       "10       person_home_ownership_OWN         inf\n",
       "11      person_home_ownership_RENT         inf\n",
       "12   loan_intent_DEBTCONSOLIDATION         inf\n",
       "13           loan_intent_EDUCATION         inf\n",
       "14     loan_intent_HOMEIMPROVEMENT         inf\n",
       "15             loan_intent_MEDICAL         inf\n",
       "16            loan_intent_PERSONAL         inf\n",
       "17             loan_intent_VENTURE         inf"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vif for cb_person_cred_hist_length, person_age is high, lets check correlation matrix too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = X_train_resampled.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#set figure size\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "# Plot correlation heatmap\n",
    "sns.heatmap(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no multi colinearity in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our train data set is ready for modeling. I will be using Logistic regression, Random Forest and XGBoost for classification. I'll be comparing F1 score, AUC and False negative rate which is imporatnt for credit risk default. Note that regularization is applied by default. L2 is the default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Rgeression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=5000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the LogisticRegression object with a higher max_iter\n",
    "lor = LogisticRegression(max_iter=5000)  # You can adjust this number as needed\n",
    "\n",
    "# Fit the model\n",
    "lor.fit(X_train_resampled, Y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lor.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating accuracy metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction probabilities for ROC curve\n",
    "y_pred_proba = lor.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29096672, 0.70903328],\n",
       "       [0.76575518, 0.23424482],\n",
       "       [0.93136325, 0.06863675],\n",
       "       ...,\n",
       "       [0.97698703, 0.02301297],\n",
       "       [0.72362983, 0.27637017],\n",
       "       [0.98538705, 0.01461295]])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_proba returns the probability of each class. so the sum of each row in this is going to be 1. We need probability of \n",
    "lor.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6119\n",
      "False Negative Rate: 0.1565\n"
     ]
    }
   ],
   "source": [
    "# Calculate ROC curve and AUC\n",
    "fpr, tpr, _ = roc_curve(Y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, y_pred)\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "\n",
    "# Calculate False Negative Rate\n",
    "fn = cm[1][0]  # False negatives\n",
    "tp = cm[1][1]  # True positives\n",
    "fnr = fn / (fn + tp)\n",
    "\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"False Negative Rate: {fnr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC (Area Under the ROC Curve): 0.87\n",
    "\n",
    "This is an excellent score. The AUC ranges from 0 to 1, where 1 is perfect prediction and 0.5 is no better than random guessing.\n",
    "A score of 0.87 indicates that your model has a strong ability to distinguish between the positive class (likely loan defaults) and the negative class (likely non-defaults).\n",
    "Generally, 0.8-0.9 is considered excellent discrimination.\n",
    "\n",
    "\n",
    "F1 Score: 0.5983\n",
    "\n",
    "The F1 score is the harmonic mean of precision and recall, ranging from 0 (worst) to 1 (best).\n",
    "A score of 0.5983 suggests moderate performance. It's above 0.5, which is good, but there's room for improvement.\n",
    "This score indicates a reasonable balance between precision (minimizing false positives) and recall (minimizing false negatives), but not outstanding in either.\n",
    "\n",
    "\n",
    "False Negative Rate (FNR): 0.1503\n",
    "\n",
    "This means that about 15.03% of actual positive cases (likely actual defaults) were incorrectly classified as negative (predicted to not default).\n",
    "In the context of credit risk assessment, false negatives are often considered more costly than false positives, as they represent loans that the model predicted would be repaid but actually defaulted.\n",
    "A 15.03% FNR isn't terrible, but in credit risk assessment, you might want to reduce this further if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using cross-validation to ensure these results are stable across different subsets of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "# Create the LogisticRegression object\n",
    "lor = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# Define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# Create a StratifiedKFold object. This cross-validation object is a variation of KFold that returns stratified folds. \n",
    "# The folds are made by preserving the percentage of samples for each class.\n",
    "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Define scoring metrics. We want to have 3 scoring metrics\n",
    "scoring = {\n",
    "    'AUC': 'roc_auc',\n",
    "    'F1': 'f1',\n",
    "    'Accuracy': 'accuracy',\n",
    "    'Recall' : 'recall' #larger recall smaller false negative TP/(TP+FN)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation using cross_validate (which supports multiple metrics)\n",
    "cv_results = cross_validate(lor, X_train_resampled, Y_train_resampled, cv=skf, scoring=scoring, return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.18977046, 0.15760279, 0.19322991, 0.16942549, 0.2553091 ]),\n",
       " 'score_time': array([0.05262828, 0.08047652, 0.06554937, 0.07561779, 0.072541  ]),\n",
       " 'test_AUC': array([0.8779863 , 0.86939251, 0.87907089, 0.874109  , 0.88280736]),\n",
       " 'test_F1': array([0.83841223, 0.83316594, 0.8373836 , 0.84021946, 0.84533755]),\n",
       " 'test_Accuracy': array([0.83259553, 0.82583877, 0.83317801, 0.83374112, 0.84038215]),\n",
       " 'test_Recall': array([0.86859273, 0.86975769, 0.85904007, 0.87438825, 0.8723206 ])}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8767 (+/- 0.0092)\n",
      "F1 Score: 0.8389 (+/- 0.0079)\n",
      "Accuracy: 0.8331 (+/- 0.0092)\n",
      "Recall: 0.8688 (+/- 0.0106)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Print results\n",
    "print(f\"AUC: {cv_results['test_AUC'].mean():.4f} (+/- {cv_results['test_AUC'].std() * 2:.4f})\")\n",
    "print(f\"F1 Score: {cv_results['test_F1'].mean():.4f} (+/- {cv_results['test_F1'].std() * 2:.4f})\")\n",
    "print(f\"Accuracy: {cv_results['test_Accuracy'].mean():.4f} (+/- {cv_results['test_Accuracy'].std() * 2:.4f})\")\n",
    "print(f\"Recall: {cv_results['test_Recall'].mean():.4f} (+/- {cv_results['test_Recall'].std() * 2:.4f})\")\n",
    "\n",
    "# Plot the distribution of scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot([cv_results['test_AUC'], cv_results['test_F1'],cv_results['test_Accuracy'], cv_results['test_Recall']], \n",
    "            labels=['AUC', 'F1 Score', 'Accuracy','Recall'])\n",
    "plt.title('Distribution of Scores Across Folds')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if we can improve accuracy using XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A little about XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting algorithms are methods designed to improve the performance of weak learners by combining them into a stronger model. Some examples are: XGBoost, LightGBM, and AdaBoost \n",
    "\n",
    "AdaBoost: It operates by sequentially training a series of weak learners and assigning higher weights to misclassified samples in each iteration.\n",
    "\n",
    "XGBoost: XGBoost introduces regularization techniques, parallel processing, and tree-pruning algorithms to achieve high accuracy and speed.\n",
    "\n",
    "LightGBM: It adopts a histogram-based learning approach, discretizing continuous features into discrete bins during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialization:\n",
    "Begin with a base model that makes simple predictions (e.g., mean for regression, mode for classification) to serve as the starting point.\n",
    "\n",
    "2. Iterative Improvement:\n",
    "Sequentially add weak learners (e.g., decision trees) to improve predictions. After each step, residuals or errors are calculated based on the difference between predicted and actual values.\n",
    "\n",
    "3. Gradient Descent Step:\n",
    "Compute the negative gradient of the loss function to guide the updates, then fit a new weak learner to these gradients.\n",
    "\n",
    "4. Update with Learning Rate:\n",
    "Scale new predictions by a learning rate and add them to the previous model. The learning rate controls the pace of learning and helps prevent overfitting.\n",
    "\n",
    "5. Regularization:\n",
    "Apply methods like limiting tree depth, setting minimum samples per leaf, or adjusting the number of iterations to prevent overfitting.\n",
    "\n",
    "6. Stopping Criteria:\n",
    "Stop adding trees after a set number of iterations or when improvements fall below a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package xgboost:\n",
      "\n",
      "NAME\n",
      "    xgboost - XGBoost: eXtreme Gradient Boosting library.\n",
      "\n",
      "DESCRIPTION\n",
      "    Contributors: https://github.com/dmlc/xgboost/blob/master/CONTRIBUTORS.md\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _typing\n",
      "    callback\n",
      "    collective\n",
      "    compat\n",
      "    config\n",
      "    core\n",
      "    dask (package)\n",
      "    data\n",
      "    federated\n",
      "    libpath\n",
      "    plotting\n",
      "    sklearn\n",
      "    spark (package)\n",
      "    testing (package)\n",
      "    tracker\n",
      "    training\n",
      "\n",
      "CLASSES\n",
      "    abc.ABC(builtins.object)\n",
      "        xgboost.core.DataIter\n",
      "    builtins.object\n",
      "        xgboost.core.Booster\n",
      "        xgboost.core.DMatrix\n",
      "            xgboost.core.QuantileDMatrix\n",
      "                xgboost.core.DeviceQuantileDMatrix\n",
      "        xgboost.tracker.RabitTracker\n",
      "    sklearn.base.BaseEstimator(sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin, sklearn.utils._metadata_requests._MetadataRequester)\n",
      "        xgboost.sklearn.XGBModel\n",
      "            xgboost.sklearn.XGBClassifier(xgboost.sklearn.XGBModel, sklearn.base.ClassifierMixin)\n",
      "                xgboost.sklearn.XGBRFClassifier\n",
      "            xgboost.sklearn.XGBRanker(xgboost.sklearn.XGBModel, xgboost.sklearn.XGBRankerMixIn)\n",
      "            xgboost.sklearn.XGBRegressor(xgboost.sklearn.XGBModel, sklearn.base.RegressorMixin)\n",
      "                xgboost.sklearn.XGBRFRegressor\n",
      "    \n",
      "    class Booster(builtins.object)\n",
      "     |  Booster(params: Union[List, Dict[str, Any], NoneType] = None, cache: Optional[Sequence[xgboost.core.DMatrix]] = None, model_file: Union[ForwardRef('Booster'), bytearray, os.PathLike, str, NoneType] = None) -> None\n",
      "     |  \n",
      "     |  A Booster of XGBoost.\n",
      "     |  \n",
      "     |  Booster is the model of xgboost, that contains low level routines for\n",
      "     |  training, prediction and evaluation.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __copy__(self) -> 'Booster'\n",
      "     |  \n",
      "     |  __deepcopy__(self, _: Any) -> 'Booster'\n",
      "     |      Return a copy of booster.\n",
      "     |  \n",
      "     |  __del__(self) -> None\n",
      "     |  \n",
      "     |  __getitem__(self, val: Union[int, numpy.integer, tuple, slice]) -> 'Booster'\n",
      "     |      Get a slice of the tree-based model.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3.0\n",
      "     |  \n",
      "     |  __getstate__(self) -> Dict\n",
      "     |  \n",
      "     |  __init__(self, params: Union[List, Dict[str, Any], NoneType] = None, cache: Optional[Sequence[xgboost.core.DMatrix]] = None, model_file: Union[ForwardRef('Booster'), bytearray, os.PathLike, str, NoneType] = None) -> None\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params :\n",
      "     |          Parameters for boosters.\n",
      "     |      cache :\n",
      "     |          List of cache items.\n",
      "     |      model_file :\n",
      "     |          Path to the model file if it's string or PathLike.\n",
      "     |  \n",
      "     |  __iter__(self) -> Generator[ForwardRef('Booster'), NoneType, NoneType]\n",
      "     |      Iterator method for getting individual trees.\n",
      "     |      \n",
      "     |      .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |  __setstate__(self, state: Dict) -> None\n",
      "     |  \n",
      "     |  attr(self, key: str) -> Optional[str]\n",
      "     |      Get attribute string from the Booster.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      key :\n",
      "     |          The key to get attribute from.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value :\n",
      "     |          The attribute value of the key, returns None if attribute do not exist.\n",
      "     |  \n",
      "     |  attributes(self) -> Dict[str, Optional[str]]\n",
      "     |      Get attributes stored in the Booster as a dictionary.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : dictionary of  attribute_name: attribute_value pairs of strings.\n",
      "     |          Returns an empty dict if there's no attributes.\n",
      "     |  \n",
      "     |  boost(self, dtrain: xgboost.core.DMatrix, iteration: int, grad: Any, hess: Any) -> None\n",
      "     |      Boost the booster for one iteration with customized gradient statistics.\n",
      "     |      Like :py:func:`xgboost.Booster.update`, this function should not be called\n",
      "     |      directly by users.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtrain :\n",
      "     |          The training DMatrix.\n",
      "     |      grad :\n",
      "     |          The first order of gradient.\n",
      "     |      hess :\n",
      "     |          The second order of gradient.\n",
      "     |  \n",
      "     |  copy(self) -> 'Booster'\n",
      "     |      Copy the booster object.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      booster :\n",
      "     |          A copied booster model\n",
      "     |  \n",
      "     |  dump_model(self, fout: Union[str, os.PathLike], fmap: Union[str, os.PathLike] = '', with_stats: bool = False, dump_format: str = 'text') -> None\n",
      "     |      Dump model into a text or JSON file.  Unlike :py:meth:`save_model`, the\n",
      "     |      output format is primarily used for visualization or interpretation,\n",
      "     |      hence it's more human readable but cannot be loaded back to XGBoost.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fout :\n",
      "     |          Output file name.\n",
      "     |      fmap :\n",
      "     |          Name of the file containing feature map names.\n",
      "     |      with_stats :\n",
      "     |          Controls whether the split statistics are output.\n",
      "     |      dump_format :\n",
      "     |          Format of model dump file. Can be 'text' or 'json'.\n",
      "     |  \n",
      "     |  eval(self, data: xgboost.core.DMatrix, name: str = 'eval', iteration: int = 0) -> str\n",
      "     |      Evaluate the model on mat.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data :\n",
      "     |          The dmatrix storing the input.\n",
      "     |      \n",
      "     |      name :\n",
      "     |          The name of the dataset.\n",
      "     |      \n",
      "     |      iteration :\n",
      "     |          The current iteration number.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result: str\n",
      "     |          Evaluation result string.\n",
      "     |  \n",
      "     |  eval_set(self, evals: Sequence[Tuple[xgboost.core.DMatrix, str]], iteration: int = 0, feval: Optional[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]]] = None, output_margin: bool = True) -> str\n",
      "     |      Evaluate a set of data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      evals :\n",
      "     |          List of items to be evaluated.\n",
      "     |      iteration :\n",
      "     |          Current iteration.\n",
      "     |      feval :\n",
      "     |          Custom evaluation function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result: str\n",
      "     |          Evaluation result string.\n",
      "     |  \n",
      "     |  get_dump(self, fmap: Union[str, os.PathLike] = '', with_stats: bool = False, dump_format: str = 'text') -> List[str]\n",
      "     |      Returns the model dump as a list of strings.  Unlike :py:meth:`save_model`,\n",
      "     |      the output format is primarily used for visualization or interpretation, hence\n",
      "     |      it's more human readable but cannot be loaded back to XGBoost.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fmap :\n",
      "     |          Name of the file containing feature map names.\n",
      "     |      with_stats :\n",
      "     |          Controls whether the split statistics are output.\n",
      "     |      dump_format :\n",
      "     |          Format of model dump. Can be 'text', 'json' or 'dot'.\n",
      "     |  \n",
      "     |  get_fscore(self, fmap: Union[str, os.PathLike] = '') -> Dict[str, Union[float, List[float]]]\n",
      "     |      Get feature importance of each feature.\n",
      "     |      \n",
      "     |      .. note:: Zero-importance features will not be included\n",
      "     |      \n",
      "     |         Keep in mind that this function does not include zero-importance feature, i.e.\n",
      "     |         those features that have not been used in any split conditions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fmap :\n",
      "     |         The name of feature map file\n",
      "     |  \n",
      "     |  get_score(self, fmap: Union[str, os.PathLike] = '', importance_type: str = 'weight') -> Dict[str, Union[float, List[float]]]\n",
      "     |      Get feature importance of each feature.\n",
      "     |      For tree model Importance type can be defined as:\n",
      "     |      \n",
      "     |      * 'weight': the number of times a feature is used to split the data across all trees.\n",
      "     |      * 'gain': the average gain across all splits the feature is used in.\n",
      "     |      * 'cover': the average coverage across all splits the feature is used in.\n",
      "     |      * 'total_gain': the total gain across all splits the feature is used in.\n",
      "     |      * 'total_cover': the total coverage across all splits the feature is used in.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |         For linear model, only \"weight\" is defined and it's the normalized coefficients\n",
      "     |         without bias.\n",
      "     |      \n",
      "     |      .. note:: Zero-importance features will not be included\n",
      "     |      \n",
      "     |         Keep in mind that this function does not include zero-importance feature, i.e.\n",
      "     |         those features that have not been used in any split conditions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fmap :\n",
      "     |         The name of feature map file.\n",
      "     |      importance_type :\n",
      "     |          One of the importance types defined above.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      A map between feature names and their scores.  When `gblinear` is used for\n",
      "     |      multi-class classification the scores for each feature is a list with length\n",
      "     |      `n_classes`, otherwise they're scalars.\n",
      "     |  \n",
      "     |  get_split_value_histogram(self, feature: str, fmap: Union[os.PathLike, str] = '', bins: Optional[int] = None, as_pandas: bool = True) -> Union[numpy.ndarray, pandas.core.frame.DataFrame]\n",
      "     |      Get split value histogram of a feature\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      feature :\n",
      "     |          The name of the feature.\n",
      "     |      fmap:\n",
      "     |          The name of feature map file.\n",
      "     |      bin :\n",
      "     |          The maximum number of bins.\n",
      "     |          Number of bins equals number of unique split values n_unique,\n",
      "     |          if bins == None or bins > n_unique.\n",
      "     |      as_pandas :\n",
      "     |          Return pd.DataFrame when pandas is installed.\n",
      "     |          If False or pandas is not installed, return numpy ndarray.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a histogram of used splitting values for the specified feature\n",
      "     |      either as numpy array or pandas DataFrame.\n",
      "     |  \n",
      "     |  inplace_predict(self, data: Any, iteration_range: Tuple[Union[int, numpy.integer], Union[int, numpy.integer]] = (0, 0), predict_type: str = 'value', missing: float = nan, validate_features: bool = True, base_margin: Any = None, strict_shape: bool = False) -> Any\n",
      "     |      Run prediction in-place when possible, Unlike :py:meth:`predict` method,\n",
      "     |      inplace prediction does not cache the prediction result.\n",
      "     |      \n",
      "     |      Calling only ``inplace_predict`` in multiple threads is safe and lock\n",
      "     |      free.  But the safety does not hold when used in conjunction with other\n",
      "     |      methods. E.g. you can't train the booster in one thread and perform\n",
      "     |      prediction in the other.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          If the device ordinal of the input data doesn't match the one configured for\n",
      "     |          the booster, data will be copied to the booster device.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |          booster.set_param({\"device\": \"cuda:0\"})\n",
      "     |          booster.inplace_predict(cupy_array)\n",
      "     |      \n",
      "     |          booster.set_param({\"device\": \"cpu\"})\n",
      "     |          booster.inplace_predict(numpy_array)\n",
      "     |      \n",
      "     |      .. versionadded:: 1.1.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data :\n",
      "     |          The input data.\n",
      "     |      iteration_range :\n",
      "     |          See :py:meth:`predict` for details.\n",
      "     |      predict_type :\n",
      "     |          * `value` Output model prediction values.\n",
      "     |          * `margin` Output the raw untransformed margin value.\n",
      "     |      missing :\n",
      "     |          See :py:obj:`xgboost.DMatrix` for details.\n",
      "     |      validate_features:\n",
      "     |          See :py:meth:`xgboost.Booster.predict` for details.\n",
      "     |      base_margin:\n",
      "     |          See :py:obj:`xgboost.DMatrix` for details.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      strict_shape:\n",
      "     |          See :py:meth:`xgboost.Booster.predict` for details.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : numpy.ndarray/cupy.ndarray\n",
      "     |          The prediction result.  When input data is on GPU, prediction result is\n",
      "     |          stored in a cupy array.\n",
      "     |  \n",
      "     |  load_config(self, config: str) -> None\n",
      "     |      Load configuration returned by `save_config`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.0.0\n",
      "     |  \n",
      "     |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      "     |      Load the model from a file or a bytearray.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.load_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.load_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Input file name or memory buffer(see also save_raw)\n",
      "     |  \n",
      "     |  num_boosted_rounds(self) -> int\n",
      "     |      Get number of boosted rounds.  For gblinear this is reset to 0 after\n",
      "     |      serializing the model.\n",
      "     |  \n",
      "     |  num_features(self) -> int\n",
      "     |      Number of features in booster.\n",
      "     |  \n",
      "     |  predict(self, data: xgboost.core.DMatrix, output_margin: bool = False, pred_leaf: bool = False, pred_contribs: bool = False, approx_contribs: bool = False, pred_interactions: bool = False, validate_features: bool = True, training: bool = False, iteration_range: Tuple[Union[int, numpy.integer], Union[int, numpy.integer]] = (0, 0), strict_shape: bool = False) -> numpy.ndarray\n",
      "     |      Predict with data.  The full model will be used unless `iteration_range` is\n",
      "     |      specified, meaning user have to either slice the model or use the\n",
      "     |      ``best_iteration`` attribute to get prediction from best model returned from\n",
      "     |      early stopping.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |      \n",
      "     |          See :doc:`Prediction </prediction>` for issues like thread safety and a\n",
      "     |          summary of outputs from this function.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data :\n",
      "     |          The dmatrix storing the input.\n",
      "     |      \n",
      "     |      output_margin :\n",
      "     |          Whether to output the raw untransformed margin value.\n",
      "     |      \n",
      "     |      pred_leaf :\n",
      "     |          When this option is on, the output will be a matrix of (nsample,\n",
      "     |          ntrees) with each record indicating the predicted leaf index of\n",
      "     |          each sample in each tree.  Note that the leaf index of a tree is\n",
      "     |          unique per tree, so you may find leaf 1 in both tree 1 and tree 0.\n",
      "     |      \n",
      "     |      pred_contribs :\n",
      "     |          When this is True the output will be a matrix of size (nsample,\n",
      "     |          nfeats + 1) with each record indicating the feature contributions\n",
      "     |          (SHAP values) for that prediction. The sum of all feature\n",
      "     |          contributions is equal to the raw untransformed margin value of the\n",
      "     |          prediction. Note the final column is the bias term.\n",
      "     |      \n",
      "     |      approx_contribs :\n",
      "     |          Approximate the contributions of each feature.  Used when ``pred_contribs`` or\n",
      "     |          ``pred_interactions`` is set to True.  Changing the default of this parameter\n",
      "     |          (False) is not recommended.\n",
      "     |      \n",
      "     |      pred_interactions :\n",
      "     |          When this is True the output will be a matrix of size (nsample,\n",
      "     |          nfeats + 1, nfeats + 1) indicating the SHAP interaction values for\n",
      "     |          each pair of features. The sum of each row (or column) of the\n",
      "     |          interaction values equals the corresponding SHAP value (from\n",
      "     |          pred_contribs), and the sum of the entire matrix equals the raw\n",
      "     |          untransformed margin value of the prediction. Note the last row and\n",
      "     |          column correspond to the bias term.\n",
      "     |      \n",
      "     |      validate_features :\n",
      "     |          When this is True, validate that the Booster's and data's\n",
      "     |          feature_names are identical.  Otherwise, it is assumed that the\n",
      "     |          feature_names are the same.\n",
      "     |      \n",
      "     |      training :\n",
      "     |          Whether the prediction value is used for training.  This can effect `dart`\n",
      "     |          booster, which performs dropouts during training iterations but use all trees\n",
      "     |          for inference. If you want to obtain result with dropouts, set this parameter\n",
      "     |          to `True`.  Also, the parameter is set to true when obtaining prediction for\n",
      "     |          custom objective function.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.0.0\n",
      "     |      \n",
      "     |      iteration_range :\n",
      "     |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      "     |          random forest is trained with 100 rounds.  Specifying `iteration_range=(10,\n",
      "     |          20)`, then only the forests built during [10, 20) (half open set) rounds are\n",
      "     |          used in this prediction.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      strict_shape :\n",
      "     |          When set to True, output shape is invariant to whether classification is used.\n",
      "     |          For both value and margin prediction, the output shape is (n_samples,\n",
      "     |          n_groups), n_groups == 1 when multi-class is not used.  Default to False, in\n",
      "     |          which case the output shape can be (n_samples, ) if multi-class is not used.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction : numpy array\n",
      "     |  \n",
      "     |  save_config(self) -> str\n",
      "     |      Output internal parameter configuration of Booster as a JSON\n",
      "     |      string.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.0.0\n",
      "     |  \n",
      "     |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.save_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.save_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Output file name\n",
      "     |  \n",
      "     |  save_raw(self, raw_format: str = 'ubj') -> bytearray\n",
      "     |      Save the model to a in memory buffer representation instead of file.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      raw_format :\n",
      "     |          Format of output buffer. Can be `json`, `ubj` or `deprecated`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      An in memory buffer representation of the model\n",
      "     |  \n",
      "     |  set_attr(self, **kwargs: Optional[Any]) -> None\n",
      "     |      Set the attribute of the Booster.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **kwargs\n",
      "     |          The attributes to set. Setting a value to None deletes an attribute.\n",
      "     |  \n",
      "     |  set_param(self, params: Union[Dict, Iterable[Tuple[str, Any]], str], value: Optional[str] = None) -> None\n",
      "     |      Set parameters into the Booster.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      params :\n",
      "     |         list of key,value pairs, dict of key to value or simply str key\n",
      "     |      value :\n",
      "     |         value of the specified parameter, when params is str key\n",
      "     |  \n",
      "     |  trees_to_dataframe(self, fmap: Union[str, os.PathLike] = '') -> pandas.core.frame.DataFrame\n",
      "     |      Parse a boosted tree model text dump into a pandas DataFrame structure.\n",
      "     |      \n",
      "     |      This feature is only defined when the decision tree model is chosen as base\n",
      "     |      learner (`booster in {gbtree, dart}`). It is not defined for other base learner\n",
      "     |      types, such as linear learners (`booster=gblinear`).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fmap :\n",
      "     |         The name of feature map file.\n",
      "     |  \n",
      "     |  update(self, dtrain: xgboost.core.DMatrix, iteration: int, fobj: Optional[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[numpy.ndarray, numpy.ndarray]]] = None) -> None\n",
      "     |      Update for one iteration, with objective function calculated\n",
      "     |      internally.  This function should not be called directly by users.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dtrain :\n",
      "     |          Training data.\n",
      "     |      iteration :\n",
      "     |          Current iteration number.\n",
      "     |      fobj :\n",
      "     |          Customized objective function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  best_iteration\n",
      "     |      The best iteration during training.\n",
      "     |  \n",
      "     |  best_score\n",
      "     |      The best evaluation score during training.\n",
      "     |  \n",
      "     |  feature_names\n",
      "     |      Feature names for this booster.  Can be directly set by input data or by\n",
      "     |      assignment.\n",
      "     |  \n",
      "     |  feature_types\n",
      "     |      Feature types for this booster.  Can be directly set by input data or by\n",
      "     |      assignment.  See :py:class:`DMatrix` for details.\n",
      "    \n",
      "    class DMatrix(builtins.object)\n",
      "     |  DMatrix(data: Any, label: Optional[Any] = None, *, weight: Optional[Any] = None, base_margin: Optional[Any] = None, missing: Optional[float] = None, silent: bool = False, feature_names: Optional[Sequence[str]] = None, feature_types: Optional[Sequence[str]] = None, nthread: Optional[int] = None, group: Optional[Any] = None, qid: Optional[Any] = None, label_lower_bound: Optional[Any] = None, label_upper_bound: Optional[Any] = None, feature_weights: Optional[Any] = None, enable_categorical: bool = False, data_split_mode: xgboost.core.DataSplitMode = <DataSplitMode.ROW: 0>) -> None\n",
      "     |  \n",
      "     |  Data Matrix used in XGBoost.\n",
      "     |  \n",
      "     |  DMatrix is an internal data structure that is used by XGBoost, which is optimized\n",
      "     |  for both memory efficiency and training speed.  You can construct DMatrix from\n",
      "     |  multiple different sources of data.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __del__(self) -> None\n",
      "     |  \n",
      "     |  __init__(self, data: Any, label: Optional[Any] = None, *, weight: Optional[Any] = None, base_margin: Optional[Any] = None, missing: Optional[float] = None, silent: bool = False, feature_names: Optional[Sequence[str]] = None, feature_types: Optional[Sequence[str]] = None, nthread: Optional[int] = None, group: Optional[Any] = None, qid: Optional[Any] = None, label_lower_bound: Optional[Any] = None, label_upper_bound: Optional[Any] = None, feature_weights: Optional[Any] = None, enable_categorical: bool = False, data_split_mode: xgboost.core.DataSplitMode = <DataSplitMode.ROW: 0>) -> None\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data :\n",
      "     |          Data source of DMatrix. See :ref:`py-data` for a list of supported input\n",
      "     |          types.\n",
      "     |      label :\n",
      "     |          Label of the training data.\n",
      "     |      weight :\n",
      "     |          Weight for each instance.\n",
      "     |      \n",
      "     |           .. note::\n",
      "     |      \n",
      "     |               For ranking task, weights are per-group.  In ranking task, one weight\n",
      "     |               is assigned to each group (not each data point). This is because we\n",
      "     |               only care about the relative ordering of data points within each group,\n",
      "     |               so it doesn't make sense to assign weights to individual data points.\n",
      "     |      \n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      missing :\n",
      "     |          Value in the input data which needs to be present as a missing value. If\n",
      "     |          None, defaults to np.nan.\n",
      "     |      silent :\n",
      "     |          Whether print messages during construction\n",
      "     |      feature_names :\n",
      "     |          Set names for features.\n",
      "     |      feature_types :\n",
      "     |      \n",
      "     |          Set types for features. If `data` is a DataFrame type and passing\n",
      "     |          `enable_categorical=True`, the types will be deduced automatically\n",
      "     |          from the column types.\n",
      "     |      \n",
      "     |          Otherwise, one can pass a list-like input with the same length as number\n",
      "     |          of columns in `data`, with the following possible values:\n",
      "     |      \n",
      "     |          - \"c\", which represents categorical columns.\n",
      "     |          - \"q\", which represents numeric columns.\n",
      "     |          - \"int\", which represents integer columns.\n",
      "     |          - \"i\", which represents boolean columns.\n",
      "     |      \n",
      "     |          Note that, while categorical types are treated differently from\n",
      "     |          the rest for model fitting purposes, the other types do not influence\n",
      "     |          the generated model, but have effects in other functionalities such as\n",
      "     |          feature importances.\n",
      "     |      \n",
      "     |          For categorical features, the input is assumed to be preprocessed and\n",
      "     |          encoded by the users. The encoding can be done via\n",
      "     |          :py:class:`sklearn.preprocessing.OrdinalEncoder` or pandas dataframe\n",
      "     |          `.cat.codes` method. This is useful when users want to specify categorical\n",
      "     |          features without having to construct a dataframe as input.\n",
      "     |      \n",
      "     |      nthread :\n",
      "     |          Number of threads to use for loading data when parallelization is\n",
      "     |          applicable. If -1, uses maximum threads available on the system.\n",
      "     |      group :\n",
      "     |          Group size for all ranking group.\n",
      "     |      qid :\n",
      "     |          Query ID for data samples, used for ranking.\n",
      "     |      label_lower_bound :\n",
      "     |          Lower bound for survival training.\n",
      "     |      label_upper_bound :\n",
      "     |          Upper bound for survival training.\n",
      "     |      feature_weights :\n",
      "     |          Set feature weights for column sampling.\n",
      "     |      enable_categorical :\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3.0\n",
      "     |      \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |      \n",
      "     |          Experimental support of specializing for categorical features.\n",
      "     |      \n",
      "     |          If passing 'True' and 'data' is a data frame (from supported libraries such\n",
      "     |          as Pandas, Modin or cuDF), columns of categorical types will automatically\n",
      "     |          be set to be of categorical type (feature_type='c') in the resulting\n",
      "     |          DMatrix.\n",
      "     |      \n",
      "     |          If passing 'False' and 'data' is a data frame with categorical columns,\n",
      "     |          it will result in an error being thrown.\n",
      "     |      \n",
      "     |          If 'data' is not a data frame, this argument is ignored.\n",
      "     |      \n",
      "     |          JSON/UBJSON serialization format is required for this.\n",
      "     |  \n",
      "     |  data_split_mode(self) -> xgboost.core.DataSplitMode\n",
      "     |      Get the data split mode of the DMatrix.\n",
      "     |      \n",
      "     |      .. versionadded:: 2.1.0\n",
      "     |  \n",
      "     |  get_base_margin(self) -> numpy.ndarray\n",
      "     |      Get the base margin of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      base_margin\n",
      "     |  \n",
      "     |  get_data(self) -> scipy.sparse._csr.csr_matrix\n",
      "     |      Get the predictors from DMatrix as a CSR matrix. This getter is mostly for\n",
      "     |      testing purposes. If this is a quantized DMatrix then quantized values are\n",
      "     |      returned instead of input values.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |  get_float_info(self, field: str) -> numpy.ndarray\n",
      "     |      Get float property from the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      info : array\n",
      "     |          a numpy array of float information of the data\n",
      "     |  \n",
      "     |  get_group(self) -> numpy.ndarray\n",
      "     |      Get the group of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      group\n",
      "     |  \n",
      "     |  get_label(self) -> numpy.ndarray\n",
      "     |      Get the label of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      label : array\n",
      "     |  \n",
      "     |  get_quantile_cut(self) -> Tuple[numpy.ndarray, numpy.ndarray]\n",
      "     |      Get quantile cuts for quantization.\n",
      "     |      \n",
      "     |      .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |  get_uint_info(self, field: str) -> numpy.ndarray\n",
      "     |      Get unsigned integer property from the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      info : array\n",
      "     |          a numpy array of unsigned integer information of the data\n",
      "     |  \n",
      "     |  get_weight(self) -> numpy.ndarray\n",
      "     |      Get the weight of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      weight : array\n",
      "     |  \n",
      "     |  num_col(self) -> int\n",
      "     |      Get the number of columns (features) in the DMatrix.\n",
      "     |  \n",
      "     |  num_nonmissing(self) -> int\n",
      "     |      Get the number of non-missing values in the DMatrix.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |  num_row(self) -> int\n",
      "     |      Get the number of rows in the DMatrix.\n",
      "     |  \n",
      "     |  save_binary(self, fname: Union[str, os.PathLike], silent: bool = True) -> None\n",
      "     |      Save DMatrix to an XGBoost buffer.  Saved binary can be later loaded\n",
      "     |      by providing the path to :py:func:`xgboost.DMatrix` as input.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string or os.PathLike\n",
      "     |          Name of the output buffer file.\n",
      "     |      silent : bool (optional; default: True)\n",
      "     |          If set, the output is suppressed.\n",
      "     |  \n",
      "     |  set_base_margin(self, margin: Any) -> None\n",
      "     |      Set base margin of booster to start from.\n",
      "     |      \n",
      "     |      This can be used to specify a prediction value of existing model to be\n",
      "     |      base_margin However, remember margin is needed, instead of transformed\n",
      "     |      prediction e.g. for logistic regression: need to put in value before\n",
      "     |      logistic transformation see also example/demo.py\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      margin: array like\n",
      "     |          Prediction margin of each datapoint\n",
      "     |  \n",
      "     |  set_float_info(self, field: str, data: Any) -> None\n",
      "     |      Set float type property into the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      data: numpy array\n",
      "     |          The array of data to be set\n",
      "     |  \n",
      "     |  set_float_info_npy2d(self, field: str, data: Any) -> None\n",
      "     |      Set float type property into the DMatrix\n",
      "     |         for numpy 2d array input\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      data: numpy array\n",
      "     |          The array of data to be set\n",
      "     |  \n",
      "     |  set_group(self, group: Any) -> None\n",
      "     |      Set group size of DMatrix (used for ranking).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      group : array like\n",
      "     |          Group size of each group\n",
      "     |  \n",
      "     |  set_info(self, *, label: Optional[Any] = None, weight: Optional[Any] = None, base_margin: Optional[Any] = None, group: Optional[Any] = None, qid: Optional[Any] = None, label_lower_bound: Optional[Any] = None, label_upper_bound: Optional[Any] = None, feature_names: Optional[Sequence[str]] = None, feature_types: Optional[Sequence[str]] = None, feature_weights: Optional[Any] = None) -> None\n",
      "     |      Set meta info for DMatrix.  See doc string for :py:obj:`xgboost.DMatrix`.\n",
      "     |  \n",
      "     |  set_label(self, label: Any) -> None\n",
      "     |      Set label of dmatrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      label: array like\n",
      "     |          The label information to be set into DMatrix\n",
      "     |  \n",
      "     |  set_uint_info(self, field: str, data: Any) -> None\n",
      "     |      Set uint type property into the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      data: numpy array\n",
      "     |          The array of data to be set\n",
      "     |  \n",
      "     |  set_weight(self, weight: Any) -> None\n",
      "     |      Set weight of each instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      weight : array like\n",
      "     |          Weight for each data point\n",
      "     |      \n",
      "     |          .. note:: For ranking task, weights are per-group.\n",
      "     |      \n",
      "     |              In ranking task, one weight is assigned to each group (not each\n",
      "     |              data point). This is because we only care about the relative\n",
      "     |              ordering of data points within each group, so it doesn't make\n",
      "     |              sense to assign weights to individual data points.\n",
      "     |  \n",
      "     |  slice(self, rindex: Union[List[int], numpy.ndarray], allow_groups: bool = False) -> 'DMatrix'\n",
      "     |      Slice the DMatrix and return a new DMatrix that only contains `rindex`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rindex\n",
      "     |          List of indices to be selected.\n",
      "     |      allow_groups\n",
      "     |          Allow slicing of a matrix with a groups attribute\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res\n",
      "     |          A new DMatrix containing only selected indices.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  feature_names\n",
      "     |      Labels for features (column labels).\n",
      "     |      \n",
      "     |      Setting it to ``None`` resets existing feature names.\n",
      "     |  \n",
      "     |  feature_types\n",
      "     |      Type of features (column types).\n",
      "     |      \n",
      "     |      This is for displaying the results and categorical data support. See\n",
      "     |      :py:class:`DMatrix` for details.\n",
      "     |      \n",
      "     |      Setting it to ``None`` resets existing feature types.\n",
      "    \n",
      "    class DataIter(abc.ABC)\n",
      "     |  DataIter(cache_prefix: Optional[str] = None, release_data: bool = True) -> None\n",
      "     |  \n",
      "     |  The interface for user defined data iterator. The iterator facilitates\n",
      "     |  distributed training, :py:class:`QuantileDMatrix`, and external memory support using\n",
      "     |  :py:class:`DMatrix`. Most of time, users don't need to interact with this class\n",
      "     |  directly.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      The class caches some intermediate results using the `data` input (predictor\n",
      "     |      `X`) as key. Don't repeat the `X` for multiple batches with different meta data\n",
      "     |      (like `label`), make a copy if necessary.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  cache_prefix :\n",
      "     |      Prefix to the cache files, only used in external memory.\n",
      "     |  release_data :\n",
      "     |      Whether the iterator should release the data during iteration. Set it to True if\n",
      "     |      the data transformation (converting data to np.float32 type) is memory\n",
      "     |      intensive. Otherwise, if the transformation is computation intensive then we can\n",
      "     |      keep the cache.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DataIter\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __del__(self) -> None\n",
      "     |  \n",
      "     |  __init__(self, cache_prefix: Optional[str] = None, release_data: bool = True) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_callbacks(self, enable_categorical: bool) -> Tuple[Callable, Callable]\n",
      "     |      Get callback functions for iterating in C. This is an internal function.\n",
      "     |  \n",
      "     |  next(self, input_data: Callable) -> int\n",
      "     |      Set the next batch of data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      input_data:\n",
      "     |          A function with same data fields like `data`, `label` with\n",
      "     |          `xgboost.DMatrix`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      0 if there's no more batch, otherwise 1.\n",
      "     |  \n",
      "     |  reraise(self) -> None\n",
      "     |      Reraise the exception thrown during iteration.\n",
      "     |  \n",
      "     |  reset(self) -> None\n",
      "     |      Reset the data iterator.  Prototype for user defined function.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  proxy\n",
      "     |      Handle of DMatrix proxy.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'next', 'reset'})\n",
      "    \n",
      "    class DeviceQuantileDMatrix(QuantileDMatrix)\n",
      "     |  DeviceQuantileDMatrix(*args: Any, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  Use `QuantileDMatrix` instead.\n",
      "     |  \n",
      "     |  .. deprecated:: 1.7.0\n",
      "     |  \n",
      "     |  .. versionadded:: 1.1.0\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DeviceQuantileDMatrix\n",
      "     |      QuantileDMatrix\n",
      "     |      DMatrix\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *args: Any, **kwargs: Any) -> None\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data :\n",
      "     |          Data source of DMatrix. See :ref:`py-data` for a list of supported input\n",
      "     |          types.\n",
      "     |      label :\n",
      "     |          Label of the training data.\n",
      "     |      weight :\n",
      "     |          Weight for each instance.\n",
      "     |      \n",
      "     |           .. note::\n",
      "     |      \n",
      "     |               For ranking task, weights are per-group.  In ranking task, one weight\n",
      "     |               is assigned to each group (not each data point). This is because we\n",
      "     |               only care about the relative ordering of data points within each group,\n",
      "     |               so it doesn't make sense to assign weights to individual data points.\n",
      "     |      \n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      missing :\n",
      "     |          Value in the input data which needs to be present as a missing value. If\n",
      "     |          None, defaults to np.nan.\n",
      "     |      silent :\n",
      "     |          Whether print messages during construction\n",
      "     |      feature_names :\n",
      "     |          Set names for features.\n",
      "     |      feature_types :\n",
      "     |      \n",
      "     |          Set types for features. If `data` is a DataFrame type and passing\n",
      "     |          `enable_categorical=True`, the types will be deduced automatically\n",
      "     |          from the column types.\n",
      "     |      \n",
      "     |          Otherwise, one can pass a list-like input with the same length as number\n",
      "     |          of columns in `data`, with the following possible values:\n",
      "     |      \n",
      "     |          - \"c\", which represents categorical columns.\n",
      "     |          - \"q\", which represents numeric columns.\n",
      "     |          - \"int\", which represents integer columns.\n",
      "     |          - \"i\", which represents boolean columns.\n",
      "     |      \n",
      "     |          Note that, while categorical types are treated differently from\n",
      "     |          the rest for model fitting purposes, the other types do not influence\n",
      "     |          the generated model, but have effects in other functionalities such as\n",
      "     |          feature importances.\n",
      "     |      \n",
      "     |          For categorical features, the input is assumed to be preprocessed and\n",
      "     |          encoded by the users. The encoding can be done via\n",
      "     |          :py:class:`sklearn.preprocessing.OrdinalEncoder` or pandas dataframe\n",
      "     |          `.cat.codes` method. This is useful when users want to specify categorical\n",
      "     |          features without having to construct a dataframe as input.\n",
      "     |      \n",
      "     |      nthread :\n",
      "     |          Number of threads to use for loading data when parallelization is\n",
      "     |          applicable. If -1, uses maximum threads available on the system.\n",
      "     |      group :\n",
      "     |          Group size for all ranking group.\n",
      "     |      qid :\n",
      "     |          Query ID for data samples, used for ranking.\n",
      "     |      label_lower_bound :\n",
      "     |          Lower bound for survival training.\n",
      "     |      label_upper_bound :\n",
      "     |          Upper bound for survival training.\n",
      "     |      feature_weights :\n",
      "     |          Set feature weights for column sampling.\n",
      "     |      enable_categorical :\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3.0\n",
      "     |      \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |      \n",
      "     |          Experimental support of specializing for categorical features.\n",
      "     |      \n",
      "     |          If passing 'True' and 'data' is a data frame (from supported libraries such\n",
      "     |          as Pandas, Modin or cuDF), columns of categorical types will automatically\n",
      "     |          be set to be of categorical type (feature_type='c') in the resulting\n",
      "     |          DMatrix.\n",
      "     |      \n",
      "     |          If passing 'False' and 'data' is a data frame with categorical columns,\n",
      "     |          it will result in an error being thrown.\n",
      "     |      \n",
      "     |          If 'data' is not a data frame, this argument is ignored.\n",
      "     |      \n",
      "     |          JSON/UBJSON serialization format is required for this.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DMatrix:\n",
      "     |  \n",
      "     |  __del__(self) -> None\n",
      "     |  \n",
      "     |  data_split_mode(self) -> xgboost.core.DataSplitMode\n",
      "     |      Get the data split mode of the DMatrix.\n",
      "     |      \n",
      "     |      .. versionadded:: 2.1.0\n",
      "     |  \n",
      "     |  get_base_margin(self) -> numpy.ndarray\n",
      "     |      Get the base margin of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      base_margin\n",
      "     |  \n",
      "     |  get_data(self) -> scipy.sparse._csr.csr_matrix\n",
      "     |      Get the predictors from DMatrix as a CSR matrix. This getter is mostly for\n",
      "     |      testing purposes. If this is a quantized DMatrix then quantized values are\n",
      "     |      returned instead of input values.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |  get_float_info(self, field: str) -> numpy.ndarray\n",
      "     |      Get float property from the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      info : array\n",
      "     |          a numpy array of float information of the data\n",
      "     |  \n",
      "     |  get_group(self) -> numpy.ndarray\n",
      "     |      Get the group of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      group\n",
      "     |  \n",
      "     |  get_label(self) -> numpy.ndarray\n",
      "     |      Get the label of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      label : array\n",
      "     |  \n",
      "     |  get_quantile_cut(self) -> Tuple[numpy.ndarray, numpy.ndarray]\n",
      "     |      Get quantile cuts for quantization.\n",
      "     |      \n",
      "     |      .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |  get_uint_info(self, field: str) -> numpy.ndarray\n",
      "     |      Get unsigned integer property from the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      info : array\n",
      "     |          a numpy array of unsigned integer information of the data\n",
      "     |  \n",
      "     |  get_weight(self) -> numpy.ndarray\n",
      "     |      Get the weight of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      weight : array\n",
      "     |  \n",
      "     |  num_col(self) -> int\n",
      "     |      Get the number of columns (features) in the DMatrix.\n",
      "     |  \n",
      "     |  num_nonmissing(self) -> int\n",
      "     |      Get the number of non-missing values in the DMatrix.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |  num_row(self) -> int\n",
      "     |      Get the number of rows in the DMatrix.\n",
      "     |  \n",
      "     |  save_binary(self, fname: Union[str, os.PathLike], silent: bool = True) -> None\n",
      "     |      Save DMatrix to an XGBoost buffer.  Saved binary can be later loaded\n",
      "     |      by providing the path to :py:func:`xgboost.DMatrix` as input.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string or os.PathLike\n",
      "     |          Name of the output buffer file.\n",
      "     |      silent : bool (optional; default: True)\n",
      "     |          If set, the output is suppressed.\n",
      "     |  \n",
      "     |  set_base_margin(self, margin: Any) -> None\n",
      "     |      Set base margin of booster to start from.\n",
      "     |      \n",
      "     |      This can be used to specify a prediction value of existing model to be\n",
      "     |      base_margin However, remember margin is needed, instead of transformed\n",
      "     |      prediction e.g. for logistic regression: need to put in value before\n",
      "     |      logistic transformation see also example/demo.py\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      margin: array like\n",
      "     |          Prediction margin of each datapoint\n",
      "     |  \n",
      "     |  set_float_info(self, field: str, data: Any) -> None\n",
      "     |      Set float type property into the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      data: numpy array\n",
      "     |          The array of data to be set\n",
      "     |  \n",
      "     |  set_float_info_npy2d(self, field: str, data: Any) -> None\n",
      "     |      Set float type property into the DMatrix\n",
      "     |         for numpy 2d array input\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      data: numpy array\n",
      "     |          The array of data to be set\n",
      "     |  \n",
      "     |  set_group(self, group: Any) -> None\n",
      "     |      Set group size of DMatrix (used for ranking).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      group : array like\n",
      "     |          Group size of each group\n",
      "     |  \n",
      "     |  set_info(self, *, label: Optional[Any] = None, weight: Optional[Any] = None, base_margin: Optional[Any] = None, group: Optional[Any] = None, qid: Optional[Any] = None, label_lower_bound: Optional[Any] = None, label_upper_bound: Optional[Any] = None, feature_names: Optional[Sequence[str]] = None, feature_types: Optional[Sequence[str]] = None, feature_weights: Optional[Any] = None) -> None\n",
      "     |      Set meta info for DMatrix.  See doc string for :py:obj:`xgboost.DMatrix`.\n",
      "     |  \n",
      "     |  set_label(self, label: Any) -> None\n",
      "     |      Set label of dmatrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      label: array like\n",
      "     |          The label information to be set into DMatrix\n",
      "     |  \n",
      "     |  set_uint_info(self, field: str, data: Any) -> None\n",
      "     |      Set uint type property into the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      data: numpy array\n",
      "     |          The array of data to be set\n",
      "     |  \n",
      "     |  set_weight(self, weight: Any) -> None\n",
      "     |      Set weight of each instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      weight : array like\n",
      "     |          Weight for each data point\n",
      "     |      \n",
      "     |          .. note:: For ranking task, weights are per-group.\n",
      "     |      \n",
      "     |              In ranking task, one weight is assigned to each group (not each\n",
      "     |              data point). This is because we only care about the relative\n",
      "     |              ordering of data points within each group, so it doesn't make\n",
      "     |              sense to assign weights to individual data points.\n",
      "     |  \n",
      "     |  slice(self, rindex: Union[List[int], numpy.ndarray], allow_groups: bool = False) -> 'DMatrix'\n",
      "     |      Slice the DMatrix and return a new DMatrix that only contains `rindex`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rindex\n",
      "     |          List of indices to be selected.\n",
      "     |      allow_groups\n",
      "     |          Allow slicing of a matrix with a groups attribute\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res\n",
      "     |          A new DMatrix containing only selected indices.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from DMatrix:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  feature_names\n",
      "     |      Labels for features (column labels).\n",
      "     |      \n",
      "     |      Setting it to ``None`` resets existing feature names.\n",
      "     |  \n",
      "     |  feature_types\n",
      "     |      Type of features (column types).\n",
      "     |      \n",
      "     |      This is for displaying the results and categorical data support. See\n",
      "     |      :py:class:`DMatrix` for details.\n",
      "     |      \n",
      "     |      Setting it to ``None`` resets existing feature types.\n",
      "    \n",
      "    class QuantileDMatrix(DMatrix)\n",
      "     |  QuantileDMatrix(data: Any, label: Optional[Any] = None, *, weight: Optional[Any] = None, base_margin: Optional[Any] = None, missing: Optional[float] = None, silent: bool = False, feature_names: Optional[Sequence[str]] = None, feature_types: Optional[Sequence[str]] = None, nthread: Optional[int] = None, max_bin: Optional[int] = None, ref: Optional[xgboost.core.DMatrix] = None, group: Optional[Any] = None, qid: Optional[Any] = None, label_lower_bound: Optional[Any] = None, label_upper_bound: Optional[Any] = None, feature_weights: Optional[Any] = None, enable_categorical: bool = False, data_split_mode: xgboost.core.DataSplitMode = <DataSplitMode.ROW: 0>) -> None\n",
      "     |  \n",
      "     |  A DMatrix variant that generates quantilized data directly from input for the\n",
      "     |  ``hist`` tree method. This DMatrix is primarily designed to save memory in training\n",
      "     |  by avoiding intermediate storage. Set ``max_bin`` to control the number of bins\n",
      "     |  during quantisation, which should be consistent with the training parameter\n",
      "     |  ``max_bin``. When ``QuantileDMatrix`` is used for validation/test dataset, ``ref``\n",
      "     |  should be another ``QuantileDMatrix``(or ``DMatrix``, but not recommended as it\n",
      "     |  defeats the purpose of saving memory) constructed from training dataset.  See\n",
      "     |  :py:obj:`xgboost.DMatrix` for documents on meta info.\n",
      "     |  \n",
      "     |  .. note::\n",
      "     |  \n",
      "     |      Do not use ``QuantileDMatrix`` as validation/test dataset without supplying a\n",
      "     |      reference (the training dataset) ``QuantileDMatrix`` using ``ref`` as some\n",
      "     |      information may be lost in quantisation.\n",
      "     |  \n",
      "     |  .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  max_bin :\n",
      "     |      The number of histogram bin, should be consistent with the training parameter\n",
      "     |      ``max_bin``.\n",
      "     |  \n",
      "     |  ref :\n",
      "     |      The training dataset that provides quantile information, needed when creating\n",
      "     |      validation/test dataset with ``QuantileDMatrix``. Supplying the training DMatrix\n",
      "     |      as a reference means that the same quantisation applied to the training data is\n",
      "     |      applied to the validation/test data\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QuantileDMatrix\n",
      "     |      DMatrix\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, data: Any, label: Optional[Any] = None, *, weight: Optional[Any] = None, base_margin: Optional[Any] = None, missing: Optional[float] = None, silent: bool = False, feature_names: Optional[Sequence[str]] = None, feature_types: Optional[Sequence[str]] = None, nthread: Optional[int] = None, max_bin: Optional[int] = None, ref: Optional[xgboost.core.DMatrix] = None, group: Optional[Any] = None, qid: Optional[Any] = None, label_lower_bound: Optional[Any] = None, label_upper_bound: Optional[Any] = None, feature_weights: Optional[Any] = None, enable_categorical: bool = False, data_split_mode: xgboost.core.DataSplitMode = <DataSplitMode.ROW: 0>) -> None\n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data :\n",
      "     |          Data source of DMatrix. See :ref:`py-data` for a list of supported input\n",
      "     |          types.\n",
      "     |      label :\n",
      "     |          Label of the training data.\n",
      "     |      weight :\n",
      "     |          Weight for each instance.\n",
      "     |      \n",
      "     |           .. note::\n",
      "     |      \n",
      "     |               For ranking task, weights are per-group.  In ranking task, one weight\n",
      "     |               is assigned to each group (not each data point). This is because we\n",
      "     |               only care about the relative ordering of data points within each group,\n",
      "     |               so it doesn't make sense to assign weights to individual data points.\n",
      "     |      \n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      missing :\n",
      "     |          Value in the input data which needs to be present as a missing value. If\n",
      "     |          None, defaults to np.nan.\n",
      "     |      silent :\n",
      "     |          Whether print messages during construction\n",
      "     |      feature_names :\n",
      "     |          Set names for features.\n",
      "     |      feature_types :\n",
      "     |      \n",
      "     |          Set types for features. If `data` is a DataFrame type and passing\n",
      "     |          `enable_categorical=True`, the types will be deduced automatically\n",
      "     |          from the column types.\n",
      "     |      \n",
      "     |          Otherwise, one can pass a list-like input with the same length as number\n",
      "     |          of columns in `data`, with the following possible values:\n",
      "     |      \n",
      "     |          - \"c\", which represents categorical columns.\n",
      "     |          - \"q\", which represents numeric columns.\n",
      "     |          - \"int\", which represents integer columns.\n",
      "     |          - \"i\", which represents boolean columns.\n",
      "     |      \n",
      "     |          Note that, while categorical types are treated differently from\n",
      "     |          the rest for model fitting purposes, the other types do not influence\n",
      "     |          the generated model, but have effects in other functionalities such as\n",
      "     |          feature importances.\n",
      "     |      \n",
      "     |          For categorical features, the input is assumed to be preprocessed and\n",
      "     |          encoded by the users. The encoding can be done via\n",
      "     |          :py:class:`sklearn.preprocessing.OrdinalEncoder` or pandas dataframe\n",
      "     |          `.cat.codes` method. This is useful when users want to specify categorical\n",
      "     |          features without having to construct a dataframe as input.\n",
      "     |      \n",
      "     |      nthread :\n",
      "     |          Number of threads to use for loading data when parallelization is\n",
      "     |          applicable. If -1, uses maximum threads available on the system.\n",
      "     |      group :\n",
      "     |          Group size for all ranking group.\n",
      "     |      qid :\n",
      "     |          Query ID for data samples, used for ranking.\n",
      "     |      label_lower_bound :\n",
      "     |          Lower bound for survival training.\n",
      "     |      label_upper_bound :\n",
      "     |          Upper bound for survival training.\n",
      "     |      feature_weights :\n",
      "     |          Set feature weights for column sampling.\n",
      "     |      enable_categorical :\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3.0\n",
      "     |      \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |      \n",
      "     |          Experimental support of specializing for categorical features.\n",
      "     |      \n",
      "     |          If passing 'True' and 'data' is a data frame (from supported libraries such\n",
      "     |          as Pandas, Modin or cuDF), columns of categorical types will automatically\n",
      "     |          be set to be of categorical type (feature_type='c') in the resulting\n",
      "     |          DMatrix.\n",
      "     |      \n",
      "     |          If passing 'False' and 'data' is a data frame with categorical columns,\n",
      "     |          it will result in an error being thrown.\n",
      "     |      \n",
      "     |          If 'data' is not a data frame, this argument is ignored.\n",
      "     |      \n",
      "     |          JSON/UBJSON serialization format is required for this.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from DMatrix:\n",
      "     |  \n",
      "     |  __del__(self) -> None\n",
      "     |  \n",
      "     |  data_split_mode(self) -> xgboost.core.DataSplitMode\n",
      "     |      Get the data split mode of the DMatrix.\n",
      "     |      \n",
      "     |      .. versionadded:: 2.1.0\n",
      "     |  \n",
      "     |  get_base_margin(self) -> numpy.ndarray\n",
      "     |      Get the base margin of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      base_margin\n",
      "     |  \n",
      "     |  get_data(self) -> scipy.sparse._csr.csr_matrix\n",
      "     |      Get the predictors from DMatrix as a CSR matrix. This getter is mostly for\n",
      "     |      testing purposes. If this is a quantized DMatrix then quantized values are\n",
      "     |      returned instead of input values.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |  get_float_info(self, field: str) -> numpy.ndarray\n",
      "     |      Get float property from the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      info : array\n",
      "     |          a numpy array of float information of the data\n",
      "     |  \n",
      "     |  get_group(self) -> numpy.ndarray\n",
      "     |      Get the group of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      group\n",
      "     |  \n",
      "     |  get_label(self) -> numpy.ndarray\n",
      "     |      Get the label of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      label : array\n",
      "     |  \n",
      "     |  get_quantile_cut(self) -> Tuple[numpy.ndarray, numpy.ndarray]\n",
      "     |      Get quantile cuts for quantization.\n",
      "     |      \n",
      "     |      .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |  get_uint_info(self, field: str) -> numpy.ndarray\n",
      "     |      Get unsigned integer property from the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      info : array\n",
      "     |          a numpy array of unsigned integer information of the data\n",
      "     |  \n",
      "     |  get_weight(self) -> numpy.ndarray\n",
      "     |      Get the weight of the DMatrix.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      weight : array\n",
      "     |  \n",
      "     |  num_col(self) -> int\n",
      "     |      Get the number of columns (features) in the DMatrix.\n",
      "     |  \n",
      "     |  num_nonmissing(self) -> int\n",
      "     |      Get the number of non-missing values in the DMatrix.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |  num_row(self) -> int\n",
      "     |      Get the number of rows in the DMatrix.\n",
      "     |  \n",
      "     |  save_binary(self, fname: Union[str, os.PathLike], silent: bool = True) -> None\n",
      "     |      Save DMatrix to an XGBoost buffer.  Saved binary can be later loaded\n",
      "     |      by providing the path to :py:func:`xgboost.DMatrix` as input.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname : string or os.PathLike\n",
      "     |          Name of the output buffer file.\n",
      "     |      silent : bool (optional; default: True)\n",
      "     |          If set, the output is suppressed.\n",
      "     |  \n",
      "     |  set_base_margin(self, margin: Any) -> None\n",
      "     |      Set base margin of booster to start from.\n",
      "     |      \n",
      "     |      This can be used to specify a prediction value of existing model to be\n",
      "     |      base_margin However, remember margin is needed, instead of transformed\n",
      "     |      prediction e.g. for logistic regression: need to put in value before\n",
      "     |      logistic transformation see also example/demo.py\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      margin: array like\n",
      "     |          Prediction margin of each datapoint\n",
      "     |  \n",
      "     |  set_float_info(self, field: str, data: Any) -> None\n",
      "     |      Set float type property into the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      data: numpy array\n",
      "     |          The array of data to be set\n",
      "     |  \n",
      "     |  set_float_info_npy2d(self, field: str, data: Any) -> None\n",
      "     |      Set float type property into the DMatrix\n",
      "     |         for numpy 2d array input\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      data: numpy array\n",
      "     |          The array of data to be set\n",
      "     |  \n",
      "     |  set_group(self, group: Any) -> None\n",
      "     |      Set group size of DMatrix (used for ranking).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      group : array like\n",
      "     |          Group size of each group\n",
      "     |  \n",
      "     |  set_info(self, *, label: Optional[Any] = None, weight: Optional[Any] = None, base_margin: Optional[Any] = None, group: Optional[Any] = None, qid: Optional[Any] = None, label_lower_bound: Optional[Any] = None, label_upper_bound: Optional[Any] = None, feature_names: Optional[Sequence[str]] = None, feature_types: Optional[Sequence[str]] = None, feature_weights: Optional[Any] = None) -> None\n",
      "     |      Set meta info for DMatrix.  See doc string for :py:obj:`xgboost.DMatrix`.\n",
      "     |  \n",
      "     |  set_label(self, label: Any) -> None\n",
      "     |      Set label of dmatrix\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      label: array like\n",
      "     |          The label information to be set into DMatrix\n",
      "     |  \n",
      "     |  set_uint_info(self, field: str, data: Any) -> None\n",
      "     |      Set uint type property into the DMatrix.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      field: str\n",
      "     |          The field name of the information\n",
      "     |      \n",
      "     |      data: numpy array\n",
      "     |          The array of data to be set\n",
      "     |  \n",
      "     |  set_weight(self, weight: Any) -> None\n",
      "     |      Set weight of each instance.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      weight : array like\n",
      "     |          Weight for each data point\n",
      "     |      \n",
      "     |          .. note:: For ranking task, weights are per-group.\n",
      "     |      \n",
      "     |              In ranking task, one weight is assigned to each group (not each\n",
      "     |              data point). This is because we only care about the relative\n",
      "     |              ordering of data points within each group, so it doesn't make\n",
      "     |              sense to assign weights to individual data points.\n",
      "     |  \n",
      "     |  slice(self, rindex: Union[List[int], numpy.ndarray], allow_groups: bool = False) -> 'DMatrix'\n",
      "     |      Slice the DMatrix and return a new DMatrix that only contains `rindex`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      rindex\n",
      "     |          List of indices to be selected.\n",
      "     |      allow_groups\n",
      "     |          Allow slicing of a matrix with a groups attribute\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      res\n",
      "     |          A new DMatrix containing only selected indices.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from DMatrix:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  feature_names\n",
      "     |      Labels for features (column labels).\n",
      "     |      \n",
      "     |      Setting it to ``None`` resets existing feature names.\n",
      "     |  \n",
      "     |  feature_types\n",
      "     |      Type of features (column types).\n",
      "     |      \n",
      "     |      This is for displaying the results and categorical data support. See\n",
      "     |      :py:class:`DMatrix` for details.\n",
      "     |      \n",
      "     |      Setting it to ``None`` resets existing feature types.\n",
      "    \n",
      "    class RabitTracker(builtins.object)\n",
      "     |  RabitTracker(n_workers: int, host_ip: Optional[str], port: int = 0, sortby: str = 'host', timeout: int = 0) -> None\n",
      "     |  \n",
      "     |  Tracker for the collective used in XGBoost, acting as a coordinator between\n",
      "     |  workers.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ..........\n",
      "     |  sortby:\n",
      "     |  \n",
      "     |      How to sort the workers for rank assignment. The default is host, but users can\n",
      "     |      set the `DMLC_TASK_ID` via RABIT initialization arguments and obtain\n",
      "     |      deterministic rank assignment. Available options are:\n",
      "     |        - host\n",
      "     |        - task\n",
      "     |  \n",
      "     |  timeout :\n",
      "     |  \n",
      "     |      Timeout for constructing the communication group and waiting for the tracker to\n",
      "     |      shutdown when it's instructed to, doesn't apply to communication when tracking\n",
      "     |      is running.\n",
      "     |  \n",
      "     |      The timeout value should take the time of data loading and pre-processing into\n",
      "     |      account, due to potential lazy execution.\n",
      "     |  \n",
      "     |      The :py:meth:`.wait_for` method has a different timeout parameter that can stop\n",
      "     |      the tracker even if the tracker is still being used. A value error is raised\n",
      "     |      when timeout is reached.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __del__(self) -> None\n",
      "     |  \n",
      "     |  __init__(self, n_workers: int, host_ip: Optional[str], port: int = 0, sortby: str = 'host', timeout: int = 0) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  free(self) -> None\n",
      "     |      Internal function for testing.\n",
      "     |  \n",
      "     |  start(self) -> None\n",
      "     |      Start the tracker. Once started, the client still need to call the\n",
      "     |      :py:meth:`wait_for` method in order to wait for it to finish (think of it as a\n",
      "     |      thread).\n",
      "     |  \n",
      "     |  wait_for(self, timeout: Optional[int] = None) -> None\n",
      "     |      Wait for the tracker to finish all the work and shutdown. When timeout is\n",
      "     |      reached, a value error is raised. By default we don't have timeout since we\n",
      "     |      don't know how long it takes for the model to finish training.\n",
      "     |  \n",
      "     |  worker_args(self) -> Dict[str, Union[str, int]]\n",
      "     |      Get arguments for workers.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class XGBClassifier(XGBModel, sklearn.base.ClassifierMixin)\n",
      "     |  XGBClassifier(*, objective: Union[str, xgboost.sklearn._SklObjWProto, Callable[[Any, Any], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  Implementation of the scikit-learn API for XGBoost classification.\n",
      "     |  See :doc:`/python/sklearn_estimator` for more information.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |      n_estimators : Optional[int]\n",
      "     |          Number of boosting rounds.\n",
      "     |  \n",
      "     |      max_depth :  typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum tree depth for base learners.\n",
      "     |  \n",
      "     |      max_leaves : typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum number of leaves; 0 indicates no limit.\n",
      "     |  \n",
      "     |      max_bin : typing.Optional[int]\n",
      "     |  \n",
      "     |          If using histogram-based algorithm, maximum number of bins per feature\n",
      "     |  \n",
      "     |      grow_policy : typing.Optional[str]\n",
      "     |  \n",
      "     |          Tree growing policy.\n",
      "     |  \n",
      "     |          - depthwise: Favors splitting at nodes closest to the node,\n",
      "     |          - lossguide: Favors splitting at nodes with highest loss change.\n",
      "     |  \n",
      "     |      learning_rate : typing.Optional[float]\n",
      "     |  \n",
      "     |          Boosting learning rate (xgb's \"eta\")\n",
      "     |  \n",
      "     |      verbosity : typing.Optional[int]\n",
      "     |  \n",
      "     |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      "     |  \n",
      "     |      objective : typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      "     |  \n",
      "     |          Specify the learning task and the corresponding learning objective or a custom\n",
      "     |          objective function to be used.\n",
      "     |  \n",
      "     |          For custom objective, see :doc:`/tutorials/custom_metric_obj` and\n",
      "     |          :ref:`custom-obj-metric` for more information, along with the end note for\n",
      "     |          function signatures.\n",
      "     |  \n",
      "     |      booster: typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which booster to use: ``gbtree``, ``gblinear`` or ``dart``.\n",
      "     |  \n",
      "     |      tree_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      "     |          default, XGBoost will choose the most conservative option available.  It's\n",
      "     |          recommended to study this option from the parameters document :doc:`tree method\n",
      "     |          </treemethod>`\n",
      "     |  \n",
      "     |      n_jobs : typing.Optional[int]\n",
      "     |  \n",
      "     |          Number of parallel threads used to run xgboost.  When used with other\n",
      "     |          Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      "     |          parallelize and balance the threads.  Creating thread contention will\n",
      "     |          significantly slow down both algorithms.\n",
      "     |  \n",
      "     |      gamma : typing.Optional[float]\n",
      "     |  \n",
      "     |          (min_split_loss) Minimum loss reduction required to make a further partition on\n",
      "     |          a leaf node of the tree.\n",
      "     |  \n",
      "     |      min_child_weight : typing.Optional[float]\n",
      "     |  \n",
      "     |          Minimum sum of instance weight(hessian) needed in a child.\n",
      "     |  \n",
      "     |      max_delta_step : typing.Optional[float]\n",
      "     |  \n",
      "     |          Maximum delta step we allow each tree's weight estimation to be.\n",
      "     |  \n",
      "     |      subsample : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of the training instance.\n",
      "     |  \n",
      "     |      sampling_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Sampling method. Used only by the GPU version of ``hist`` tree method.\n",
      "     |  \n",
      "     |          - ``uniform``: Select random training instances uniformly.\n",
      "     |          - ``gradient_based``: Select random training instances with higher probability\n",
      "     |              when the gradient and hessian are larger. (cf. CatBoost)\n",
      "     |  \n",
      "     |      colsample_bytree : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |  \n",
      "     |      colsample_bylevel : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each level.\n",
      "     |  \n",
      "     |      colsample_bynode : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each split.\n",
      "     |  \n",
      "     |      reg_alpha : typing.Optional[float]\n",
      "     |  \n",
      "     |          L1 regularization term on weights (xgb's alpha).\n",
      "     |  \n",
      "     |      reg_lambda : typing.Optional[float]\n",
      "     |  \n",
      "     |          L2 regularization term on weights (xgb's lambda).\n",
      "     |  \n",
      "     |      scale_pos_weight : typing.Optional[float]\n",
      "     |          Balancing of positive and negative weights.\n",
      "     |  \n",
      "     |      base_score : typing.Optional[float]\n",
      "     |  \n",
      "     |          The initial prediction score of all instances, global bias.\n",
      "     |  \n",
      "     |      random_state : typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]\n",
      "     |  \n",
      "     |          Random number seed.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      "     |             it uses Hogwild algorithm.\n",
      "     |  \n",
      "     |      missing : float\n",
      "     |  \n",
      "     |          Value in the data which needs to be present as a missing value. Default to\n",
      "     |          :py:data:`numpy.nan`.\n",
      "     |  \n",
      "     |      num_parallel_tree: typing.Optional[int]\n",
      "     |  \n",
      "     |          Used for boosting random forest.\n",
      "     |  \n",
      "     |      monotone_constraints : typing.Union[typing.Dict[str, int], str, NoneType]\n",
      "     |  \n",
      "     |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      "     |          for more information.\n",
      "     |  \n",
      "     |      interaction_constraints : typing.Union[str, typing.List[typing.Tuple[str]], NoneType]\n",
      "     |  \n",
      "     |          Constraints for interaction representing permitted interactions.  The\n",
      "     |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      "     |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      "     |          allowed to interact with each other.  See :doc:`tutorial\n",
      "     |          </tutorials/feature_interaction_constraint>` for more information\n",
      "     |  \n",
      "     |      importance_type: typing.Optional[str]\n",
      "     |  \n",
      "     |          The feature importance type for the feature_importances\\_ property:\n",
      "     |  \n",
      "     |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      "     |            \"total_cover\".\n",
      "     |          * For linear model, only \"weight\" is defined and it's the normalized\n",
      "     |            coefficients without bias.\n",
      "     |  \n",
      "     |      device : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          Device ordinal, available options are `cpu`, `cuda`, and `gpu`.\n",
      "     |  \n",
      "     |      validate_parameters : typing.Optional[bool]\n",
      "     |  \n",
      "     |          Give warnings for unknown parameter.\n",
      "     |  \n",
      "     |      enable_categorical : bool\n",
      "     |  \n",
      "     |          See the same parameter of :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      feature_types : typing.Optional[typing.Sequence[str]]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          Used for specifying feature types without constructing a dataframe. See\n",
      "     |          :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      max_cat_to_onehot : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      "     |          for categorical data.  When number of categories is lesser than the threshold\n",
      "     |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      "     |          into children nodes. Also, `enable_categorical` needs to be set to have\n",
      "     |          categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      max_cat_threshold : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          Maximum number of categories considered for each split. Used only by\n",
      "     |          partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      "     |          needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      multi_strategy : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is working-in-progress.\n",
      "     |  \n",
      "     |          The strategy used for training multi-target models, including multi-target\n",
      "     |          regression and multi-class classification. See :doc:`/tutorials/multioutput` for\n",
      "     |          more information.\n",
      "     |  \n",
      "     |          - ``one_output_per_tree``: One model for each target.\n",
      "     |          - ``multi_output_tree``:  Use multi-target trees.\n",
      "     |  \n",
      "     |      eval_metric : typing.Union[str, typing.List[str], typing.Callable, NoneType]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      "     |          string or list of strings as names of predefined metric in XGBoost (See\n",
      "     |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any\n",
      "     |          other user defined metric that looks like `sklearn.metrics`.\n",
      "     |  \n",
      "     |          If custom objective is also provided, then custom metric should implement the\n",
      "     |          corresponding reverse link function.\n",
      "     |  \n",
      "     |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      "     |          object is provided, it's assumed to be a cost function and by default XGBoost\n",
      "     |          will minimize the result during early stopping.\n",
      "     |  \n",
      "     |          For advanced usage on Early stopping like directly choosing to maximize instead\n",
      "     |          of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more\n",
      "     |          information.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              from sklearn.datasets import load_diabetes\n",
      "     |              from sklearn.metrics import mean_absolute_error\n",
      "     |              X, y = load_diabetes(return_X_y=True)\n",
      "     |              reg = xgb.XGBRegressor(\n",
      "     |                  tree_method=\"hist\",\n",
      "     |                  eval_metric=mean_absolute_error,\n",
      "     |              )\n",
      "     |              reg.fit(X, y, eval_set=[(X, y)])\n",
      "     |  \n",
      "     |      early_stopping_rounds : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          - Activates early stopping. Validation metric needs to improve at least once in\n",
      "     |            every **early_stopping_rounds** round(s) to continue training.  Requires at\n",
      "     |            least one item in **eval_set** in :py:meth:`fit`.\n",
      "     |  \n",
      "     |          - If early stopping occurs, the model will have two additional attributes:\n",
      "     |            :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the\n",
      "     |            :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal\n",
      "     |            number of trees during inference. If users want to access the full model\n",
      "     |            (including trees built after early stopping), they can specify the\n",
      "     |            `iteration_range` in these inference methods. In addition, other utilities\n",
      "     |            like model plotting can also use the entire model.\n",
      "     |  \n",
      "     |          - If you prefer to discard the trees after `best_iteration`, consider using the\n",
      "     |            callback function :py:class:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          - If there's more than one item in **eval_set**, the last entry will be used for\n",
      "     |            early stopping.  If there's more than one metric in **eval_metric**, the last\n",
      "     |            metric will be used for early stopping.\n",
      "     |  \n",
      "     |      callbacks : typing.Optional[typing.List[xgboost.callback.TrainingCallback]]\n",
      "     |  \n",
      "     |          List of callback functions that are applied at end of each iteration.\n",
      "     |          It is possible to use predefined callbacks by using\n",
      "     |          :ref:`Callback API <callback_api>`.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             States in callback are not preserved during training, which means callback\n",
      "     |             objects can not be reused for multiple training sessions without\n",
      "     |             reinitialization or deepcopy.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              for params in parameters_grid:\n",
      "     |                  # be sure to (re)initialize the callbacks before each run\n",
      "     |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "     |                  reg = xgboost.XGBRegressor(**params, callbacks=callbacks)\n",
      "     |                  reg.fit(X, y)\n",
      "     |  \n",
      "     |      kwargs : typing.Optional[typing.Any]\n",
      "     |  \n",
      "     |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      "     |          can be found :doc:`here </parameter>`.\n",
      "     |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      "     |          dict simultaneously will result in a TypeError.\n",
      "     |  \n",
      "     |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      "     |  \n",
      "     |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      "     |              that parameters passed via this argument will interact properly\n",
      "     |              with scikit-learn.\n",
      "     |  \n",
      "     |          .. note::  Custom objective function\n",
      "     |  \n",
      "     |              A custom objective function can be provided for the ``objective``\n",
      "     |              parameter. In this case, it should have the signature ``objective(y_true,\n",
      "     |              y_pred) -> [grad, hess]`` or ``objective(y_true, y_pred, *, sample_weight)\n",
      "     |              -> [grad, hess]``:\n",
      "     |  \n",
      "     |              y_true: array_like of shape [n_samples]\n",
      "     |                  The target values\n",
      "     |              y_pred: array_like of shape [n_samples]\n",
      "     |                  The predicted values\n",
      "     |              sample_weight :\n",
      "     |                  Optional sample weights.\n",
      "     |  \n",
      "     |              grad: array_like of shape [n_samples]\n",
      "     |                  The value of the gradient for each sample point.\n",
      "     |              hess: array_like of shape [n_samples]\n",
      "     |                  The value of the second derivative for each sample point\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      XGBClassifier\n",
      "     |      XGBModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, objective: Union[str, xgboost.sklearn._SklObjWProto, Callable[[Any, Any], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'binary:logistic', **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X: Any, y: Any, *, sample_weight: Optional[Any] = None, base_margin: Optional[Any] = None, eval_set: Optional[Sequence[Tuple[Any, Any]]] = None, verbose: Union[bool, int, NoneType] = True, xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None, sample_weight_eval_set: Optional[Sequence[Any]] = None, base_margin_eval_set: Optional[Sequence[Any]] = None, feature_weights: Optional[Any] = None) -> 'XGBClassifier'\n",
      "     |      Fit gradient boosting classifier.\n",
      "     |      \n",
      "     |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      "     |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      "     |      pass ``xgb_model`` argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      "     |      \n",
      "     |          When the ``tree_method`` is set to ``hist``, internally, the\n",
      "     |          :py:class:`QuantileDMatrix` will be used instead of the :py:class:`DMatrix`\n",
      "     |          for conserving memory. However, this has performance implications when the\n",
      "     |          device of input data is not matched with algorithm. For instance, if the\n",
      "     |          input is a numpy array on CPU but ``cuda`` is used for training, then the\n",
      "     |          data is first processed on CPU then transferred to GPU.\n",
      "     |      y :\n",
      "     |          Labels\n",
      "     |      sample_weight :\n",
      "     |          instance weights\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      eval_set :\n",
      "     |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      "     |          metrics will be computed.\n",
      "     |          Validation metrics will help us track the performance of the model.\n",
      "     |      \n",
      "     |      verbose :\n",
      "     |          If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      "     |          measured on the validation set is printed to stdout at each boosting stage.\n",
      "     |          If `verbose` is an integer, the evaluation metric is printed at each\n",
      "     |          `verbose` boosting stage. The last boosting stage / the boosting stage found\n",
      "     |          by using `early_stopping_rounds` is also printed.\n",
      "     |      xgb_model :\n",
      "     |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      "     |          loaded before training (allows training continuation).\n",
      "     |      sample_weight_eval_set :\n",
      "     |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      "     |          object storing instance weights for the i-th validation set.\n",
      "     |      base_margin_eval_set :\n",
      "     |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      "     |          object storing base margin for the i-th validation set.\n",
      "     |      feature_weights :\n",
      "     |          Weight for each feature, defines the probability of each feature being\n",
      "     |          selected when colsample is being used.  All values must be greater than 0,\n",
      "     |          otherwise a `ValueError` is thrown.\n",
      "     |  \n",
      "     |  predict(self, X: Any, output_margin: bool = False, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> Any\n",
      "     |      Predict with `X`.  If the model is trained with early stopping, then\n",
      "     |      :py:attr:`best_iteration` is used automatically. The estimator uses\n",
      "     |      `inplace_predict` by default and falls back to using :py:class:`DMatrix` if\n",
      "     |      devices between the data and the estimator don't match.\n",
      "     |      \n",
      "     |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Data to predict with.\n",
      "     |      output_margin :\n",
      "     |          Whether to output the raw untransformed margin value.\n",
      "     |      validate_features :\n",
      "     |          When this is True, validate that the Booster's and data's feature_names are\n",
      "     |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      iteration_range :\n",
      "     |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      "     |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      "     |          20)``, then only the forests built during [10, 20) (half open set) rounds\n",
      "     |          are used in this prediction.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction\n",
      "     |  \n",
      "     |  predict_proba(self, X: Any, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> numpy.ndarray\n",
      "     |      Predict the probability of each `X` example being of a given class. If the\n",
      "     |      model is trained with early stopping, then :py:attr:`best_iteration` is used\n",
      "     |      automatically. The estimator uses `inplace_predict` by default and falls back to\n",
      "     |      using :py:class:`DMatrix` if devices between the data and the estimator don't\n",
      "     |      match.\n",
      "     |      \n",
      "     |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      "     |      validate_features :\n",
      "     |          When this is True, validate that the Booster's and data's feature_names are\n",
      "     |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      iteration_range :\n",
      "     |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      "     |          random forest is trained with 100 rounds.  Specifying `iteration_range=(10,\n",
      "     |          20)`, then only the forests built during [10, 20) (half open set) rounds are\n",
      "     |          used in this prediction.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction :\n",
      "     |          a numpy array of shape array-like of shape (n_samples, n_classes) with the\n",
      "     |          probability of each data example being of a given class.\n",
      "     |  \n",
      "     |  set_fit_request(self: xgboost.sklearn.XGBClassifier, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', base_margin_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_weights: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', verbose: Union[bool, NoneType, str] = '$UNCHANGED$', xgb_model: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBClassifier\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      base_margin_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      feature_weights : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``feature_weights`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      verbose : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``verbose`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      xgb_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``xgb_model`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_predict_proba_request(self: xgboost.sklearn.XGBClassifier, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBClassifier\n",
      "     |      Request metadata passed to the ``predict_proba`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``predict_proba`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict_proba``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``predict_proba``.\n",
      "     |      \n",
      "     |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``iteration_range`` parameter in ``predict_proba``.\n",
      "     |      \n",
      "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``validate_features`` parameter in ``predict_proba``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_predict_request(self: xgboost.sklearn.XGBClassifier, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$', output_margin: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBClassifier\n",
      "     |      Request metadata passed to the ``predict`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``iteration_range`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      output_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``output_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_score_request(self: xgboost.sklearn.XGBClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBClassifier\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  classes_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from XGBModel:\n",
      "     |  \n",
      "     |  __sklearn_is_fitted__(self) -> bool\n",
      "     |  \n",
      "     |  apply(self, X: Any, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> numpy.ndarray\n",
      "     |      Return the predicted leaf every tree for each sample. If the model is trained\n",
      "     |      with early stopping, then :py:attr:`best_iteration` is used automatically.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like, shape=[n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      \n",
      "     |      iteration_range :\n",
      "     |          See :py:meth:`predict`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      "     |          For each datapoint x in X and for each tree, return the index of the\n",
      "     |          leaf x ends up in. Leaves are numbered within\n",
      "     |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      "     |  \n",
      "     |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      "     |      Return the evaluation results.\n",
      "     |      \n",
      "     |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      "     |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      "     |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      "     |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      "     |      function.\n",
      "     |      \n",
      "     |      The returned evaluation result is a dictionary:\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      "     |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      evals_result\n",
      "     |  \n",
      "     |  get_booster(self) -> xgboost.core.Booster\n",
      "     |      Get the underlying xgboost Booster of this model.\n",
      "     |      \n",
      "     |      This will raise an exception when fit was not called\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      booster : a xgboost booster of underlying model\n",
      "     |  \n",
      "     |  get_num_boosting_rounds(self) -> int\n",
      "     |      Gets the number of xgboost boosting rounds.\n",
      "     |  \n",
      "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      "     |      Get parameters.\n",
      "     |  \n",
      "     |  get_xgb_params(self) -> Dict[str, Any]\n",
      "     |      Get xgboost specific parameters.\n",
      "     |  \n",
      "     |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      "     |      Load the model from a file or a bytearray.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.load_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.load_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Input file name or memory buffer(see also save_raw)\n",
      "     |  \n",
      "     |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.save_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.save_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Output file name\n",
      "     |  \n",
      "     |  set_params(self, **params: Any) -> 'XGBModel'\n",
      "     |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      "     |      allow unknown kwargs. This allows using the full range of xgboost\n",
      "     |      parameters that are not defined as member variables in sklearn grid\n",
      "     |      search.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from XGBModel:\n",
      "     |  \n",
      "     |  best_iteration\n",
      "     |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      "     |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      "     |  \n",
      "     |  best_score\n",
      "     |      The best score obtained by early stopping.\n",
      "     |  \n",
      "     |  coef_\n",
      "     |      Coefficients property\n",
      "     |      \n",
      "     |      .. note:: Coefficients are defined only for linear learners\n",
      "     |      \n",
      "     |          Coefficients are only defined when the linear model is chosen as\n",
      "     |          base learner (`booster=gblinear`). It is not defined for other base\n",
      "     |          learner types, such as tree learners (`booster=gbtree`).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Feature importances property, return depends on `importance_type`\n",
      "     |      parameter. When model trained with multi-class/multi-label/multi-target dataset,\n",
      "     |      the feature importance is \"averaged\" over all targets. The \"average\" is defined\n",
      "     |      based on the importance type. For instance, if the importance type is\n",
      "     |      \"total_gain\", then the score is sum of loss change for each split from all\n",
      "     |      trees.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      "     |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      "     |  \n",
      "     |  feature_names_in_\n",
      "     |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has\n",
      "     |      feature names that are all strings.\n",
      "     |  \n",
      "     |  intercept_\n",
      "     |      Intercept (bias) property\n",
      "     |      \n",
      "     |      For tree-based model, the returned value is the `base_score`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |      Number of features seen during :py:meth:`fit`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "    \n",
      "    class XGBModel(sklearn.base.BaseEstimator)\n",
      "     |  XGBModel(max_depth: Optional[int] = None, max_leaves: Optional[int] = None, max_bin: Optional[int] = None, grow_policy: Optional[str] = None, learning_rate: Optional[float] = None, n_estimators: Optional[int] = None, verbosity: Optional[int] = None, objective: Union[str, xgboost.sklearn._SklObjWProto, Callable[[Any, Any], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, booster: Optional[str] = None, tree_method: Optional[str] = None, n_jobs: Optional[int] = None, gamma: Optional[float] = None, min_child_weight: Optional[float] = None, max_delta_step: Optional[float] = None, subsample: Optional[float] = None, sampling_method: Optional[str] = None, colsample_bytree: Optional[float] = None, colsample_bylevel: Optional[float] = None, colsample_bynode: Optional[float] = None, reg_alpha: Optional[float] = None, reg_lambda: Optional[float] = None, scale_pos_weight: Optional[float] = None, base_score: Optional[float] = None, random_state: Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType] = None, missing: float = nan, num_parallel_tree: Optional[int] = None, monotone_constraints: Union[Dict[str, int], str, NoneType] = None, interaction_constraints: Union[str, Sequence[Sequence[str]], NoneType] = None, importance_type: Optional[str] = None, device: Optional[str] = None, validate_parameters: Optional[bool] = None, enable_categorical: bool = False, feature_types: Optional[Sequence[str]] = None, max_cat_to_onehot: Optional[int] = None, max_cat_threshold: Optional[int] = None, multi_strategy: Optional[str] = None, eval_metric: Union[str, List[str], Callable, NoneType] = None, early_stopping_rounds: Optional[int] = None, callbacks: Optional[List[xgboost.callback.TrainingCallback]] = None, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  Implementation of the Scikit-Learn API for XGBoost.\n",
      "     |  See :doc:`/python/sklearn_estimator` for more information.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |      n_estimators : typing.Optional[int]\n",
      "     |          Number of gradient boosted trees.  Equivalent to number of boosting\n",
      "     |          rounds.\n",
      "     |  \n",
      "     |      max_depth :  typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum tree depth for base learners.\n",
      "     |  \n",
      "     |      max_leaves : typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum number of leaves; 0 indicates no limit.\n",
      "     |  \n",
      "     |      max_bin : typing.Optional[int]\n",
      "     |  \n",
      "     |          If using histogram-based algorithm, maximum number of bins per feature\n",
      "     |  \n",
      "     |      grow_policy : typing.Optional[str]\n",
      "     |  \n",
      "     |          Tree growing policy.\n",
      "     |  \n",
      "     |          - depthwise: Favors splitting at nodes closest to the node,\n",
      "     |          - lossguide: Favors splitting at nodes with highest loss change.\n",
      "     |  \n",
      "     |      learning_rate : typing.Optional[float]\n",
      "     |  \n",
      "     |          Boosting learning rate (xgb's \"eta\")\n",
      "     |  \n",
      "     |      verbosity : typing.Optional[int]\n",
      "     |  \n",
      "     |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      "     |  \n",
      "     |      objective : typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      "     |  \n",
      "     |          Specify the learning task and the corresponding learning objective or a custom\n",
      "     |          objective function to be used.\n",
      "     |  \n",
      "     |          For custom objective, see :doc:`/tutorials/custom_metric_obj` and\n",
      "     |          :ref:`custom-obj-metric` for more information, along with the end note for\n",
      "     |          function signatures.\n",
      "     |  \n",
      "     |      booster: typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which booster to use: ``gbtree``, ``gblinear`` or ``dart``.\n",
      "     |  \n",
      "     |      tree_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      "     |          default, XGBoost will choose the most conservative option available.  It's\n",
      "     |          recommended to study this option from the parameters document :doc:`tree method\n",
      "     |          </treemethod>`\n",
      "     |  \n",
      "     |      n_jobs : typing.Optional[int]\n",
      "     |  \n",
      "     |          Number of parallel threads used to run xgboost.  When used with other\n",
      "     |          Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      "     |          parallelize and balance the threads.  Creating thread contention will\n",
      "     |          significantly slow down both algorithms.\n",
      "     |  \n",
      "     |      gamma : typing.Optional[float]\n",
      "     |  \n",
      "     |          (min_split_loss) Minimum loss reduction required to make a further partition on\n",
      "     |          a leaf node of the tree.\n",
      "     |  \n",
      "     |      min_child_weight : typing.Optional[float]\n",
      "     |  \n",
      "     |          Minimum sum of instance weight(hessian) needed in a child.\n",
      "     |  \n",
      "     |      max_delta_step : typing.Optional[float]\n",
      "     |  \n",
      "     |          Maximum delta step we allow each tree's weight estimation to be.\n",
      "     |  \n",
      "     |      subsample : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of the training instance.\n",
      "     |  \n",
      "     |      sampling_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Sampling method. Used only by the GPU version of ``hist`` tree method.\n",
      "     |  \n",
      "     |          - ``uniform``: Select random training instances uniformly.\n",
      "     |          - ``gradient_based``: Select random training instances with higher probability\n",
      "     |              when the gradient and hessian are larger. (cf. CatBoost)\n",
      "     |  \n",
      "     |      colsample_bytree : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |  \n",
      "     |      colsample_bylevel : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each level.\n",
      "     |  \n",
      "     |      colsample_bynode : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each split.\n",
      "     |  \n",
      "     |      reg_alpha : typing.Optional[float]\n",
      "     |  \n",
      "     |          L1 regularization term on weights (xgb's alpha).\n",
      "     |  \n",
      "     |      reg_lambda : typing.Optional[float]\n",
      "     |  \n",
      "     |          L2 regularization term on weights (xgb's lambda).\n",
      "     |  \n",
      "     |      scale_pos_weight : typing.Optional[float]\n",
      "     |          Balancing of positive and negative weights.\n",
      "     |  \n",
      "     |      base_score : typing.Optional[float]\n",
      "     |  \n",
      "     |          The initial prediction score of all instances, global bias.\n",
      "     |  \n",
      "     |      random_state : typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]\n",
      "     |  \n",
      "     |          Random number seed.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      "     |             it uses Hogwild algorithm.\n",
      "     |  \n",
      "     |      missing : float\n",
      "     |  \n",
      "     |          Value in the data which needs to be present as a missing value. Default to\n",
      "     |          :py:data:`numpy.nan`.\n",
      "     |  \n",
      "     |      num_parallel_tree: typing.Optional[int]\n",
      "     |  \n",
      "     |          Used for boosting random forest.\n",
      "     |  \n",
      "     |      monotone_constraints : typing.Union[typing.Dict[str, int], str, NoneType]\n",
      "     |  \n",
      "     |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      "     |          for more information.\n",
      "     |  \n",
      "     |      interaction_constraints : typing.Union[str, typing.List[typing.Tuple[str]], NoneType]\n",
      "     |  \n",
      "     |          Constraints for interaction representing permitted interactions.  The\n",
      "     |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      "     |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      "     |          allowed to interact with each other.  See :doc:`tutorial\n",
      "     |          </tutorials/feature_interaction_constraint>` for more information\n",
      "     |  \n",
      "     |      importance_type: typing.Optional[str]\n",
      "     |  \n",
      "     |          The feature importance type for the feature_importances\\_ property:\n",
      "     |  \n",
      "     |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      "     |            \"total_cover\".\n",
      "     |          * For linear model, only \"weight\" is defined and it's the normalized\n",
      "     |            coefficients without bias.\n",
      "     |  \n",
      "     |      device : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          Device ordinal, available options are `cpu`, `cuda`, and `gpu`.\n",
      "     |  \n",
      "     |      validate_parameters : typing.Optional[bool]\n",
      "     |  \n",
      "     |          Give warnings for unknown parameter.\n",
      "     |  \n",
      "     |      enable_categorical : bool\n",
      "     |  \n",
      "     |          See the same parameter of :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      feature_types : typing.Optional[typing.Sequence[str]]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          Used for specifying feature types without constructing a dataframe. See\n",
      "     |          :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      max_cat_to_onehot : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      "     |          for categorical data.  When number of categories is lesser than the threshold\n",
      "     |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      "     |          into children nodes. Also, `enable_categorical` needs to be set to have\n",
      "     |          categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      max_cat_threshold : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          Maximum number of categories considered for each split. Used only by\n",
      "     |          partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      "     |          needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      multi_strategy : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is working-in-progress.\n",
      "     |  \n",
      "     |          The strategy used for training multi-target models, including multi-target\n",
      "     |          regression and multi-class classification. See :doc:`/tutorials/multioutput` for\n",
      "     |          more information.\n",
      "     |  \n",
      "     |          - ``one_output_per_tree``: One model for each target.\n",
      "     |          - ``multi_output_tree``:  Use multi-target trees.\n",
      "     |  \n",
      "     |      eval_metric : typing.Union[str, typing.List[str], typing.Callable, NoneType]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      "     |          string or list of strings as names of predefined metric in XGBoost (See\n",
      "     |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any\n",
      "     |          other user defined metric that looks like `sklearn.metrics`.\n",
      "     |  \n",
      "     |          If custom objective is also provided, then custom metric should implement the\n",
      "     |          corresponding reverse link function.\n",
      "     |  \n",
      "     |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      "     |          object is provided, it's assumed to be a cost function and by default XGBoost\n",
      "     |          will minimize the result during early stopping.\n",
      "     |  \n",
      "     |          For advanced usage on Early stopping like directly choosing to maximize instead\n",
      "     |          of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more\n",
      "     |          information.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              from sklearn.datasets import load_diabetes\n",
      "     |              from sklearn.metrics import mean_absolute_error\n",
      "     |              X, y = load_diabetes(return_X_y=True)\n",
      "     |              reg = xgb.XGBRegressor(\n",
      "     |                  tree_method=\"hist\",\n",
      "     |                  eval_metric=mean_absolute_error,\n",
      "     |              )\n",
      "     |              reg.fit(X, y, eval_set=[(X, y)])\n",
      "     |  \n",
      "     |      early_stopping_rounds : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          - Activates early stopping. Validation metric needs to improve at least once in\n",
      "     |            every **early_stopping_rounds** round(s) to continue training.  Requires at\n",
      "     |            least one item in **eval_set** in :py:meth:`fit`.\n",
      "     |  \n",
      "     |          - If early stopping occurs, the model will have two additional attributes:\n",
      "     |            :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the\n",
      "     |            :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal\n",
      "     |            number of trees during inference. If users want to access the full model\n",
      "     |            (including trees built after early stopping), they can specify the\n",
      "     |            `iteration_range` in these inference methods. In addition, other utilities\n",
      "     |            like model plotting can also use the entire model.\n",
      "     |  \n",
      "     |          - If you prefer to discard the trees after `best_iteration`, consider using the\n",
      "     |            callback function :py:class:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          - If there's more than one item in **eval_set**, the last entry will be used for\n",
      "     |            early stopping.  If there's more than one metric in **eval_metric**, the last\n",
      "     |            metric will be used for early stopping.\n",
      "     |  \n",
      "     |      callbacks : typing.Optional[typing.List[xgboost.callback.TrainingCallback]]\n",
      "     |  \n",
      "     |          List of callback functions that are applied at end of each iteration.\n",
      "     |          It is possible to use predefined callbacks by using\n",
      "     |          :ref:`Callback API <callback_api>`.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             States in callback are not preserved during training, which means callback\n",
      "     |             objects can not be reused for multiple training sessions without\n",
      "     |             reinitialization or deepcopy.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              for params in parameters_grid:\n",
      "     |                  # be sure to (re)initialize the callbacks before each run\n",
      "     |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "     |                  reg = xgboost.XGBRegressor(**params, callbacks=callbacks)\n",
      "     |                  reg.fit(X, y)\n",
      "     |  \n",
      "     |      kwargs : typing.Optional[typing.Any]\n",
      "     |  \n",
      "     |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      "     |          can be found :doc:`here </parameter>`.\n",
      "     |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      "     |          dict simultaneously will result in a TypeError.\n",
      "     |  \n",
      "     |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      "     |  \n",
      "     |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      "     |              that parameters passed via this argument will interact properly\n",
      "     |              with scikit-learn.\n",
      "     |  \n",
      "     |          .. note::  Custom objective function\n",
      "     |  \n",
      "     |              A custom objective function can be provided for the ``objective``\n",
      "     |              parameter. In this case, it should have the signature ``objective(y_true,\n",
      "     |              y_pred) -> [grad, hess]`` or ``objective(y_true, y_pred, *, sample_weight)\n",
      "     |              -> [grad, hess]``:\n",
      "     |  \n",
      "     |              y_true: array_like of shape [n_samples]\n",
      "     |                  The target values\n",
      "     |              y_pred: array_like of shape [n_samples]\n",
      "     |                  The predicted values\n",
      "     |              sample_weight :\n",
      "     |                  Optional sample weights.\n",
      "     |  \n",
      "     |              grad: array_like of shape [n_samples]\n",
      "     |                  The value of the gradient for each sample point.\n",
      "     |              hess: array_like of shape [n_samples]\n",
      "     |                  The value of the second derivative for each sample point\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      XGBModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, max_depth: Optional[int] = None, max_leaves: Optional[int] = None, max_bin: Optional[int] = None, grow_policy: Optional[str] = None, learning_rate: Optional[float] = None, n_estimators: Optional[int] = None, verbosity: Optional[int] = None, objective: Union[str, xgboost.sklearn._SklObjWProto, Callable[[Any, Any], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = None, booster: Optional[str] = None, tree_method: Optional[str] = None, n_jobs: Optional[int] = None, gamma: Optional[float] = None, min_child_weight: Optional[float] = None, max_delta_step: Optional[float] = None, subsample: Optional[float] = None, sampling_method: Optional[str] = None, colsample_bytree: Optional[float] = None, colsample_bylevel: Optional[float] = None, colsample_bynode: Optional[float] = None, reg_alpha: Optional[float] = None, reg_lambda: Optional[float] = None, scale_pos_weight: Optional[float] = None, base_score: Optional[float] = None, random_state: Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType] = None, missing: float = nan, num_parallel_tree: Optional[int] = None, monotone_constraints: Union[Dict[str, int], str, NoneType] = None, interaction_constraints: Union[str, Sequence[Sequence[str]], NoneType] = None, importance_type: Optional[str] = None, device: Optional[str] = None, validate_parameters: Optional[bool] = None, enable_categorical: bool = False, feature_types: Optional[Sequence[str]] = None, max_cat_to_onehot: Optional[int] = None, max_cat_threshold: Optional[int] = None, multi_strategy: Optional[str] = None, eval_metric: Union[str, List[str], Callable, NoneType] = None, early_stopping_rounds: Optional[int] = None, callbacks: Optional[List[xgboost.callback.TrainingCallback]] = None, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __sklearn_is_fitted__(self) -> bool\n",
      "     |  \n",
      "     |  apply(self, X: Any, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> numpy.ndarray\n",
      "     |      Return the predicted leaf every tree for each sample. If the model is trained\n",
      "     |      with early stopping, then :py:attr:`best_iteration` is used automatically.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like, shape=[n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      \n",
      "     |      iteration_range :\n",
      "     |          See :py:meth:`predict`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      "     |          For each datapoint x in X and for each tree, return the index of the\n",
      "     |          leaf x ends up in. Leaves are numbered within\n",
      "     |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      "     |  \n",
      "     |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      "     |      Return the evaluation results.\n",
      "     |      \n",
      "     |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      "     |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      "     |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      "     |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      "     |      function.\n",
      "     |      \n",
      "     |      The returned evaluation result is a dictionary:\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      "     |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      evals_result\n",
      "     |  \n",
      "     |  fit(self, X: Any, y: Any, *, sample_weight: Optional[Any] = None, base_margin: Optional[Any] = None, eval_set: Optional[Sequence[Tuple[Any, Any]]] = None, verbose: Union[bool, int, NoneType] = True, xgb_model: Union[xgboost.core.Booster, ForwardRef('XGBModel'), str, NoneType] = None, sample_weight_eval_set: Optional[Sequence[Any]] = None, base_margin_eval_set: Optional[Sequence[Any]] = None, feature_weights: Optional[Any] = None) -> 'XGBModel'\n",
      "     |      Fit gradient boosting model.\n",
      "     |      \n",
      "     |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      "     |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      "     |      pass ``xgb_model`` argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      "     |      \n",
      "     |          When the ``tree_method`` is set to ``hist``, internally, the\n",
      "     |          :py:class:`QuantileDMatrix` will be used instead of the :py:class:`DMatrix`\n",
      "     |          for conserving memory. However, this has performance implications when the\n",
      "     |          device of input data is not matched with algorithm. For instance, if the\n",
      "     |          input is a numpy array on CPU but ``cuda`` is used for training, then the\n",
      "     |          data is first processed on CPU then transferred to GPU.\n",
      "     |      y :\n",
      "     |          Labels\n",
      "     |      sample_weight :\n",
      "     |          instance weights\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      eval_set :\n",
      "     |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      "     |          metrics will be computed.\n",
      "     |          Validation metrics will help us track the performance of the model.\n",
      "     |      \n",
      "     |      verbose :\n",
      "     |          If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      "     |          measured on the validation set is printed to stdout at each boosting stage.\n",
      "     |          If `verbose` is an integer, the evaluation metric is printed at each\n",
      "     |          `verbose` boosting stage. The last boosting stage / the boosting stage found\n",
      "     |          by using `early_stopping_rounds` is also printed.\n",
      "     |      xgb_model :\n",
      "     |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      "     |          loaded before training (allows training continuation).\n",
      "     |      sample_weight_eval_set :\n",
      "     |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      "     |          object storing instance weights for the i-th validation set.\n",
      "     |      base_margin_eval_set :\n",
      "     |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      "     |          object storing base margin for the i-th validation set.\n",
      "     |      feature_weights :\n",
      "     |          Weight for each feature, defines the probability of each feature being\n",
      "     |          selected when colsample is being used.  All values must be greater than 0,\n",
      "     |          otherwise a `ValueError` is thrown.\n",
      "     |  \n",
      "     |  get_booster(self) -> xgboost.core.Booster\n",
      "     |      Get the underlying xgboost Booster of this model.\n",
      "     |      \n",
      "     |      This will raise an exception when fit was not called\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      booster : a xgboost booster of underlying model\n",
      "     |  \n",
      "     |  get_num_boosting_rounds(self) -> int\n",
      "     |      Gets the number of xgboost boosting rounds.\n",
      "     |  \n",
      "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      "     |      Get parameters.\n",
      "     |  \n",
      "     |  get_xgb_params(self) -> Dict[str, Any]\n",
      "     |      Get xgboost specific parameters.\n",
      "     |  \n",
      "     |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      "     |      Load the model from a file or a bytearray.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.load_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.load_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Input file name or memory buffer(see also save_raw)\n",
      "     |  \n",
      "     |  predict(self, X: Any, output_margin: bool = False, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> Any\n",
      "     |      Predict with `X`.  If the model is trained with early stopping, then\n",
      "     |      :py:attr:`best_iteration` is used automatically. The estimator uses\n",
      "     |      `inplace_predict` by default and falls back to using :py:class:`DMatrix` if\n",
      "     |      devices between the data and the estimator don't match.\n",
      "     |      \n",
      "     |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Data to predict with.\n",
      "     |      output_margin :\n",
      "     |          Whether to output the raw untransformed margin value.\n",
      "     |      validate_features :\n",
      "     |          When this is True, validate that the Booster's and data's feature_names are\n",
      "     |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      iteration_range :\n",
      "     |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      "     |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      "     |          20)``, then only the forests built during [10, 20) (half open set) rounds\n",
      "     |          are used in this prediction.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction\n",
      "     |  \n",
      "     |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.save_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.save_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Output file name\n",
      "     |  \n",
      "     |  set_fit_request(self: xgboost.sklearn.XGBModel, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', base_margin_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_weights: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', verbose: Union[bool, NoneType, str] = '$UNCHANGED$', xgb_model: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBModel\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      base_margin_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      feature_weights : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``feature_weights`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      verbose : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``verbose`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      xgb_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``xgb_model`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_params(self, **params: Any) -> 'XGBModel'\n",
      "     |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      "     |      allow unknown kwargs. This allows using the full range of xgboost\n",
      "     |      parameters that are not defined as member variables in sklearn grid\n",
      "     |      search.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  set_predict_request(self: xgboost.sklearn.XGBModel, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$', output_margin: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBModel\n",
      "     |      Request metadata passed to the ``predict`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``iteration_range`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      output_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``output_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  best_iteration\n",
      "     |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      "     |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      "     |  \n",
      "     |  best_score\n",
      "     |      The best score obtained by early stopping.\n",
      "     |  \n",
      "     |  coef_\n",
      "     |      Coefficients property\n",
      "     |      \n",
      "     |      .. note:: Coefficients are defined only for linear learners\n",
      "     |      \n",
      "     |          Coefficients are only defined when the linear model is chosen as\n",
      "     |          base learner (`booster=gblinear`). It is not defined for other base\n",
      "     |          learner types, such as tree learners (`booster=gbtree`).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Feature importances property, return depends on `importance_type`\n",
      "     |      parameter. When model trained with multi-class/multi-label/multi-target dataset,\n",
      "     |      the feature importance is \"averaged\" over all targets. The \"average\" is defined\n",
      "     |      based on the importance type. For instance, if the importance type is\n",
      "     |      \"total_gain\", then the score is sum of loss change for each split from all\n",
      "     |      trees.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      "     |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      "     |  \n",
      "     |  feature_names_in_\n",
      "     |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has\n",
      "     |      feature names that are all strings.\n",
      "     |  \n",
      "     |  intercept_\n",
      "     |      Intercept (bias) property\n",
      "     |      \n",
      "     |      For tree-based model, the returned value is the `base_score`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |      Number of features seen during :py:meth:`fit`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "    \n",
      "    class XGBRFClassifier(XGBClassifier)\n",
      "     |  XGBRFClassifier(*, learning_rate: float = 1.0, subsample: float = 0.8, colsample_bynode: float = 0.8, reg_lambda: float = 1e-05, **kwargs: Any)\n",
      "     |  \n",
      "     |  scikit-learn API for XGBoost random forest classification.\n",
      "     |  See :doc:`/python/sklearn_estimator` for more information.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |      n_estimators : Optional[int]\n",
      "     |          Number of trees in random forest to fit.\n",
      "     |  \n",
      "     |      max_depth :  typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum tree depth for base learners.\n",
      "     |  \n",
      "     |      max_leaves : typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum number of leaves; 0 indicates no limit.\n",
      "     |  \n",
      "     |      max_bin : typing.Optional[int]\n",
      "     |  \n",
      "     |          If using histogram-based algorithm, maximum number of bins per feature\n",
      "     |  \n",
      "     |      grow_policy : typing.Optional[str]\n",
      "     |  \n",
      "     |          Tree growing policy.\n",
      "     |  \n",
      "     |          - depthwise: Favors splitting at nodes closest to the node,\n",
      "     |          - lossguide: Favors splitting at nodes with highest loss change.\n",
      "     |  \n",
      "     |      learning_rate : typing.Optional[float]\n",
      "     |  \n",
      "     |          Boosting learning rate (xgb's \"eta\")\n",
      "     |  \n",
      "     |      verbosity : typing.Optional[int]\n",
      "     |  \n",
      "     |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      "     |  \n",
      "     |      objective : typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      "     |  \n",
      "     |          Specify the learning task and the corresponding learning objective or a custom\n",
      "     |          objective function to be used.\n",
      "     |  \n",
      "     |          For custom objective, see :doc:`/tutorials/custom_metric_obj` and\n",
      "     |          :ref:`custom-obj-metric` for more information, along with the end note for\n",
      "     |          function signatures.\n",
      "     |  \n",
      "     |      booster: typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which booster to use: ``gbtree``, ``gblinear`` or ``dart``.\n",
      "     |  \n",
      "     |      tree_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      "     |          default, XGBoost will choose the most conservative option available.  It's\n",
      "     |          recommended to study this option from the parameters document :doc:`tree method\n",
      "     |          </treemethod>`\n",
      "     |  \n",
      "     |      n_jobs : typing.Optional[int]\n",
      "     |  \n",
      "     |          Number of parallel threads used to run xgboost.  When used with other\n",
      "     |          Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      "     |          parallelize and balance the threads.  Creating thread contention will\n",
      "     |          significantly slow down both algorithms.\n",
      "     |  \n",
      "     |      gamma : typing.Optional[float]\n",
      "     |  \n",
      "     |          (min_split_loss) Minimum loss reduction required to make a further partition on\n",
      "     |          a leaf node of the tree.\n",
      "     |  \n",
      "     |      min_child_weight : typing.Optional[float]\n",
      "     |  \n",
      "     |          Minimum sum of instance weight(hessian) needed in a child.\n",
      "     |  \n",
      "     |      max_delta_step : typing.Optional[float]\n",
      "     |  \n",
      "     |          Maximum delta step we allow each tree's weight estimation to be.\n",
      "     |  \n",
      "     |      subsample : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of the training instance.\n",
      "     |  \n",
      "     |      sampling_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Sampling method. Used only by the GPU version of ``hist`` tree method.\n",
      "     |  \n",
      "     |          - ``uniform``: Select random training instances uniformly.\n",
      "     |          - ``gradient_based``: Select random training instances with higher probability\n",
      "     |              when the gradient and hessian are larger. (cf. CatBoost)\n",
      "     |  \n",
      "     |      colsample_bytree : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |  \n",
      "     |      colsample_bylevel : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each level.\n",
      "     |  \n",
      "     |      colsample_bynode : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each split.\n",
      "     |  \n",
      "     |      reg_alpha : typing.Optional[float]\n",
      "     |  \n",
      "     |          L1 regularization term on weights (xgb's alpha).\n",
      "     |  \n",
      "     |      reg_lambda : typing.Optional[float]\n",
      "     |  \n",
      "     |          L2 regularization term on weights (xgb's lambda).\n",
      "     |  \n",
      "     |      scale_pos_weight : typing.Optional[float]\n",
      "     |          Balancing of positive and negative weights.\n",
      "     |  \n",
      "     |      base_score : typing.Optional[float]\n",
      "     |  \n",
      "     |          The initial prediction score of all instances, global bias.\n",
      "     |  \n",
      "     |      random_state : typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]\n",
      "     |  \n",
      "     |          Random number seed.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      "     |             it uses Hogwild algorithm.\n",
      "     |  \n",
      "     |      missing : float\n",
      "     |  \n",
      "     |          Value in the data which needs to be present as a missing value. Default to\n",
      "     |          :py:data:`numpy.nan`.\n",
      "     |  \n",
      "     |      num_parallel_tree: typing.Optional[int]\n",
      "     |  \n",
      "     |          Used for boosting random forest.\n",
      "     |  \n",
      "     |      monotone_constraints : typing.Union[typing.Dict[str, int], str, NoneType]\n",
      "     |  \n",
      "     |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      "     |          for more information.\n",
      "     |  \n",
      "     |      interaction_constraints : typing.Union[str, typing.List[typing.Tuple[str]], NoneType]\n",
      "     |  \n",
      "     |          Constraints for interaction representing permitted interactions.  The\n",
      "     |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      "     |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      "     |          allowed to interact with each other.  See :doc:`tutorial\n",
      "     |          </tutorials/feature_interaction_constraint>` for more information\n",
      "     |  \n",
      "     |      importance_type: typing.Optional[str]\n",
      "     |  \n",
      "     |          The feature importance type for the feature_importances\\_ property:\n",
      "     |  \n",
      "     |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      "     |            \"total_cover\".\n",
      "     |          * For linear model, only \"weight\" is defined and it's the normalized\n",
      "     |            coefficients without bias.\n",
      "     |  \n",
      "     |      device : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          Device ordinal, available options are `cpu`, `cuda`, and `gpu`.\n",
      "     |  \n",
      "     |      validate_parameters : typing.Optional[bool]\n",
      "     |  \n",
      "     |          Give warnings for unknown parameter.\n",
      "     |  \n",
      "     |      enable_categorical : bool\n",
      "     |  \n",
      "     |          See the same parameter of :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      feature_types : typing.Optional[typing.Sequence[str]]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          Used for specifying feature types without constructing a dataframe. See\n",
      "     |          :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      max_cat_to_onehot : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      "     |          for categorical data.  When number of categories is lesser than the threshold\n",
      "     |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      "     |          into children nodes. Also, `enable_categorical` needs to be set to have\n",
      "     |          categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      max_cat_threshold : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          Maximum number of categories considered for each split. Used only by\n",
      "     |          partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      "     |          needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      multi_strategy : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is working-in-progress.\n",
      "     |  \n",
      "     |          The strategy used for training multi-target models, including multi-target\n",
      "     |          regression and multi-class classification. See :doc:`/tutorials/multioutput` for\n",
      "     |          more information.\n",
      "     |  \n",
      "     |          - ``one_output_per_tree``: One model for each target.\n",
      "     |          - ``multi_output_tree``:  Use multi-target trees.\n",
      "     |  \n",
      "     |      eval_metric : typing.Union[str, typing.List[str], typing.Callable, NoneType]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      "     |          string or list of strings as names of predefined metric in XGBoost (See\n",
      "     |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any\n",
      "     |          other user defined metric that looks like `sklearn.metrics`.\n",
      "     |  \n",
      "     |          If custom objective is also provided, then custom metric should implement the\n",
      "     |          corresponding reverse link function.\n",
      "     |  \n",
      "     |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      "     |          object is provided, it's assumed to be a cost function and by default XGBoost\n",
      "     |          will minimize the result during early stopping.\n",
      "     |  \n",
      "     |          For advanced usage on Early stopping like directly choosing to maximize instead\n",
      "     |          of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more\n",
      "     |          information.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              from sklearn.datasets import load_diabetes\n",
      "     |              from sklearn.metrics import mean_absolute_error\n",
      "     |              X, y = load_diabetes(return_X_y=True)\n",
      "     |              reg = xgb.XGBRegressor(\n",
      "     |                  tree_method=\"hist\",\n",
      "     |                  eval_metric=mean_absolute_error,\n",
      "     |              )\n",
      "     |              reg.fit(X, y, eval_set=[(X, y)])\n",
      "     |  \n",
      "     |      early_stopping_rounds : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          - Activates early stopping. Validation metric needs to improve at least once in\n",
      "     |            every **early_stopping_rounds** round(s) to continue training.  Requires at\n",
      "     |            least one item in **eval_set** in :py:meth:`fit`.\n",
      "     |  \n",
      "     |          - If early stopping occurs, the model will have two additional attributes:\n",
      "     |            :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the\n",
      "     |            :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal\n",
      "     |            number of trees during inference. If users want to access the full model\n",
      "     |            (including trees built after early stopping), they can specify the\n",
      "     |            `iteration_range` in these inference methods. In addition, other utilities\n",
      "     |            like model plotting can also use the entire model.\n",
      "     |  \n",
      "     |          - If you prefer to discard the trees after `best_iteration`, consider using the\n",
      "     |            callback function :py:class:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          - If there's more than one item in **eval_set**, the last entry will be used for\n",
      "     |            early stopping.  If there's more than one metric in **eval_metric**, the last\n",
      "     |            metric will be used for early stopping.\n",
      "     |  \n",
      "     |      callbacks : typing.Optional[typing.List[xgboost.callback.TrainingCallback]]\n",
      "     |  \n",
      "     |          List of callback functions that are applied at end of each iteration.\n",
      "     |          It is possible to use predefined callbacks by using\n",
      "     |          :ref:`Callback API <callback_api>`.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             States in callback are not preserved during training, which means callback\n",
      "     |             objects can not be reused for multiple training sessions without\n",
      "     |             reinitialization or deepcopy.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              for params in parameters_grid:\n",
      "     |                  # be sure to (re)initialize the callbacks before each run\n",
      "     |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "     |                  reg = xgboost.XGBRegressor(**params, callbacks=callbacks)\n",
      "     |                  reg.fit(X, y)\n",
      "     |  \n",
      "     |      kwargs : typing.Optional[typing.Any]\n",
      "     |  \n",
      "     |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      "     |          can be found :doc:`here </parameter>`.\n",
      "     |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      "     |          dict simultaneously will result in a TypeError.\n",
      "     |  \n",
      "     |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      "     |  \n",
      "     |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      "     |              that parameters passed via this argument will interact properly\n",
      "     |              with scikit-learn.\n",
      "     |  \n",
      "     |          .. note::  Custom objective function\n",
      "     |  \n",
      "     |              A custom objective function can be provided for the ``objective``\n",
      "     |              parameter. In this case, it should have the signature ``objective(y_true,\n",
      "     |              y_pred) -> [grad, hess]`` or ``objective(y_true, y_pred, *, sample_weight)\n",
      "     |              -> [grad, hess]``:\n",
      "     |  \n",
      "     |              y_true: array_like of shape [n_samples]\n",
      "     |                  The target values\n",
      "     |              y_pred: array_like of shape [n_samples]\n",
      "     |                  The predicted values\n",
      "     |              sample_weight :\n",
      "     |                  Optional sample weights.\n",
      "     |  \n",
      "     |              grad: array_like of shape [n_samples]\n",
      "     |                  The value of the gradient for each sample point.\n",
      "     |              hess: array_like of shape [n_samples]\n",
      "     |                  The value of the second derivative for each sample point\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      XGBRFClassifier\n",
      "     |      XGBClassifier\n",
      "     |      XGBModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      sklearn.base.ClassifierMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, learning_rate: float = 1.0, subsample: float = 0.8, colsample_bynode: float = 0.8, reg_lambda: float = 1e-05, **kwargs: Any)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X: Any, y: Any, *, sample_weight: Optional[Any] = None, base_margin: Optional[Any] = None, eval_set: Optional[Sequence[Tuple[Any, Any]]] = None, verbose: Union[bool, int, NoneType] = True, xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None, sample_weight_eval_set: Optional[Sequence[Any]] = None, base_margin_eval_set: Optional[Sequence[Any]] = None, feature_weights: Optional[Any] = None) -> 'XGBRFClassifier'\n",
      "     |      Fit gradient boosting classifier.\n",
      "     |      \n",
      "     |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      "     |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      "     |      pass ``xgb_model`` argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      "     |      \n",
      "     |          When the ``tree_method`` is set to ``hist``, internally, the\n",
      "     |          :py:class:`QuantileDMatrix` will be used instead of the :py:class:`DMatrix`\n",
      "     |          for conserving memory. However, this has performance implications when the\n",
      "     |          device of input data is not matched with algorithm. For instance, if the\n",
      "     |          input is a numpy array on CPU but ``cuda`` is used for training, then the\n",
      "     |          data is first processed on CPU then transferred to GPU.\n",
      "     |      y :\n",
      "     |          Labels\n",
      "     |      sample_weight :\n",
      "     |          instance weights\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      eval_set :\n",
      "     |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      "     |          metrics will be computed.\n",
      "     |          Validation metrics will help us track the performance of the model.\n",
      "     |      \n",
      "     |      verbose :\n",
      "     |          If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      "     |          measured on the validation set is printed to stdout at each boosting stage.\n",
      "     |          If `verbose` is an integer, the evaluation metric is printed at each\n",
      "     |          `verbose` boosting stage. The last boosting stage / the boosting stage found\n",
      "     |          by using `early_stopping_rounds` is also printed.\n",
      "     |      xgb_model :\n",
      "     |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      "     |          loaded before training (allows training continuation).\n",
      "     |      sample_weight_eval_set :\n",
      "     |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      "     |          object storing instance weights for the i-th validation set.\n",
      "     |      base_margin_eval_set :\n",
      "     |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      "     |          object storing base margin for the i-th validation set.\n",
      "     |      feature_weights :\n",
      "     |          Weight for each feature, defines the probability of each feature being\n",
      "     |          selected when colsample is being used.  All values must be greater than 0,\n",
      "     |          otherwise a `ValueError` is thrown.\n",
      "     |  \n",
      "     |  get_num_boosting_rounds(self) -> int\n",
      "     |      Gets the number of xgboost boosting rounds.\n",
      "     |  \n",
      "     |  get_xgb_params(self) -> Dict[str, Any]\n",
      "     |      Get xgboost specific parameters.\n",
      "     |  \n",
      "     |  set_fit_request(self: xgboost.sklearn.XGBRFClassifier, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', base_margin_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_weights: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', verbose: Union[bool, NoneType, str] = '$UNCHANGED$', xgb_model: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRFClassifier\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      base_margin_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      feature_weights : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``feature_weights`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      verbose : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``verbose`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      xgb_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``xgb_model`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_predict_proba_request(self: xgboost.sklearn.XGBRFClassifier, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRFClassifier\n",
      "     |      Request metadata passed to the ``predict_proba`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``predict_proba`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict_proba``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``predict_proba``.\n",
      "     |      \n",
      "     |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``iteration_range`` parameter in ``predict_proba``.\n",
      "     |      \n",
      "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``validate_features`` parameter in ``predict_proba``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_predict_request(self: xgboost.sklearn.XGBRFClassifier, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$', output_margin: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRFClassifier\n",
      "     |      Request metadata passed to the ``predict`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``iteration_range`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      output_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``output_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_score_request(self: xgboost.sklearn.XGBRFClassifier, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRFClassifier\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from XGBClassifier:\n",
      "     |  \n",
      "     |  predict(self, X: Any, output_margin: bool = False, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> Any\n",
      "     |      Predict with `X`.  If the model is trained with early stopping, then\n",
      "     |      :py:attr:`best_iteration` is used automatically. The estimator uses\n",
      "     |      `inplace_predict` by default and falls back to using :py:class:`DMatrix` if\n",
      "     |      devices between the data and the estimator don't match.\n",
      "     |      \n",
      "     |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Data to predict with.\n",
      "     |      output_margin :\n",
      "     |          Whether to output the raw untransformed margin value.\n",
      "     |      validate_features :\n",
      "     |          When this is True, validate that the Booster's and data's feature_names are\n",
      "     |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      iteration_range :\n",
      "     |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      "     |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      "     |          20)``, then only the forests built during [10, 20) (half open set) rounds\n",
      "     |          are used in this prediction.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction\n",
      "     |  \n",
      "     |  predict_proba(self, X: Any, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> numpy.ndarray\n",
      "     |      Predict the probability of each `X` example being of a given class. If the\n",
      "     |      model is trained with early stopping, then :py:attr:`best_iteration` is used\n",
      "     |      automatically. The estimator uses `inplace_predict` by default and falls back to\n",
      "     |      using :py:class:`DMatrix` if devices between the data and the estimator don't\n",
      "     |      match.\n",
      "     |      \n",
      "     |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      "     |      validate_features :\n",
      "     |          When this is True, validate that the Booster's and data's feature_names are\n",
      "     |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      iteration_range :\n",
      "     |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      "     |          random forest is trained with 100 rounds.  Specifying `iteration_range=(10,\n",
      "     |          20)`, then only the forests built during [10, 20) (half open set) rounds are\n",
      "     |          used in this prediction.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction :\n",
      "     |          a numpy array of shape array-like of shape (n_samples, n_classes) with the\n",
      "     |          probability of each data example being of a given class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from XGBClassifier:\n",
      "     |  \n",
      "     |  classes_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from XGBModel:\n",
      "     |  \n",
      "     |  __sklearn_is_fitted__(self) -> bool\n",
      "     |  \n",
      "     |  apply(self, X: Any, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> numpy.ndarray\n",
      "     |      Return the predicted leaf every tree for each sample. If the model is trained\n",
      "     |      with early stopping, then :py:attr:`best_iteration` is used automatically.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like, shape=[n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      \n",
      "     |      iteration_range :\n",
      "     |          See :py:meth:`predict`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      "     |          For each datapoint x in X and for each tree, return the index of the\n",
      "     |          leaf x ends up in. Leaves are numbered within\n",
      "     |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      "     |  \n",
      "     |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      "     |      Return the evaluation results.\n",
      "     |      \n",
      "     |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      "     |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      "     |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      "     |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      "     |      function.\n",
      "     |      \n",
      "     |      The returned evaluation result is a dictionary:\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      "     |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      evals_result\n",
      "     |  \n",
      "     |  get_booster(self) -> xgboost.core.Booster\n",
      "     |      Get the underlying xgboost Booster of this model.\n",
      "     |      \n",
      "     |      This will raise an exception when fit was not called\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      booster : a xgboost booster of underlying model\n",
      "     |  \n",
      "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      "     |      Get parameters.\n",
      "     |  \n",
      "     |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      "     |      Load the model from a file or a bytearray.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.load_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.load_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Input file name or memory buffer(see also save_raw)\n",
      "     |  \n",
      "     |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.save_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.save_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Output file name\n",
      "     |  \n",
      "     |  set_params(self, **params: Any) -> 'XGBModel'\n",
      "     |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      "     |      allow unknown kwargs. This allows using the full range of xgboost\n",
      "     |      parameters that are not defined as member variables in sklearn grid\n",
      "     |      search.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from XGBModel:\n",
      "     |  \n",
      "     |  best_iteration\n",
      "     |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      "     |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      "     |  \n",
      "     |  best_score\n",
      "     |      The best score obtained by early stopping.\n",
      "     |  \n",
      "     |  coef_\n",
      "     |      Coefficients property\n",
      "     |      \n",
      "     |      .. note:: Coefficients are defined only for linear learners\n",
      "     |      \n",
      "     |          Coefficients are only defined when the linear model is chosen as\n",
      "     |          base learner (`booster=gblinear`). It is not defined for other base\n",
      "     |          learner types, such as tree learners (`booster=gbtree`).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Feature importances property, return depends on `importance_type`\n",
      "     |      parameter. When model trained with multi-class/multi-label/multi-target dataset,\n",
      "     |      the feature importance is \"averaged\" over all targets. The \"average\" is defined\n",
      "     |      based on the importance type. For instance, if the importance type is\n",
      "     |      \"total_gain\", then the score is sum of loss change for each split from all\n",
      "     |      trees.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      "     |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      "     |  \n",
      "     |  feature_names_in_\n",
      "     |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has\n",
      "     |      feature names that are all strings.\n",
      "     |  \n",
      "     |  intercept_\n",
      "     |      Intercept (bias) property\n",
      "     |      \n",
      "     |      For tree-based model, the returned value is the `base_score`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |      Number of features seen during :py:meth:`fit`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the mean accuracy on the given test data and labels.\n",
      "     |      \n",
      "     |      In multi-label classification, this is the subset accuracy\n",
      "     |      which is a harsh metric since you require for each sample that\n",
      "     |      each label set be correctly predicted.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True labels for `X`.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          Mean accuracy of ``self.predict(X)`` w.r.t. `y`.\n",
      "    \n",
      "    class XGBRFRegressor(XGBRegressor)\n",
      "     |  XGBRFRegressor(*, learning_rate: float = 1.0, subsample: float = 0.8, colsample_bynode: float = 0.8, reg_lambda: float = 1e-05, **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  scikit-learn API for XGBoost random forest regression.\n",
      "     |  See :doc:`/python/sklearn_estimator` for more information.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |      n_estimators : Optional[int]\n",
      "     |          Number of trees in random forest to fit.\n",
      "     |  \n",
      "     |      max_depth :  typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum tree depth for base learners.\n",
      "     |  \n",
      "     |      max_leaves : typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum number of leaves; 0 indicates no limit.\n",
      "     |  \n",
      "     |      max_bin : typing.Optional[int]\n",
      "     |  \n",
      "     |          If using histogram-based algorithm, maximum number of bins per feature\n",
      "     |  \n",
      "     |      grow_policy : typing.Optional[str]\n",
      "     |  \n",
      "     |          Tree growing policy.\n",
      "     |  \n",
      "     |          - depthwise: Favors splitting at nodes closest to the node,\n",
      "     |          - lossguide: Favors splitting at nodes with highest loss change.\n",
      "     |  \n",
      "     |      learning_rate : typing.Optional[float]\n",
      "     |  \n",
      "     |          Boosting learning rate (xgb's \"eta\")\n",
      "     |  \n",
      "     |      verbosity : typing.Optional[int]\n",
      "     |  \n",
      "     |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      "     |  \n",
      "     |      objective : typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      "     |  \n",
      "     |          Specify the learning task and the corresponding learning objective or a custom\n",
      "     |          objective function to be used.\n",
      "     |  \n",
      "     |          For custom objective, see :doc:`/tutorials/custom_metric_obj` and\n",
      "     |          :ref:`custom-obj-metric` for more information, along with the end note for\n",
      "     |          function signatures.\n",
      "     |  \n",
      "     |      booster: typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which booster to use: ``gbtree``, ``gblinear`` or ``dart``.\n",
      "     |  \n",
      "     |      tree_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      "     |          default, XGBoost will choose the most conservative option available.  It's\n",
      "     |          recommended to study this option from the parameters document :doc:`tree method\n",
      "     |          </treemethod>`\n",
      "     |  \n",
      "     |      n_jobs : typing.Optional[int]\n",
      "     |  \n",
      "     |          Number of parallel threads used to run xgboost.  When used with other\n",
      "     |          Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      "     |          parallelize and balance the threads.  Creating thread contention will\n",
      "     |          significantly slow down both algorithms.\n",
      "     |  \n",
      "     |      gamma : typing.Optional[float]\n",
      "     |  \n",
      "     |          (min_split_loss) Minimum loss reduction required to make a further partition on\n",
      "     |          a leaf node of the tree.\n",
      "     |  \n",
      "     |      min_child_weight : typing.Optional[float]\n",
      "     |  \n",
      "     |          Minimum sum of instance weight(hessian) needed in a child.\n",
      "     |  \n",
      "     |      max_delta_step : typing.Optional[float]\n",
      "     |  \n",
      "     |          Maximum delta step we allow each tree's weight estimation to be.\n",
      "     |  \n",
      "     |      subsample : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of the training instance.\n",
      "     |  \n",
      "     |      sampling_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Sampling method. Used only by the GPU version of ``hist`` tree method.\n",
      "     |  \n",
      "     |          - ``uniform``: Select random training instances uniformly.\n",
      "     |          - ``gradient_based``: Select random training instances with higher probability\n",
      "     |              when the gradient and hessian are larger. (cf. CatBoost)\n",
      "     |  \n",
      "     |      colsample_bytree : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |  \n",
      "     |      colsample_bylevel : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each level.\n",
      "     |  \n",
      "     |      colsample_bynode : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each split.\n",
      "     |  \n",
      "     |      reg_alpha : typing.Optional[float]\n",
      "     |  \n",
      "     |          L1 regularization term on weights (xgb's alpha).\n",
      "     |  \n",
      "     |      reg_lambda : typing.Optional[float]\n",
      "     |  \n",
      "     |          L2 regularization term on weights (xgb's lambda).\n",
      "     |  \n",
      "     |      scale_pos_weight : typing.Optional[float]\n",
      "     |          Balancing of positive and negative weights.\n",
      "     |  \n",
      "     |      base_score : typing.Optional[float]\n",
      "     |  \n",
      "     |          The initial prediction score of all instances, global bias.\n",
      "     |  \n",
      "     |      random_state : typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]\n",
      "     |  \n",
      "     |          Random number seed.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      "     |             it uses Hogwild algorithm.\n",
      "     |  \n",
      "     |      missing : float\n",
      "     |  \n",
      "     |          Value in the data which needs to be present as a missing value. Default to\n",
      "     |          :py:data:`numpy.nan`.\n",
      "     |  \n",
      "     |      num_parallel_tree: typing.Optional[int]\n",
      "     |  \n",
      "     |          Used for boosting random forest.\n",
      "     |  \n",
      "     |      monotone_constraints : typing.Union[typing.Dict[str, int], str, NoneType]\n",
      "     |  \n",
      "     |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      "     |          for more information.\n",
      "     |  \n",
      "     |      interaction_constraints : typing.Union[str, typing.List[typing.Tuple[str]], NoneType]\n",
      "     |  \n",
      "     |          Constraints for interaction representing permitted interactions.  The\n",
      "     |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      "     |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      "     |          allowed to interact with each other.  See :doc:`tutorial\n",
      "     |          </tutorials/feature_interaction_constraint>` for more information\n",
      "     |  \n",
      "     |      importance_type: typing.Optional[str]\n",
      "     |  \n",
      "     |          The feature importance type for the feature_importances\\_ property:\n",
      "     |  \n",
      "     |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      "     |            \"total_cover\".\n",
      "     |          * For linear model, only \"weight\" is defined and it's the normalized\n",
      "     |            coefficients without bias.\n",
      "     |  \n",
      "     |      device : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          Device ordinal, available options are `cpu`, `cuda`, and `gpu`.\n",
      "     |  \n",
      "     |      validate_parameters : typing.Optional[bool]\n",
      "     |  \n",
      "     |          Give warnings for unknown parameter.\n",
      "     |  \n",
      "     |      enable_categorical : bool\n",
      "     |  \n",
      "     |          See the same parameter of :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      feature_types : typing.Optional[typing.Sequence[str]]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          Used for specifying feature types without constructing a dataframe. See\n",
      "     |          :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      max_cat_to_onehot : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      "     |          for categorical data.  When number of categories is lesser than the threshold\n",
      "     |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      "     |          into children nodes. Also, `enable_categorical` needs to be set to have\n",
      "     |          categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      max_cat_threshold : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          Maximum number of categories considered for each split. Used only by\n",
      "     |          partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      "     |          needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      multi_strategy : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is working-in-progress.\n",
      "     |  \n",
      "     |          The strategy used for training multi-target models, including multi-target\n",
      "     |          regression and multi-class classification. See :doc:`/tutorials/multioutput` for\n",
      "     |          more information.\n",
      "     |  \n",
      "     |          - ``one_output_per_tree``: One model for each target.\n",
      "     |          - ``multi_output_tree``:  Use multi-target trees.\n",
      "     |  \n",
      "     |      eval_metric : typing.Union[str, typing.List[str], typing.Callable, NoneType]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      "     |          string or list of strings as names of predefined metric in XGBoost (See\n",
      "     |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any\n",
      "     |          other user defined metric that looks like `sklearn.metrics`.\n",
      "     |  \n",
      "     |          If custom objective is also provided, then custom metric should implement the\n",
      "     |          corresponding reverse link function.\n",
      "     |  \n",
      "     |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      "     |          object is provided, it's assumed to be a cost function and by default XGBoost\n",
      "     |          will minimize the result during early stopping.\n",
      "     |  \n",
      "     |          For advanced usage on Early stopping like directly choosing to maximize instead\n",
      "     |          of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more\n",
      "     |          information.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              from sklearn.datasets import load_diabetes\n",
      "     |              from sklearn.metrics import mean_absolute_error\n",
      "     |              X, y = load_diabetes(return_X_y=True)\n",
      "     |              reg = xgb.XGBRegressor(\n",
      "     |                  tree_method=\"hist\",\n",
      "     |                  eval_metric=mean_absolute_error,\n",
      "     |              )\n",
      "     |              reg.fit(X, y, eval_set=[(X, y)])\n",
      "     |  \n",
      "     |      early_stopping_rounds : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          - Activates early stopping. Validation metric needs to improve at least once in\n",
      "     |            every **early_stopping_rounds** round(s) to continue training.  Requires at\n",
      "     |            least one item in **eval_set** in :py:meth:`fit`.\n",
      "     |  \n",
      "     |          - If early stopping occurs, the model will have two additional attributes:\n",
      "     |            :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the\n",
      "     |            :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal\n",
      "     |            number of trees during inference. If users want to access the full model\n",
      "     |            (including trees built after early stopping), they can specify the\n",
      "     |            `iteration_range` in these inference methods. In addition, other utilities\n",
      "     |            like model plotting can also use the entire model.\n",
      "     |  \n",
      "     |          - If you prefer to discard the trees after `best_iteration`, consider using the\n",
      "     |            callback function :py:class:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          - If there's more than one item in **eval_set**, the last entry will be used for\n",
      "     |            early stopping.  If there's more than one metric in **eval_metric**, the last\n",
      "     |            metric will be used for early stopping.\n",
      "     |  \n",
      "     |      callbacks : typing.Optional[typing.List[xgboost.callback.TrainingCallback]]\n",
      "     |  \n",
      "     |          List of callback functions that are applied at end of each iteration.\n",
      "     |          It is possible to use predefined callbacks by using\n",
      "     |          :ref:`Callback API <callback_api>`.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             States in callback are not preserved during training, which means callback\n",
      "     |             objects can not be reused for multiple training sessions without\n",
      "     |             reinitialization or deepcopy.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              for params in parameters_grid:\n",
      "     |                  # be sure to (re)initialize the callbacks before each run\n",
      "     |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "     |                  reg = xgboost.XGBRegressor(**params, callbacks=callbacks)\n",
      "     |                  reg.fit(X, y)\n",
      "     |  \n",
      "     |      kwargs : typing.Optional[typing.Any]\n",
      "     |  \n",
      "     |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      "     |          can be found :doc:`here </parameter>`.\n",
      "     |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      "     |          dict simultaneously will result in a TypeError.\n",
      "     |  \n",
      "     |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      "     |  \n",
      "     |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      "     |              that parameters passed via this argument will interact properly\n",
      "     |              with scikit-learn.\n",
      "     |  \n",
      "     |          .. note::  Custom objective function\n",
      "     |  \n",
      "     |              A custom objective function can be provided for the ``objective``\n",
      "     |              parameter. In this case, it should have the signature ``objective(y_true,\n",
      "     |              y_pred) -> [grad, hess]`` or ``objective(y_true, y_pred, *, sample_weight)\n",
      "     |              -> [grad, hess]``:\n",
      "     |  \n",
      "     |              y_true: array_like of shape [n_samples]\n",
      "     |                  The target values\n",
      "     |              y_pred: array_like of shape [n_samples]\n",
      "     |                  The predicted values\n",
      "     |              sample_weight :\n",
      "     |                  Optional sample weights.\n",
      "     |  \n",
      "     |              grad: array_like of shape [n_samples]\n",
      "     |                  The value of the gradient for each sample point.\n",
      "     |              hess: array_like of shape [n_samples]\n",
      "     |                  The value of the second derivative for each sample point\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      XGBRFRegressor\n",
      "     |      XGBRegressor\n",
      "     |      XGBModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, learning_rate: float = 1.0, subsample: float = 0.8, colsample_bynode: float = 0.8, reg_lambda: float = 1e-05, **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  fit(self, X: Any, y: Any, *, sample_weight: Optional[Any] = None, base_margin: Optional[Any] = None, eval_set: Optional[Sequence[Tuple[Any, Any]]] = None, verbose: Union[bool, int, NoneType] = True, xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None, sample_weight_eval_set: Optional[Sequence[Any]] = None, base_margin_eval_set: Optional[Sequence[Any]] = None, feature_weights: Optional[Any] = None) -> 'XGBRFRegressor'\n",
      "     |      Fit gradient boosting model.\n",
      "     |      \n",
      "     |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      "     |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      "     |      pass ``xgb_model`` argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      "     |      \n",
      "     |          When the ``tree_method`` is set to ``hist``, internally, the\n",
      "     |          :py:class:`QuantileDMatrix` will be used instead of the :py:class:`DMatrix`\n",
      "     |          for conserving memory. However, this has performance implications when the\n",
      "     |          device of input data is not matched with algorithm. For instance, if the\n",
      "     |          input is a numpy array on CPU but ``cuda`` is used for training, then the\n",
      "     |          data is first processed on CPU then transferred to GPU.\n",
      "     |      y :\n",
      "     |          Labels\n",
      "     |      sample_weight :\n",
      "     |          instance weights\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      eval_set :\n",
      "     |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      "     |          metrics will be computed.\n",
      "     |          Validation metrics will help us track the performance of the model.\n",
      "     |      \n",
      "     |      verbose :\n",
      "     |          If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      "     |          measured on the validation set is printed to stdout at each boosting stage.\n",
      "     |          If `verbose` is an integer, the evaluation metric is printed at each\n",
      "     |          `verbose` boosting stage. The last boosting stage / the boosting stage found\n",
      "     |          by using `early_stopping_rounds` is also printed.\n",
      "     |      xgb_model :\n",
      "     |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      "     |          loaded before training (allows training continuation).\n",
      "     |      sample_weight_eval_set :\n",
      "     |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      "     |          object storing instance weights for the i-th validation set.\n",
      "     |      base_margin_eval_set :\n",
      "     |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      "     |          object storing base margin for the i-th validation set.\n",
      "     |      feature_weights :\n",
      "     |          Weight for each feature, defines the probability of each feature being\n",
      "     |          selected when colsample is being used.  All values must be greater than 0,\n",
      "     |          otherwise a `ValueError` is thrown.\n",
      "     |  \n",
      "     |  get_num_boosting_rounds(self) -> int\n",
      "     |      Gets the number of xgboost boosting rounds.\n",
      "     |  \n",
      "     |  get_xgb_params(self) -> Dict[str, Any]\n",
      "     |      Get xgboost specific parameters.\n",
      "     |  \n",
      "     |  set_fit_request(self: xgboost.sklearn.XGBRFRegressor, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', base_margin_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_weights: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', verbose: Union[bool, NoneType, str] = '$UNCHANGED$', xgb_model: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRFRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      base_margin_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      feature_weights : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``feature_weights`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      verbose : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``verbose`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      xgb_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``xgb_model`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_predict_request(self: xgboost.sklearn.XGBRFRegressor, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$', output_margin: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRFRegressor\n",
      "     |      Request metadata passed to the ``predict`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``iteration_range`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      output_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``output_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_score_request(self: xgboost.sklearn.XGBRFRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRFRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from XGBModel:\n",
      "     |  \n",
      "     |  __sklearn_is_fitted__(self) -> bool\n",
      "     |  \n",
      "     |  apply(self, X: Any, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> numpy.ndarray\n",
      "     |      Return the predicted leaf every tree for each sample. If the model is trained\n",
      "     |      with early stopping, then :py:attr:`best_iteration` is used automatically.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like, shape=[n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      \n",
      "     |      iteration_range :\n",
      "     |          See :py:meth:`predict`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      "     |          For each datapoint x in X and for each tree, return the index of the\n",
      "     |          leaf x ends up in. Leaves are numbered within\n",
      "     |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      "     |  \n",
      "     |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      "     |      Return the evaluation results.\n",
      "     |      \n",
      "     |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      "     |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      "     |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      "     |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      "     |      function.\n",
      "     |      \n",
      "     |      The returned evaluation result is a dictionary:\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      "     |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      evals_result\n",
      "     |  \n",
      "     |  get_booster(self) -> xgboost.core.Booster\n",
      "     |      Get the underlying xgboost Booster of this model.\n",
      "     |      \n",
      "     |      This will raise an exception when fit was not called\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      booster : a xgboost booster of underlying model\n",
      "     |  \n",
      "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      "     |      Get parameters.\n",
      "     |  \n",
      "     |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      "     |      Load the model from a file or a bytearray.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.load_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.load_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Input file name or memory buffer(see also save_raw)\n",
      "     |  \n",
      "     |  predict(self, X: Any, output_margin: bool = False, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> Any\n",
      "     |      Predict with `X`.  If the model is trained with early stopping, then\n",
      "     |      :py:attr:`best_iteration` is used automatically. The estimator uses\n",
      "     |      `inplace_predict` by default and falls back to using :py:class:`DMatrix` if\n",
      "     |      devices between the data and the estimator don't match.\n",
      "     |      \n",
      "     |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Data to predict with.\n",
      "     |      output_margin :\n",
      "     |          Whether to output the raw untransformed margin value.\n",
      "     |      validate_features :\n",
      "     |          When this is True, validate that the Booster's and data's feature_names are\n",
      "     |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      iteration_range :\n",
      "     |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      "     |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      "     |          20)``, then only the forests built during [10, 20) (half open set) rounds\n",
      "     |          are used in this prediction.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction\n",
      "     |  \n",
      "     |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.save_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.save_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Output file name\n",
      "     |  \n",
      "     |  set_params(self, **params: Any) -> 'XGBModel'\n",
      "     |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      "     |      allow unknown kwargs. This allows using the full range of xgboost\n",
      "     |      parameters that are not defined as member variables in sklearn grid\n",
      "     |      search.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from XGBModel:\n",
      "     |  \n",
      "     |  best_iteration\n",
      "     |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      "     |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      "     |  \n",
      "     |  best_score\n",
      "     |      The best score obtained by early stopping.\n",
      "     |  \n",
      "     |  coef_\n",
      "     |      Coefficients property\n",
      "     |      \n",
      "     |      .. note:: Coefficients are defined only for linear learners\n",
      "     |      \n",
      "     |          Coefficients are only defined when the linear model is chosen as\n",
      "     |          base learner (`booster=gblinear`). It is not defined for other base\n",
      "     |          learner types, such as tree learners (`booster=gbtree`).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Feature importances property, return depends on `importance_type`\n",
      "     |      parameter. When model trained with multi-class/multi-label/multi-target dataset,\n",
      "     |      the feature importance is \"averaged\" over all targets. The \"average\" is defined\n",
      "     |      based on the importance type. For instance, if the importance type is\n",
      "     |      \"total_gain\", then the score is sum of loss change for each split from all\n",
      "     |      trees.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      "     |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      "     |  \n",
      "     |  feature_names_in_\n",
      "     |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has\n",
      "     |      feature names that are all strings.\n",
      "     |  \n",
      "     |  intercept_\n",
      "     |      Intercept (bias) property\n",
      "     |      \n",
      "     |      For tree-based model, the returned value is the `base_score`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |      Number of features seen during :py:meth:`fit`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |      \n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "    \n",
      "    class XGBRanker(XGBModel, XGBRankerMixIn)\n",
      "     |  XGBRanker(*, objective: str = 'rank:ndcg', **kwargs: Any)\n",
      "     |  \n",
      "     |  Implementation of the Scikit-Learn API for XGBoost Ranking.\n",
      "     |  \n",
      "     |  See :doc:`Learning to Rank </tutorials/learning_to_rank>` for an introducion.\n",
      "     |  \n",
      "     |      \n",
      "     |  See :doc:`/python/sklearn_estimator` for more information.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |      n_estimators : typing.Optional[int]\n",
      "     |          Number of gradient boosted trees.  Equivalent to number of boosting\n",
      "     |          rounds.\n",
      "     |  \n",
      "     |      max_depth :  typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum tree depth for base learners.\n",
      "     |  \n",
      "     |      max_leaves : typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum number of leaves; 0 indicates no limit.\n",
      "     |  \n",
      "     |      max_bin : typing.Optional[int]\n",
      "     |  \n",
      "     |          If using histogram-based algorithm, maximum number of bins per feature\n",
      "     |  \n",
      "     |      grow_policy : typing.Optional[str]\n",
      "     |  \n",
      "     |          Tree growing policy.\n",
      "     |  \n",
      "     |          - depthwise: Favors splitting at nodes closest to the node,\n",
      "     |          - lossguide: Favors splitting at nodes with highest loss change.\n",
      "     |  \n",
      "     |      learning_rate : typing.Optional[float]\n",
      "     |  \n",
      "     |          Boosting learning rate (xgb's \"eta\")\n",
      "     |  \n",
      "     |      verbosity : typing.Optional[int]\n",
      "     |  \n",
      "     |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      "     |  \n",
      "     |      objective : typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      "     |  \n",
      "     |          Specify the learning task and the corresponding learning objective or a custom\n",
      "     |          objective function to be used.\n",
      "     |  \n",
      "     |          For custom objective, see :doc:`/tutorials/custom_metric_obj` and\n",
      "     |          :ref:`custom-obj-metric` for more information, along with the end note for\n",
      "     |          function signatures.\n",
      "     |  \n",
      "     |      booster: typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which booster to use: ``gbtree``, ``gblinear`` or ``dart``.\n",
      "     |  \n",
      "     |      tree_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      "     |          default, XGBoost will choose the most conservative option available.  It's\n",
      "     |          recommended to study this option from the parameters document :doc:`tree method\n",
      "     |          </treemethod>`\n",
      "     |  \n",
      "     |      n_jobs : typing.Optional[int]\n",
      "     |  \n",
      "     |          Number of parallel threads used to run xgboost.  When used with other\n",
      "     |          Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      "     |          parallelize and balance the threads.  Creating thread contention will\n",
      "     |          significantly slow down both algorithms.\n",
      "     |  \n",
      "     |      gamma : typing.Optional[float]\n",
      "     |  \n",
      "     |          (min_split_loss) Minimum loss reduction required to make a further partition on\n",
      "     |          a leaf node of the tree.\n",
      "     |  \n",
      "     |      min_child_weight : typing.Optional[float]\n",
      "     |  \n",
      "     |          Minimum sum of instance weight(hessian) needed in a child.\n",
      "     |  \n",
      "     |      max_delta_step : typing.Optional[float]\n",
      "     |  \n",
      "     |          Maximum delta step we allow each tree's weight estimation to be.\n",
      "     |  \n",
      "     |      subsample : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of the training instance.\n",
      "     |  \n",
      "     |      sampling_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Sampling method. Used only by the GPU version of ``hist`` tree method.\n",
      "     |  \n",
      "     |          - ``uniform``: Select random training instances uniformly.\n",
      "     |          - ``gradient_based``: Select random training instances with higher probability\n",
      "     |              when the gradient and hessian are larger. (cf. CatBoost)\n",
      "     |  \n",
      "     |      colsample_bytree : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |  \n",
      "     |      colsample_bylevel : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each level.\n",
      "     |  \n",
      "     |      colsample_bynode : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each split.\n",
      "     |  \n",
      "     |      reg_alpha : typing.Optional[float]\n",
      "     |  \n",
      "     |          L1 regularization term on weights (xgb's alpha).\n",
      "     |  \n",
      "     |      reg_lambda : typing.Optional[float]\n",
      "     |  \n",
      "     |          L2 regularization term on weights (xgb's lambda).\n",
      "     |  \n",
      "     |      scale_pos_weight : typing.Optional[float]\n",
      "     |          Balancing of positive and negative weights.\n",
      "     |  \n",
      "     |      base_score : typing.Optional[float]\n",
      "     |  \n",
      "     |          The initial prediction score of all instances, global bias.\n",
      "     |  \n",
      "     |      random_state : typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]\n",
      "     |  \n",
      "     |          Random number seed.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      "     |             it uses Hogwild algorithm.\n",
      "     |  \n",
      "     |      missing : float\n",
      "     |  \n",
      "     |          Value in the data which needs to be present as a missing value. Default to\n",
      "     |          :py:data:`numpy.nan`.\n",
      "     |  \n",
      "     |      num_parallel_tree: typing.Optional[int]\n",
      "     |  \n",
      "     |          Used for boosting random forest.\n",
      "     |  \n",
      "     |      monotone_constraints : typing.Union[typing.Dict[str, int], str, NoneType]\n",
      "     |  \n",
      "     |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      "     |          for more information.\n",
      "     |  \n",
      "     |      interaction_constraints : typing.Union[str, typing.List[typing.Tuple[str]], NoneType]\n",
      "     |  \n",
      "     |          Constraints for interaction representing permitted interactions.  The\n",
      "     |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      "     |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      "     |          allowed to interact with each other.  See :doc:`tutorial\n",
      "     |          </tutorials/feature_interaction_constraint>` for more information\n",
      "     |  \n",
      "     |      importance_type: typing.Optional[str]\n",
      "     |  \n",
      "     |          The feature importance type for the feature_importances\\_ property:\n",
      "     |  \n",
      "     |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      "     |            \"total_cover\".\n",
      "     |          * For linear model, only \"weight\" is defined and it's the normalized\n",
      "     |            coefficients without bias.\n",
      "     |  \n",
      "     |      device : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          Device ordinal, available options are `cpu`, `cuda`, and `gpu`.\n",
      "     |  \n",
      "     |      validate_parameters : typing.Optional[bool]\n",
      "     |  \n",
      "     |          Give warnings for unknown parameter.\n",
      "     |  \n",
      "     |      enable_categorical : bool\n",
      "     |  \n",
      "     |          See the same parameter of :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      feature_types : typing.Optional[typing.Sequence[str]]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          Used for specifying feature types without constructing a dataframe. See\n",
      "     |          :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      max_cat_to_onehot : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      "     |          for categorical data.  When number of categories is lesser than the threshold\n",
      "     |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      "     |          into children nodes. Also, `enable_categorical` needs to be set to have\n",
      "     |          categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      max_cat_threshold : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          Maximum number of categories considered for each split. Used only by\n",
      "     |          partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      "     |          needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      multi_strategy : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is working-in-progress.\n",
      "     |  \n",
      "     |          The strategy used for training multi-target models, including multi-target\n",
      "     |          regression and multi-class classification. See :doc:`/tutorials/multioutput` for\n",
      "     |          more information.\n",
      "     |  \n",
      "     |          - ``one_output_per_tree``: One model for each target.\n",
      "     |          - ``multi_output_tree``:  Use multi-target trees.\n",
      "     |  \n",
      "     |      eval_metric : typing.Union[str, typing.List[str], typing.Callable, NoneType]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      "     |          string or list of strings as names of predefined metric in XGBoost (See\n",
      "     |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any\n",
      "     |          other user defined metric that looks like `sklearn.metrics`.\n",
      "     |  \n",
      "     |          If custom objective is also provided, then custom metric should implement the\n",
      "     |          corresponding reverse link function.\n",
      "     |  \n",
      "     |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      "     |          object is provided, it's assumed to be a cost function and by default XGBoost\n",
      "     |          will minimize the result during early stopping.\n",
      "     |  \n",
      "     |          For advanced usage on Early stopping like directly choosing to maximize instead\n",
      "     |          of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more\n",
      "     |          information.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              from sklearn.datasets import load_diabetes\n",
      "     |              from sklearn.metrics import mean_absolute_error\n",
      "     |              X, y = load_diabetes(return_X_y=True)\n",
      "     |              reg = xgb.XGBRegressor(\n",
      "     |                  tree_method=\"hist\",\n",
      "     |                  eval_metric=mean_absolute_error,\n",
      "     |              )\n",
      "     |              reg.fit(X, y, eval_set=[(X, y)])\n",
      "     |  \n",
      "     |      early_stopping_rounds : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          - Activates early stopping. Validation metric needs to improve at least once in\n",
      "     |            every **early_stopping_rounds** round(s) to continue training.  Requires at\n",
      "     |            least one item in **eval_set** in :py:meth:`fit`.\n",
      "     |  \n",
      "     |          - If early stopping occurs, the model will have two additional attributes:\n",
      "     |            :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the\n",
      "     |            :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal\n",
      "     |            number of trees during inference. If users want to access the full model\n",
      "     |            (including trees built after early stopping), they can specify the\n",
      "     |            `iteration_range` in these inference methods. In addition, other utilities\n",
      "     |            like model plotting can also use the entire model.\n",
      "     |  \n",
      "     |          - If you prefer to discard the trees after `best_iteration`, consider using the\n",
      "     |            callback function :py:class:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          - If there's more than one item in **eval_set**, the last entry will be used for\n",
      "     |            early stopping.  If there's more than one metric in **eval_metric**, the last\n",
      "     |            metric will be used for early stopping.\n",
      "     |  \n",
      "     |      callbacks : typing.Optional[typing.List[xgboost.callback.TrainingCallback]]\n",
      "     |  \n",
      "     |          List of callback functions that are applied at end of each iteration.\n",
      "     |          It is possible to use predefined callbacks by using\n",
      "     |          :ref:`Callback API <callback_api>`.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             States in callback are not preserved during training, which means callback\n",
      "     |             objects can not be reused for multiple training sessions without\n",
      "     |             reinitialization or deepcopy.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              for params in parameters_grid:\n",
      "     |                  # be sure to (re)initialize the callbacks before each run\n",
      "     |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "     |                  reg = xgboost.XGBRegressor(**params, callbacks=callbacks)\n",
      "     |                  reg.fit(X, y)\n",
      "     |  \n",
      "     |      kwargs : typing.Optional[typing.Any]\n",
      "     |  \n",
      "     |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      "     |          can be found :doc:`here </parameter>`.\n",
      "     |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      "     |          dict simultaneously will result in a TypeError.\n",
      "     |  \n",
      "     |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      "     |  \n",
      "     |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      "     |              that parameters passed via this argument will interact properly\n",
      "     |              with scikit-learn.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |              A custom objective function is currently not supported by XGBRanker.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |              Query group information is only required for ranking training but not\n",
      "     |              prediction. Multiple groups can be predicted on a single call to\n",
      "     |              :py:meth:`predict`.\n",
      "     |  \n",
      "     |          When fitting the model with the `group` parameter, your data need to be sorted\n",
      "     |          by the query group first. `group` is an array that contains the size of each\n",
      "     |          query group.\n",
      "     |  \n",
      "     |          Similarly, when fitting the model with the `qid` parameter, the data should be\n",
      "     |          sorted according to query index and `qid` is an array that contains the query\n",
      "     |          index for each training sample.\n",
      "     |  \n",
      "     |          For example, if your original data look like:\n",
      "     |  \n",
      "     |          +-------+-----------+---------------+\n",
      "     |          |   qid |   label   |   features    |\n",
      "     |          +-------+-----------+---------------+\n",
      "     |          |   1   |   0       |   x_1         |\n",
      "     |          +-------+-----------+---------------+\n",
      "     |          |   1   |   1       |   x_2         |\n",
      "     |          +-------+-----------+---------------+\n",
      "     |          |   1   |   0       |   x_3         |\n",
      "     |          +-------+-----------+---------------+\n",
      "     |          |   2   |   0       |   x_4         |\n",
      "     |          +-------+-----------+---------------+\n",
      "     |          |   2   |   1       |   x_5         |\n",
      "     |          +-------+-----------+---------------+\n",
      "     |          |   2   |   1       |   x_6         |\n",
      "     |          +-------+-----------+---------------+\n",
      "     |          |   2   |   1       |   x_7         |\n",
      "     |          +-------+-----------+---------------+\n",
      "     |  \n",
      "     |          then :py:meth:`fit` method can be called with either `group` array as ``[3, 4]``\n",
      "     |          or with `qid` as ``[1, 1, 1, 2, 2, 2, 2]``, that is the qid column.  Also, the\n",
      "     |          `qid` can be a special column of input `X` instead of a separated parameter, see\n",
      "     |          :py:meth:`fit` for more info.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      XGBRanker\n",
      "     |      XGBModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      XGBRankerMixIn\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, objective: str = 'rank:ndcg', **kwargs: Any)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  apply(self, X: Any, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> Any\n",
      "     |      Return the predicted leaf every tree for each sample. If the model is trained\n",
      "     |      with early stopping, then :py:attr:`best_iteration` is used automatically.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like, shape=[n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      \n",
      "     |      iteration_range :\n",
      "     |          See :py:meth:`predict`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      "     |          For each datapoint x in X and for each tree, return the index of the\n",
      "     |          leaf x ends up in. Leaves are numbered within\n",
      "     |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      "     |  \n",
      "     |  fit(self, X: Any, y: Any, *, group: Optional[Any] = None, qid: Optional[Any] = None, sample_weight: Optional[Any] = None, base_margin: Optional[Any] = None, eval_set: Optional[Sequence[Tuple[Any, Any]]] = None, eval_group: Optional[Sequence[Any]] = None, eval_qid: Optional[Sequence[Any]] = None, verbose: Union[bool, int, NoneType] = False, xgb_model: Union[xgboost.core.Booster, str, xgboost.sklearn.XGBModel, NoneType] = None, sample_weight_eval_set: Optional[Sequence[Any]] = None, base_margin_eval_set: Optional[Sequence[Any]] = None, feature_weights: Optional[Any] = None) -> 'XGBRanker'\n",
      "     |      Fit gradient boosting ranker\n",
      "     |      \n",
      "     |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      "     |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      "     |      pass ``xgb_model`` argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      "     |      \n",
      "     |          When this is a :py:class:`pandas.DataFrame` or a :py:class:`cudf.DataFrame`,\n",
      "     |          it may contain a special column called ``qid`` for specifying the query\n",
      "     |          index. Using a special column is the same as using the `qid` parameter,\n",
      "     |          except for being compatible with sklearn utility functions like\n",
      "     |          :py:func:`sklearn.model_selection.cross_validation`. The same convention\n",
      "     |          applies to the :py:meth:`XGBRanker.score` and :py:meth:`XGBRanker.predict`.\n",
      "     |      \n",
      "     |          +-----+----------------+----------------+\n",
      "     |          | qid | feat_0         | feat_1         |\n",
      "     |          +-----+----------------+----------------+\n",
      "     |          | 0   | :math:`x_{00}` | :math:`x_{01}` |\n",
      "     |          +-----+----------------+----------------+\n",
      "     |          | 1   | :math:`x_{10}` | :math:`x_{11}` |\n",
      "     |          +-----+----------------+----------------+\n",
      "     |          | 1   | :math:`x_{20}` | :math:`x_{21}` |\n",
      "     |          +-----+----------------+----------------+\n",
      "     |      \n",
      "     |          When the ``tree_method`` is set to ``hist``, internally, the\n",
      "     |          :py:class:`QuantileDMatrix` will be used instead of the :py:class:`DMatrix`\n",
      "     |          for conserving memory. However, this has performance implications when the\n",
      "     |          device of input data is not matched with algorithm. For instance, if the\n",
      "     |          input is a numpy array on CPU but ``cuda`` is used for training, then the\n",
      "     |          data is first processed on CPU then transferred to GPU.\n",
      "     |      y :\n",
      "     |          Labels\n",
      "     |      group :\n",
      "     |          Size of each query group of training data. Should have as many elements as\n",
      "     |          the query groups in the training data.  If this is set to None, then user\n",
      "     |          must provide qid.\n",
      "     |      qid :\n",
      "     |          Query ID for each training sample.  Should have the size of n_samples.  If\n",
      "     |          this is set to None, then user must provide group or a special column in X.\n",
      "     |      sample_weight :\n",
      "     |          Query group weights\n",
      "     |      \n",
      "     |          .. note:: Weights are per-group for ranking tasks\n",
      "     |      \n",
      "     |              In ranking task, one weight is assigned to each query group/id (not each\n",
      "     |              data point). This is because we only care about the relative ordering of\n",
      "     |              data points within each group, so it doesn't make sense to assign\n",
      "     |              weights to individual data points.\n",
      "     |      \n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      eval_set :\n",
      "     |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      "     |          metrics will be computed.\n",
      "     |          Validation metrics will help us track the performance of the model.\n",
      "     |      eval_group :\n",
      "     |          A list in which ``eval_group[i]`` is the list containing the sizes of all\n",
      "     |          query groups in the ``i``-th pair in **eval_set**.\n",
      "     |      eval_qid :\n",
      "     |          A list in which ``eval_qid[i]`` is the array containing query ID of ``i``-th\n",
      "     |          pair in **eval_set**. The special column convention in `X` applies to\n",
      "     |          validation datasets as well.\n",
      "     |      \n",
      "     |      verbose :\n",
      "     |          If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      "     |          measured on the validation set is printed to stdout at each boosting stage.\n",
      "     |          If `verbose` is an integer, the evaluation metric is printed at each\n",
      "     |          `verbose` boosting stage. The last boosting stage / the boosting stage found\n",
      "     |          by using `early_stopping_rounds` is also printed.\n",
      "     |      xgb_model :\n",
      "     |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      "     |          loaded before training (allows training continuation).\n",
      "     |      sample_weight_eval_set :\n",
      "     |          A list of the form [L_1, L_2, ..., L_n], where each L_i is a list of\n",
      "     |          group weights on the i-th validation set.\n",
      "     |      \n",
      "     |          .. note:: Weights are per-group for ranking tasks\n",
      "     |      \n",
      "     |              In ranking task, one weight is assigned to each query group (not each\n",
      "     |              data point). This is because we only care about the relative ordering of\n",
      "     |              data points within each group, so it doesn't make sense to assign\n",
      "     |              weights to individual data points.\n",
      "     |      base_margin_eval_set :\n",
      "     |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      "     |          object storing base margin for the i-th validation set.\n",
      "     |      feature_weights :\n",
      "     |          Weight for each feature, defines the probability of each feature being\n",
      "     |          selected when colsample is being used.  All values must be greater than 0,\n",
      "     |          otherwise a `ValueError` is thrown.\n",
      "     |  \n",
      "     |  predict(self, X: Any, output_margin: bool = False, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> Any\n",
      "     |      Predict with `X`.  If the model is trained with early stopping, then\n",
      "     |      :py:attr:`best_iteration` is used automatically. The estimator uses\n",
      "     |      `inplace_predict` by default and falls back to using :py:class:`DMatrix` if\n",
      "     |      devices between the data and the estimator don't match.\n",
      "     |      \n",
      "     |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Data to predict with.\n",
      "     |      output_margin :\n",
      "     |          Whether to output the raw untransformed margin value.\n",
      "     |      validate_features :\n",
      "     |          When this is True, validate that the Booster's and data's feature_names are\n",
      "     |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      iteration_range :\n",
      "     |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      "     |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      "     |          20)``, then only the forests built during [10, 20) (half open set) rounds\n",
      "     |          are used in this prediction.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction\n",
      "     |  \n",
      "     |  score(self, X: Any, y: Any) -> float\n",
      "     |      Evaluate score for data using the last evaluation metric. If the model is\n",
      "     |      trained with early stopping, then :py:attr:`best_iteration` is used\n",
      "     |      automatically.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : Union[pd.DataFrame, cudf.DataFrame]\n",
      "     |        Feature matrix. A DataFrame with a special `qid` column.\n",
      "     |      \n",
      "     |      y :\n",
      "     |        Labels\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score :\n",
      "     |        The result of the first evaluation metric for the ranker.\n",
      "     |  \n",
      "     |  set_fit_request(self: xgboost.sklearn.XGBRanker, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', base_margin_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', eval_group: Union[bool, NoneType, str] = '$UNCHANGED$', eval_qid: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_weights: Union[bool, NoneType, str] = '$UNCHANGED$', group: Union[bool, NoneType, str] = '$UNCHANGED$', qid: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', verbose: Union[bool, NoneType, str] = '$UNCHANGED$', xgb_model: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRanker\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      base_margin_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      eval_group : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``eval_group`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      eval_qid : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``eval_qid`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      feature_weights : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``feature_weights`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      group : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``group`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      qid : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``qid`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      verbose : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``verbose`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      xgb_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``xgb_model`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_predict_request(self: xgboost.sklearn.XGBRanker, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$', output_margin: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRanker\n",
      "     |      Request metadata passed to the ``predict`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``iteration_range`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      output_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``output_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from XGBModel:\n",
      "     |  \n",
      "     |  __sklearn_is_fitted__(self) -> bool\n",
      "     |  \n",
      "     |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      "     |      Return the evaluation results.\n",
      "     |      \n",
      "     |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      "     |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      "     |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      "     |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      "     |      function.\n",
      "     |      \n",
      "     |      The returned evaluation result is a dictionary:\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      "     |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      evals_result\n",
      "     |  \n",
      "     |  get_booster(self) -> xgboost.core.Booster\n",
      "     |      Get the underlying xgboost Booster of this model.\n",
      "     |      \n",
      "     |      This will raise an exception when fit was not called\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      booster : a xgboost booster of underlying model\n",
      "     |  \n",
      "     |  get_num_boosting_rounds(self) -> int\n",
      "     |      Gets the number of xgboost boosting rounds.\n",
      "     |  \n",
      "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      "     |      Get parameters.\n",
      "     |  \n",
      "     |  get_xgb_params(self) -> Dict[str, Any]\n",
      "     |      Get xgboost specific parameters.\n",
      "     |  \n",
      "     |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      "     |      Load the model from a file or a bytearray.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.load_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.load_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Input file name or memory buffer(see also save_raw)\n",
      "     |  \n",
      "     |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.save_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.save_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Output file name\n",
      "     |  \n",
      "     |  set_params(self, **params: Any) -> 'XGBModel'\n",
      "     |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      "     |      allow unknown kwargs. This allows using the full range of xgboost\n",
      "     |      parameters that are not defined as member variables in sklearn grid\n",
      "     |      search.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from XGBModel:\n",
      "     |  \n",
      "     |  best_iteration\n",
      "     |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      "     |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      "     |  \n",
      "     |  best_score\n",
      "     |      The best score obtained by early stopping.\n",
      "     |  \n",
      "     |  coef_\n",
      "     |      Coefficients property\n",
      "     |      \n",
      "     |      .. note:: Coefficients are defined only for linear learners\n",
      "     |      \n",
      "     |          Coefficients are only defined when the linear model is chosen as\n",
      "     |          base learner (`booster=gblinear`). It is not defined for other base\n",
      "     |          learner types, such as tree learners (`booster=gbtree`).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Feature importances property, return depends on `importance_type`\n",
      "     |      parameter. When model trained with multi-class/multi-label/multi-target dataset,\n",
      "     |      the feature importance is \"averaged\" over all targets. The \"average\" is defined\n",
      "     |      based on the importance type. For instance, if the importance type is\n",
      "     |      \"total_gain\", then the score is sum of loss change for each split from all\n",
      "     |      trees.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      "     |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      "     |  \n",
      "     |  feature_names_in_\n",
      "     |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has\n",
      "     |      feature names that are all strings.\n",
      "     |  \n",
      "     |  intercept_\n",
      "     |      Intercept (bias) property\n",
      "     |      \n",
      "     |      For tree-based model, the returned value is the `base_score`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |      Number of features seen during :py:meth:`fit`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "    \n",
      "    class XGBRegressor(XGBModel, sklearn.base.RegressorMixin)\n",
      "     |  XGBRegressor(*, objective: Union[str, xgboost.sklearn._SklObjWProto, Callable[[Any, Any], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'reg:squarederror', **kwargs: Any) -> None\n",
      "     |  \n",
      "     |  Implementation of the scikit-learn API for XGBoost regression.\n",
      "     |  See :doc:`/python/sklearn_estimator` for more information.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  \n",
      "     |      n_estimators : typing.Optional[int]\n",
      "     |          Number of gradient boosted trees.  Equivalent to number of boosting\n",
      "     |          rounds.\n",
      "     |  \n",
      "     |      max_depth :  typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum tree depth for base learners.\n",
      "     |  \n",
      "     |      max_leaves : typing.Optional[int]\n",
      "     |  \n",
      "     |          Maximum number of leaves; 0 indicates no limit.\n",
      "     |  \n",
      "     |      max_bin : typing.Optional[int]\n",
      "     |  \n",
      "     |          If using histogram-based algorithm, maximum number of bins per feature\n",
      "     |  \n",
      "     |      grow_policy : typing.Optional[str]\n",
      "     |  \n",
      "     |          Tree growing policy.\n",
      "     |  \n",
      "     |          - depthwise: Favors splitting at nodes closest to the node,\n",
      "     |          - lossguide: Favors splitting at nodes with highest loss change.\n",
      "     |  \n",
      "     |      learning_rate : typing.Optional[float]\n",
      "     |  \n",
      "     |          Boosting learning rate (xgb's \"eta\")\n",
      "     |  \n",
      "     |      verbosity : typing.Optional[int]\n",
      "     |  \n",
      "     |          The degree of verbosity. Valid values are 0 (silent) - 3 (debug).\n",
      "     |  \n",
      "     |      objective : typing.Union[str, xgboost.sklearn._SklObjWProto, typing.Callable[[typing.Any, typing.Any], typing.Tuple[numpy.ndarray, numpy.ndarray]], NoneType]\n",
      "     |  \n",
      "     |          Specify the learning task and the corresponding learning objective or a custom\n",
      "     |          objective function to be used.\n",
      "     |  \n",
      "     |          For custom objective, see :doc:`/tutorials/custom_metric_obj` and\n",
      "     |          :ref:`custom-obj-metric` for more information, along with the end note for\n",
      "     |          function signatures.\n",
      "     |  \n",
      "     |      booster: typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which booster to use: ``gbtree``, ``gblinear`` or ``dart``.\n",
      "     |  \n",
      "     |      tree_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Specify which tree method to use.  Default to auto.  If this parameter is set to\n",
      "     |          default, XGBoost will choose the most conservative option available.  It's\n",
      "     |          recommended to study this option from the parameters document :doc:`tree method\n",
      "     |          </treemethod>`\n",
      "     |  \n",
      "     |      n_jobs : typing.Optional[int]\n",
      "     |  \n",
      "     |          Number of parallel threads used to run xgboost.  When used with other\n",
      "     |          Scikit-Learn algorithms like grid search, you may choose which algorithm to\n",
      "     |          parallelize and balance the threads.  Creating thread contention will\n",
      "     |          significantly slow down both algorithms.\n",
      "     |  \n",
      "     |      gamma : typing.Optional[float]\n",
      "     |  \n",
      "     |          (min_split_loss) Minimum loss reduction required to make a further partition on\n",
      "     |          a leaf node of the tree.\n",
      "     |  \n",
      "     |      min_child_weight : typing.Optional[float]\n",
      "     |  \n",
      "     |          Minimum sum of instance weight(hessian) needed in a child.\n",
      "     |  \n",
      "     |      max_delta_step : typing.Optional[float]\n",
      "     |  \n",
      "     |          Maximum delta step we allow each tree's weight estimation to be.\n",
      "     |  \n",
      "     |      subsample : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of the training instance.\n",
      "     |  \n",
      "     |      sampling_method : typing.Optional[str]\n",
      "     |  \n",
      "     |          Sampling method. Used only by the GPU version of ``hist`` tree method.\n",
      "     |  \n",
      "     |          - ``uniform``: Select random training instances uniformly.\n",
      "     |          - ``gradient_based``: Select random training instances with higher probability\n",
      "     |              when the gradient and hessian are larger. (cf. CatBoost)\n",
      "     |  \n",
      "     |      colsample_bytree : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns when constructing each tree.\n",
      "     |  \n",
      "     |      colsample_bylevel : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each level.\n",
      "     |  \n",
      "     |      colsample_bynode : typing.Optional[float]\n",
      "     |  \n",
      "     |          Subsample ratio of columns for each split.\n",
      "     |  \n",
      "     |      reg_alpha : typing.Optional[float]\n",
      "     |  \n",
      "     |          L1 regularization term on weights (xgb's alpha).\n",
      "     |  \n",
      "     |      reg_lambda : typing.Optional[float]\n",
      "     |  \n",
      "     |          L2 regularization term on weights (xgb's lambda).\n",
      "     |  \n",
      "     |      scale_pos_weight : typing.Optional[float]\n",
      "     |          Balancing of positive and negative weights.\n",
      "     |  \n",
      "     |      base_score : typing.Optional[float]\n",
      "     |  \n",
      "     |          The initial prediction score of all instances, global bias.\n",
      "     |  \n",
      "     |      random_state : typing.Union[numpy.random.mtrand.RandomState, numpy.random._generator.Generator, int, NoneType]\n",
      "     |  \n",
      "     |          Random number seed.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             Using gblinear booster with shotgun updater is nondeterministic as\n",
      "     |             it uses Hogwild algorithm.\n",
      "     |  \n",
      "     |      missing : float\n",
      "     |  \n",
      "     |          Value in the data which needs to be present as a missing value. Default to\n",
      "     |          :py:data:`numpy.nan`.\n",
      "     |  \n",
      "     |      num_parallel_tree: typing.Optional[int]\n",
      "     |  \n",
      "     |          Used for boosting random forest.\n",
      "     |  \n",
      "     |      monotone_constraints : typing.Union[typing.Dict[str, int], str, NoneType]\n",
      "     |  \n",
      "     |          Constraint of variable monotonicity.  See :doc:`tutorial </tutorials/monotonic>`\n",
      "     |          for more information.\n",
      "     |  \n",
      "     |      interaction_constraints : typing.Union[str, typing.List[typing.Tuple[str]], NoneType]\n",
      "     |  \n",
      "     |          Constraints for interaction representing permitted interactions.  The\n",
      "     |          constraints must be specified in the form of a nested list, e.g. ``[[0, 1], [2,\n",
      "     |          3, 4]]``, where each inner list is a group of indices of features that are\n",
      "     |          allowed to interact with each other.  See :doc:`tutorial\n",
      "     |          </tutorials/feature_interaction_constraint>` for more information\n",
      "     |  \n",
      "     |      importance_type: typing.Optional[str]\n",
      "     |  \n",
      "     |          The feature importance type for the feature_importances\\_ property:\n",
      "     |  \n",
      "     |          * For tree model, it's either \"gain\", \"weight\", \"cover\", \"total_gain\" or\n",
      "     |            \"total_cover\".\n",
      "     |          * For linear model, only \"weight\" is defined and it's the normalized\n",
      "     |            coefficients without bias.\n",
      "     |  \n",
      "     |      device : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          Device ordinal, available options are `cpu`, `cuda`, and `gpu`.\n",
      "     |  \n",
      "     |      validate_parameters : typing.Optional[bool]\n",
      "     |  \n",
      "     |          Give warnings for unknown parameter.\n",
      "     |  \n",
      "     |      enable_categorical : bool\n",
      "     |  \n",
      "     |          See the same parameter of :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      feature_types : typing.Optional[typing.Sequence[str]]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          Used for specifying feature types without constructing a dataframe. See\n",
      "     |          :py:class:`DMatrix` for details.\n",
      "     |  \n",
      "     |      max_cat_to_onehot : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          A threshold for deciding whether XGBoost should use one-hot encoding based split\n",
      "     |          for categorical data.  When number of categories is lesser than the threshold\n",
      "     |          then one-hot encoding is chosen, otherwise the categories will be partitioned\n",
      "     |          into children nodes. Also, `enable_categorical` needs to be set to have\n",
      "     |          categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      max_cat_threshold : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.7.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is experimental\n",
      "     |  \n",
      "     |          Maximum number of categories considered for each split. Used only by\n",
      "     |          partition-based splits for preventing over-fitting. Also, `enable_categorical`\n",
      "     |          needs to be set to have categorical feature support. See :doc:`Categorical Data\n",
      "     |          </tutorials/categorical>` and :ref:`cat-param` for details.\n",
      "     |  \n",
      "     |      multi_strategy : typing.Optional[str]\n",
      "     |  \n",
      "     |          .. versionadded:: 2.0.0\n",
      "     |  \n",
      "     |          .. note:: This parameter is working-in-progress.\n",
      "     |  \n",
      "     |          The strategy used for training multi-target models, including multi-target\n",
      "     |          regression and multi-class classification. See :doc:`/tutorials/multioutput` for\n",
      "     |          more information.\n",
      "     |  \n",
      "     |          - ``one_output_per_tree``: One model for each target.\n",
      "     |          - ``multi_output_tree``:  Use multi-target trees.\n",
      "     |  \n",
      "     |      eval_metric : typing.Union[str, typing.List[str], typing.Callable, NoneType]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          Metric used for monitoring the training result and early stopping.  It can be a\n",
      "     |          string or list of strings as names of predefined metric in XGBoost (See\n",
      "     |          doc/parameter.rst), one of the metrics in :py:mod:`sklearn.metrics`, or any\n",
      "     |          other user defined metric that looks like `sklearn.metrics`.\n",
      "     |  \n",
      "     |          If custom objective is also provided, then custom metric should implement the\n",
      "     |          corresponding reverse link function.\n",
      "     |  \n",
      "     |          Unlike the `scoring` parameter commonly used in scikit-learn, when a callable\n",
      "     |          object is provided, it's assumed to be a cost function and by default XGBoost\n",
      "     |          will minimize the result during early stopping.\n",
      "     |  \n",
      "     |          For advanced usage on Early stopping like directly choosing to maximize instead\n",
      "     |          of minimize, see :py:obj:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          See :doc:`/tutorials/custom_metric_obj` and :ref:`custom-obj-metric` for more\n",
      "     |          information.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              from sklearn.datasets import load_diabetes\n",
      "     |              from sklearn.metrics import mean_absolute_error\n",
      "     |              X, y = load_diabetes(return_X_y=True)\n",
      "     |              reg = xgb.XGBRegressor(\n",
      "     |                  tree_method=\"hist\",\n",
      "     |                  eval_metric=mean_absolute_error,\n",
      "     |              )\n",
      "     |              reg.fit(X, y, eval_set=[(X, y)])\n",
      "     |  \n",
      "     |      early_stopping_rounds : typing.Optional[int]\n",
      "     |  \n",
      "     |          .. versionadded:: 1.6.0\n",
      "     |  \n",
      "     |          - Activates early stopping. Validation metric needs to improve at least once in\n",
      "     |            every **early_stopping_rounds** round(s) to continue training.  Requires at\n",
      "     |            least one item in **eval_set** in :py:meth:`fit`.\n",
      "     |  \n",
      "     |          - If early stopping occurs, the model will have two additional attributes:\n",
      "     |            :py:attr:`best_score` and :py:attr:`best_iteration`. These are used by the\n",
      "     |            :py:meth:`predict` and :py:meth:`apply` methods to determine the optimal\n",
      "     |            number of trees during inference. If users want to access the full model\n",
      "     |            (including trees built after early stopping), they can specify the\n",
      "     |            `iteration_range` in these inference methods. In addition, other utilities\n",
      "     |            like model plotting can also use the entire model.\n",
      "     |  \n",
      "     |          - If you prefer to discard the trees after `best_iteration`, consider using the\n",
      "     |            callback function :py:class:`xgboost.callback.EarlyStopping`.\n",
      "     |  \n",
      "     |          - If there's more than one item in **eval_set**, the last entry will be used for\n",
      "     |            early stopping.  If there's more than one metric in **eval_metric**, the last\n",
      "     |            metric will be used for early stopping.\n",
      "     |  \n",
      "     |      callbacks : typing.Optional[typing.List[xgboost.callback.TrainingCallback]]\n",
      "     |  \n",
      "     |          List of callback functions that are applied at end of each iteration.\n",
      "     |          It is possible to use predefined callbacks by using\n",
      "     |          :ref:`Callback API <callback_api>`.\n",
      "     |  \n",
      "     |          .. note::\n",
      "     |  \n",
      "     |             States in callback are not preserved during training, which means callback\n",
      "     |             objects can not be reused for multiple training sessions without\n",
      "     |             reinitialization or deepcopy.\n",
      "     |  \n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              for params in parameters_grid:\n",
      "     |                  # be sure to (re)initialize the callbacks before each run\n",
      "     |                  callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "     |                  reg = xgboost.XGBRegressor(**params, callbacks=callbacks)\n",
      "     |                  reg.fit(X, y)\n",
      "     |  \n",
      "     |      kwargs : typing.Optional[typing.Any]\n",
      "     |  \n",
      "     |          Keyword arguments for XGBoost Booster object.  Full documentation of parameters\n",
      "     |          can be found :doc:`here </parameter>`.\n",
      "     |          Attempting to set a parameter via the constructor args and \\*\\*kwargs\n",
      "     |          dict simultaneously will result in a TypeError.\n",
      "     |  \n",
      "     |          .. note:: \\*\\*kwargs unsupported by scikit-learn\n",
      "     |  \n",
      "     |              \\*\\*kwargs is unsupported by scikit-learn.  We do not guarantee\n",
      "     |              that parameters passed via this argument will interact properly\n",
      "     |              with scikit-learn.\n",
      "     |  \n",
      "     |          .. note::  Custom objective function\n",
      "     |  \n",
      "     |              A custom objective function can be provided for the ``objective``\n",
      "     |              parameter. In this case, it should have the signature ``objective(y_true,\n",
      "     |              y_pred) -> [grad, hess]`` or ``objective(y_true, y_pred, *, sample_weight)\n",
      "     |              -> [grad, hess]``:\n",
      "     |  \n",
      "     |              y_true: array_like of shape [n_samples]\n",
      "     |                  The target values\n",
      "     |              y_pred: array_like of shape [n_samples]\n",
      "     |                  The predicted values\n",
      "     |              sample_weight :\n",
      "     |                  Optional sample weights.\n",
      "     |  \n",
      "     |              grad: array_like of shape [n_samples]\n",
      "     |                  The value of the gradient for each sample point.\n",
      "     |              hess: array_like of shape [n_samples]\n",
      "     |                  The value of the second derivative for each sample point\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      XGBRegressor\n",
      "     |      XGBModel\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      "     |      sklearn.utils._metadata_requests._MetadataRequester\n",
      "     |      sklearn.base.RegressorMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, objective: Union[str, xgboost.sklearn._SklObjWProto, Callable[[Any, Any], Tuple[numpy.ndarray, numpy.ndarray]], NoneType] = 'reg:squarederror', **kwargs: Any) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  set_fit_request(self: xgboost.sklearn.XGBRegressor, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', base_margin_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', feature_weights: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$', sample_weight_eval_set: Union[bool, NoneType, str] = '$UNCHANGED$', verbose: Union[bool, NoneType, str] = '$UNCHANGED$', xgb_model: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRegressor\n",
      "     |      Request metadata passed to the ``fit`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``fit`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``fit``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      base_margin_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      feature_weights : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``feature_weights`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      sample_weight_eval_set : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight_eval_set`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      verbose : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``verbose`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      xgb_model : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``xgb_model`` parameter in ``fit``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_predict_request(self: xgboost.sklearn.XGBRegressor, *, base_margin: Union[bool, NoneType, str] = '$UNCHANGED$', iteration_range: Union[bool, NoneType, str] = '$UNCHANGED$', output_margin: Union[bool, NoneType, str] = '$UNCHANGED$', validate_features: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRegressor\n",
      "     |      Request metadata passed to the ``predict`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``predict`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``predict``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      base_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``base_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      iteration_range : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``iteration_range`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      output_margin : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``output_margin`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      validate_features : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``validate_features`` parameter in ``predict``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  set_score_request(self: xgboost.sklearn.XGBRegressor, *, sample_weight: Union[bool, NoneType, str] = '$UNCHANGED$') -> xgboost.sklearn.XGBRegressor\n",
      "     |      Request metadata passed to the ``score`` method.\n",
      "     |      \n",
      "     |      Note that this method is only relevant if\n",
      "     |      ``enable_metadata_routing=True`` (see :func:`sklearn.set_config`).\n",
      "     |      Please see :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      The options for each parameter are:\n",
      "     |      \n",
      "     |      - ``True``: metadata is requested, and passed to ``score`` if provided. The request is ignored if metadata is not provided.\n",
      "     |      \n",
      "     |      - ``False``: metadata is not requested and the meta-estimator will not pass it to ``score``.\n",
      "     |      \n",
      "     |      - ``None``: metadata is not requested, and the meta-estimator will raise an error if the user provides it.\n",
      "     |      \n",
      "     |      - ``str``: metadata should be passed to the meta-estimator with this given alias instead of the original name.\n",
      "     |      \n",
      "     |      The default (``sklearn.utils.metadata_routing.UNCHANGED``) retains the\n",
      "     |      existing request. This allows you to change the request for some\n",
      "     |      parameters and not others.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This method is only relevant if this estimator is used as a\n",
      "     |          sub-estimator of a meta-estimator, e.g. used inside a\n",
      "     |          :class:`~sklearn.pipeline.Pipeline`. Otherwise it has no effect.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      sample_weight : str, True, False, or None,                     default=sklearn.utils.metadata_routing.UNCHANGED\n",
      "     |          Metadata routing for ``sample_weight`` parameter in ``score``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          The updated object.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from XGBModel:\n",
      "     |  \n",
      "     |  __sklearn_is_fitted__(self) -> bool\n",
      "     |  \n",
      "     |  apply(self, X: Any, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> numpy.ndarray\n",
      "     |      Return the predicted leaf every tree for each sample. If the model is trained\n",
      "     |      with early stopping, then :py:attr:`best_iteration` is used automatically.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array_like, shape=[n_samples, n_features]\n",
      "     |          Input features matrix.\n",
      "     |      \n",
      "     |      iteration_range :\n",
      "     |          See :py:meth:`predict`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      X_leaves : array_like, shape=[n_samples, n_trees]\n",
      "     |          For each datapoint x in X and for each tree, return the index of the\n",
      "     |          leaf x ends up in. Leaves are numbered within\n",
      "     |          ``[0; 2**(self.max_depth+1))``, possibly with gaps in the numbering.\n",
      "     |  \n",
      "     |  evals_result(self) -> Dict[str, Dict[str, List[float]]]\n",
      "     |      Return the evaluation results.\n",
      "     |      \n",
      "     |      If **eval_set** is passed to the :py:meth:`fit` function, you can call\n",
      "     |      ``evals_result()`` to get evaluation results for all passed **eval_sets**.  When\n",
      "     |      **eval_metric** is also passed to the :py:meth:`fit` function, the\n",
      "     |      **evals_result** will contain the **eval_metrics** passed to the :py:meth:`fit`\n",
      "     |      function.\n",
      "     |      \n",
      "     |      The returned evaluation result is a dictionary:\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |          {'validation_0': {'logloss': ['0.604835', '0.531479']},\n",
      "     |           'validation_1': {'logloss': ['0.41965', '0.17686']}}\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      evals_result\n",
      "     |  \n",
      "     |  fit(self, X: Any, y: Any, *, sample_weight: Optional[Any] = None, base_margin: Optional[Any] = None, eval_set: Optional[Sequence[Tuple[Any, Any]]] = None, verbose: Union[bool, int, NoneType] = True, xgb_model: Union[xgboost.core.Booster, ForwardRef('XGBModel'), str, NoneType] = None, sample_weight_eval_set: Optional[Sequence[Any]] = None, base_margin_eval_set: Optional[Sequence[Any]] = None, feature_weights: Optional[Any] = None) -> 'XGBModel'\n",
      "     |      Fit gradient boosting model.\n",
      "     |      \n",
      "     |      Note that calling ``fit()`` multiple times will cause the model object to be\n",
      "     |      re-fit from scratch. To resume training from a previous checkpoint, explicitly\n",
      "     |      pass ``xgb_model`` argument.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Feature matrix. See :ref:`py-data` for a list of supported types.\n",
      "     |      \n",
      "     |          When the ``tree_method`` is set to ``hist``, internally, the\n",
      "     |          :py:class:`QuantileDMatrix` will be used instead of the :py:class:`DMatrix`\n",
      "     |          for conserving memory. However, this has performance implications when the\n",
      "     |          device of input data is not matched with algorithm. For instance, if the\n",
      "     |          input is a numpy array on CPU but ``cuda`` is used for training, then the\n",
      "     |          data is first processed on CPU then transferred to GPU.\n",
      "     |      y :\n",
      "     |          Labels\n",
      "     |      sample_weight :\n",
      "     |          instance weights\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      eval_set :\n",
      "     |          A list of (X, y) tuple pairs to use as validation sets, for which\n",
      "     |          metrics will be computed.\n",
      "     |          Validation metrics will help us track the performance of the model.\n",
      "     |      \n",
      "     |      verbose :\n",
      "     |          If `verbose` is True and an evaluation set is used, the evaluation metric\n",
      "     |          measured on the validation set is printed to stdout at each boosting stage.\n",
      "     |          If `verbose` is an integer, the evaluation metric is printed at each\n",
      "     |          `verbose` boosting stage. The last boosting stage / the boosting stage found\n",
      "     |          by using `early_stopping_rounds` is also printed.\n",
      "     |      xgb_model :\n",
      "     |          file name of stored XGBoost model or 'Booster' instance XGBoost model to be\n",
      "     |          loaded before training (allows training continuation).\n",
      "     |      sample_weight_eval_set :\n",
      "     |          A list of the form [L_1, L_2, ..., L_n], where each L_i is an array like\n",
      "     |          object storing instance weights for the i-th validation set.\n",
      "     |      base_margin_eval_set :\n",
      "     |          A list of the form [M_1, M_2, ..., M_n], where each M_i is an array like\n",
      "     |          object storing base margin for the i-th validation set.\n",
      "     |      feature_weights :\n",
      "     |          Weight for each feature, defines the probability of each feature being\n",
      "     |          selected when colsample is being used.  All values must be greater than 0,\n",
      "     |          otherwise a `ValueError` is thrown.\n",
      "     |  \n",
      "     |  get_booster(self) -> xgboost.core.Booster\n",
      "     |      Get the underlying xgboost Booster of this model.\n",
      "     |      \n",
      "     |      This will raise an exception when fit was not called\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      booster : a xgboost booster of underlying model\n",
      "     |  \n",
      "     |  get_num_boosting_rounds(self) -> int\n",
      "     |      Gets the number of xgboost boosting rounds.\n",
      "     |  \n",
      "     |  get_params(self, deep: bool = True) -> Dict[str, Any]\n",
      "     |      Get parameters.\n",
      "     |  \n",
      "     |  get_xgb_params(self) -> Dict[str, Any]\n",
      "     |      Get xgboost specific parameters.\n",
      "     |  \n",
      "     |  load_model(self, fname: Union[str, bytearray, os.PathLike]) -> None\n",
      "     |      Load the model from a file or a bytearray.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.load_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.load_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Input file name or memory buffer(see also save_raw)\n",
      "     |  \n",
      "     |  predict(self, X: Any, output_margin: bool = False, validate_features: bool = True, base_margin: Optional[Any] = None, iteration_range: Optional[Tuple[Union[int, numpy.integer], Union[int, numpy.integer]]] = None) -> Any\n",
      "     |      Predict with `X`.  If the model is trained with early stopping, then\n",
      "     |      :py:attr:`best_iteration` is used automatically. The estimator uses\n",
      "     |      `inplace_predict` by default and falls back to using :py:class:`DMatrix` if\n",
      "     |      devices between the data and the estimator don't match.\n",
      "     |      \n",
      "     |      .. note:: This function is only thread safe for `gbtree` and `dart`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X :\n",
      "     |          Data to predict with.\n",
      "     |      output_margin :\n",
      "     |          Whether to output the raw untransformed margin value.\n",
      "     |      validate_features :\n",
      "     |          When this is True, validate that the Booster's and data's feature_names are\n",
      "     |          identical.  Otherwise, it is assumed that the feature_names are the same.\n",
      "     |      base_margin :\n",
      "     |          Global bias for each instance. See :doc:`/tutorials/intercept` for details.\n",
      "     |      iteration_range :\n",
      "     |          Specifies which layer of trees are used in prediction.  For example, if a\n",
      "     |          random forest is trained with 100 rounds.  Specifying ``iteration_range=(10,\n",
      "     |          20)``, then only the forests built during [10, 20) (half open set) rounds\n",
      "     |          are used in this prediction.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.4.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      prediction\n",
      "     |  \n",
      "     |  save_model(self, fname: Union[str, os.PathLike]) -> None\n",
      "     |      Save the model to a file.\n",
      "     |      \n",
      "     |      The model is saved in an XGBoost internal format which is universal among the\n",
      "     |      various XGBoost interfaces. Auxiliary attributes of the Python Booster object\n",
      "     |      (such as feature_names) are only saved when using JSON or UBJSON (default)\n",
      "     |      format. See :doc:`Model IO </tutorials/saving_model>` for more info.\n",
      "     |      \n",
      "     |      .. code-block:: python\n",
      "     |      \n",
      "     |        model.save_model(\"model.json\")\n",
      "     |        # or\n",
      "     |        model.save_model(\"model.ubj\")\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      fname :\n",
      "     |          Output file name\n",
      "     |  \n",
      "     |  set_params(self, **params: Any) -> 'XGBModel'\n",
      "     |      Set the parameters of this estimator.  Modification of the sklearn method to\n",
      "     |      allow unknown kwargs. This allows using the full range of xgboost\n",
      "     |      parameters that are not defined as member variables in sklearn grid\n",
      "     |      search.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from XGBModel:\n",
      "     |  \n",
      "     |  best_iteration\n",
      "     |      The best iteration obtained by early stopping.  This attribute is 0-based,\n",
      "     |      for instance if the best iteration is the first round, then best_iteration is 0.\n",
      "     |  \n",
      "     |  best_score\n",
      "     |      The best score obtained by early stopping.\n",
      "     |  \n",
      "     |  coef_\n",
      "     |      Coefficients property\n",
      "     |      \n",
      "     |      .. note:: Coefficients are defined only for linear learners\n",
      "     |      \n",
      "     |          Coefficients are only defined when the linear model is chosen as\n",
      "     |          base learner (`booster=gblinear`). It is not defined for other base\n",
      "     |          learner types, such as tree learners (`booster=gbtree`).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      coef_ : array of shape ``[n_features]`` or ``[n_classes, n_features]``\n",
      "     |  \n",
      "     |  feature_importances_\n",
      "     |      Feature importances property, return depends on `importance_type`\n",
      "     |      parameter. When model trained with multi-class/multi-label/multi-target dataset,\n",
      "     |      the feature importance is \"averaged\" over all targets. The \"average\" is defined\n",
      "     |      based on the importance type. For instance, if the importance type is\n",
      "     |      \"total_gain\", then the score is sum of loss change for each split from all\n",
      "     |      trees.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      feature_importances_ : array of shape ``[n_features]`` except for multi-class\n",
      "     |      linear model, which returns an array with shape `(n_features, n_classes)`\n",
      "     |  \n",
      "     |  feature_names_in_\n",
      "     |      Names of features seen during :py:meth:`fit`.  Defined only when `X` has\n",
      "     |      feature names that are all strings.\n",
      "     |  \n",
      "     |  intercept_\n",
      "     |      Intercept (bias) property\n",
      "     |      \n",
      "     |      For tree-based model, the returned value is the `base_score`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      intercept_ : array of shape ``(1,)`` or ``[n_classes]``\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |      Number of features seen during :py:meth:`fit`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  __sklearn_clone__(self)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  get_metadata_routing(self)\n",
      "     |      Get metadata routing of this object.\n",
      "     |      \n",
      "     |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      "     |      mechanism works.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      routing : MetadataRequest\n",
      "     |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      "     |          routing information.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      "     |  \n",
      "     |  __init_subclass__(**kwargs) from builtins.type\n",
      "     |      Set the ``set_{method}_request`` methods.\n",
      "     |      \n",
      "     |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      "     |      looks for the information available in the set default values which are\n",
      "     |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      "     |      from method signatures.\n",
      "     |      \n",
      "     |      The ``__metadata_request__*`` class attributes are used when a method\n",
      "     |      does not explicitly accept a metadata through its arguments or if the\n",
      "     |      developer would like to specify a request value for those metadata\n",
      "     |      which are different from the default ``None``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.RegressorMixin:\n",
      "     |  \n",
      "     |  score(self, X, y, sample_weight=None)\n",
      "     |      Return the coefficient of determination of the prediction.\n",
      "     |      \n",
      "     |      The coefficient of determination :math:`R^2` is defined as\n",
      "     |      :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual\n",
      "     |      sum of squares ``((y_true - y_pred)** 2).sum()`` and :math:`v`\n",
      "     |      is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``.\n",
      "     |      The best possible score is 1.0 and it can be negative (because the\n",
      "     |      model can be arbitrarily worse). A constant model that always predicts\n",
      "     |      the expected value of `y`, disregarding the input features, would get\n",
      "     |      a :math:`R^2` score of 0.0.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Test samples. For some estimators this may be a precomputed\n",
      "     |          kernel matrix or a list of generic objects instead with shape\n",
      "     |          ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``\n",
      "     |          is the number of samples used in the fitting for the estimator.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "     |          True values for `X`.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |          :math:`R^2` of ``self.predict(X)`` w.r.t. `y`.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The :math:`R^2` score used when calling ``score`` on a regressor uses\n",
      "     |      ``multioutput='uniform_average'`` from version 0.23 to keep consistent\n",
      "     |      with default value of :func:`~sklearn.metrics.r2_score`.\n",
      "     |      This influences the ``score`` method of all the multioutput\n",
      "     |      regressors (except for\n",
      "     |      :class:`~sklearn.multioutput.MultiOutputRegressor`).\n",
      "\n",
      "FUNCTIONS\n",
      "    build_info() -> dict\n",
      "        Build information of XGBoost.  The returned value format is not stable. Also,\n",
      "        please note that build time dependency is not the same as runtime dependency. For\n",
      "        instance, it's possible to build XGBoost with older CUDA version but run it with the\n",
      "        lastest one.\n",
      "        \n",
      "          .. versionadded:: 1.6.0\n",
      "    \n",
      "    config_context(**new_config: Any) -> Iterator[NoneType]\n",
      "        Context manager for global XGBoost configuration.\n",
      "        \n",
      "        \n",
      "        Global configuration consists of a collection of parameters that can be applied in the\n",
      "        global scope. See :ref:`global_config` for the full list of parameters supported in\n",
      "        the global configuration.\n",
      "        \n",
      "        \n",
      "        .. note::\n",
      "        \n",
      "            All settings, not just those presently modified, will be returned to their\n",
      "            previous values when the context manager is exited. This is not thread-safe.\n",
      "                \n",
      "        \n",
      "        .. versionadded:: 1.4.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        new_config: Dict[str, Any]\n",
      "            Keyword arguments representing the parameters and their values\n",
      "                \n",
      "        Example\n",
      "        -------\n",
      "        \n",
      "        .. code-block:: python\n",
      "        \n",
      "            import xgboost as xgb\n",
      "        \n",
      "            # Show all messages, including ones pertaining to debugging\n",
      "            xgb.set_config(verbosity=2)\n",
      "        \n",
      "            # Get current value of global configuration\n",
      "            # This is a dict containing all parameters in the global configuration,\n",
      "            # including 'verbosity'\n",
      "            config = xgb.get_config()\n",
      "            assert config['verbosity'] == 2\n",
      "        \n",
      "            # Example of using the context manager xgb.config_context().\n",
      "            # The context manager will restore the previous value of the global\n",
      "            # configuration upon exiting.\n",
      "            with xgb.config_context(verbosity=0):\n",
      "                # Suppress warning caused by model generated with XGBoost version < 1.0.0\n",
      "                bst = xgb.Booster(model_file='./old_model.bin')\n",
      "            assert xgb.get_config()['verbosity'] == 2  # old value restored\n",
      "        \n",
      "        Nested configuration context is also supported:\n",
      "        \n",
      "        Example\n",
      "        -------\n",
      "        \n",
      "        .. code-block:: python\n",
      "        \n",
      "            with xgb.config_context(verbosity=3):\n",
      "                assert xgb.get_config()[\"verbosity\"] == 3\n",
      "                with xgb.config_context(verbosity=2):\n",
      "                    assert xgb.get_config()[\"verbosity\"] == 2\n",
      "        \n",
      "            xgb.set_config(verbosity=2)\n",
      "            assert xgb.get_config()[\"verbosity\"] == 2\n",
      "            with xgb.config_context(verbosity=3):\n",
      "                assert xgb.get_config()[\"verbosity\"] == 3\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        set_config: Set global XGBoost configuration\n",
      "        get_config: Get current values of the global configuration\n",
      "    \n",
      "    cv(params: Union[List, Dict[str, Any]], dtrain: xgboost.core.DMatrix, num_boost_round: int = 10, nfold: int = 3, stratified: bool = False, folds: sklearn.model_selection._split.StratifiedKFold = None, metrics: Sequence[str] = (), obj: Optional[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[numpy.ndarray, numpy.ndarray]]] = None, feval: Optional[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]]] = None, maximize: Optional[bool] = None, early_stopping_rounds: Optional[int] = None, fpreproc: Optional[Callable] = None, as_pandas: bool = True, verbose_eval: Union[bool, int, NoneType] = None, show_stdv: bool = True, seed: int = 0, callbacks: Optional[Sequence[xgboost.callback.TrainingCallback]] = None, shuffle: bool = True, custom_metric: Optional[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]]] = None) -> Union[Dict[str, float], pandas.core.frame.DataFrame]\n",
      "        Cross-validation with given parameters.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        params : dict\n",
      "            Booster params.\n",
      "        dtrain : DMatrix\n",
      "            Data to be trained.\n",
      "        num_boost_round : int\n",
      "            Number of boosting iterations.\n",
      "        nfold : int\n",
      "            Number of folds in CV.\n",
      "        stratified : bool\n",
      "            Perform stratified sampling.\n",
      "        folds : a KFold or StratifiedKFold instance or list of fold indices\n",
      "            Sklearn KFolds or StratifiedKFolds object.\n",
      "            Alternatively may explicitly pass sample indices for each fold.\n",
      "            For ``n`` folds, **folds** should be a length ``n`` list of tuples.\n",
      "            Each tuple is ``(in,out)`` where ``in`` is a list of indices to be used\n",
      "            as the training samples for the ``n`` th fold and ``out`` is a list of\n",
      "            indices to be used as the testing samples for the ``n`` th fold.\n",
      "        metrics : string or list of strings\n",
      "            Evaluation metrics to be watched in CV.\n",
      "        obj :\n",
      "        \n",
      "            Custom objective function.  See :doc:`Custom Objective\n",
      "            </tutorials/custom_metric_obj>` for details.\n",
      "        \n",
      "        feval : function\n",
      "            .. deprecated:: 1.6.0\n",
      "                Use `custom_metric` instead.\n",
      "        maximize : bool\n",
      "            Whether to maximize feval.\n",
      "        early_stopping_rounds: int\n",
      "            Activates early stopping. Cross-Validation metric (average of validation\n",
      "            metric computed over CV folds) needs to improve at least once in\n",
      "            every **early_stopping_rounds** round(s) to continue training.\n",
      "            The last entry in the evaluation history will represent the best iteration.\n",
      "            If there's more than one metric in the **eval_metric** parameter given in\n",
      "            **params**, the last metric will be used for early stopping.\n",
      "        fpreproc : function\n",
      "            Preprocessing function that takes (dtrain, dtest, param) and returns\n",
      "            transformed versions of those.\n",
      "        as_pandas : bool, default True\n",
      "            Return pd.DataFrame when pandas is installed.\n",
      "            If False or pandas is not installed, return np.ndarray\n",
      "        verbose_eval : bool, int, or None, default None\n",
      "            Whether to display the progress. If None, progress will be displayed\n",
      "            when np.ndarray is returned. If True, progress will be displayed at\n",
      "            boosting stage. If an integer is given, progress will be displayed\n",
      "            at every given `verbose_eval` boosting stage.\n",
      "        show_stdv : bool, default True\n",
      "            Whether to display the standard deviation in progress.\n",
      "            Results are not affected, and always contains std.\n",
      "        seed : int\n",
      "            Seed used to generate the folds (passed to numpy.random.seed).\n",
      "        callbacks :\n",
      "            List of callback functions that are applied at end of each iteration.\n",
      "            It is possible to use predefined callbacks by using\n",
      "            :ref:`Callback API <callback_api>`.\n",
      "        \n",
      "            .. note::\n",
      "        \n",
      "               States in callback are not preserved during training, which means callback\n",
      "               objects can not be reused for multiple training sessions without\n",
      "               reinitialization or deepcopy.\n",
      "        \n",
      "            .. code-block:: python\n",
      "        \n",
      "                for params in parameters_grid:\n",
      "                    # be sure to (re)initialize the callbacks before each run\n",
      "                    callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "                    xgboost.train(params, Xy, callbacks=callbacks)\n",
      "        \n",
      "        shuffle : bool\n",
      "            Shuffle data before creating folds.\n",
      "        custom_metric :\n",
      "        \n",
      "            .. versionadded 1.6.0\n",
      "        \n",
      "            Custom metric function.  See :doc:`Custom Metric </tutorials/custom_metric_obj>`\n",
      "            for details.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        evaluation history : list(string)\n",
      "    \n",
      "    get_config() -> Dict[str, Any]\n",
      "        Get current values of the global configuration.\n",
      "        \n",
      "        \n",
      "        Global configuration consists of a collection of parameters that can be applied in the\n",
      "        global scope. See :ref:`global_config` for the full list of parameters supported in\n",
      "        the global configuration.\n",
      "        \n",
      "        \n",
      "        \n",
      "        .. versionadded:: 1.4.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        args: Dict[str, Any]\n",
      "            The list of global parameters and their values\n",
      "                \n",
      "        Example\n",
      "        -------\n",
      "        \n",
      "        .. code-block:: python\n",
      "        \n",
      "            import xgboost as xgb\n",
      "        \n",
      "            # Show all messages, including ones pertaining to debugging\n",
      "            xgb.set_config(verbosity=2)\n",
      "        \n",
      "            # Get current value of global configuration\n",
      "            # This is a dict containing all parameters in the global configuration,\n",
      "            # including 'verbosity'\n",
      "            config = xgb.get_config()\n",
      "            assert config['verbosity'] == 2\n",
      "        \n",
      "            # Example of using the context manager xgb.config_context().\n",
      "            # The context manager will restore the previous value of the global\n",
      "            # configuration upon exiting.\n",
      "            with xgb.config_context(verbosity=0):\n",
      "                # Suppress warning caused by model generated with XGBoost version < 1.0.0\n",
      "                bst = xgb.Booster(model_file='./old_model.bin')\n",
      "            assert xgb.get_config()['verbosity'] == 2  # old value restored\n",
      "        \n",
      "        Nested configuration context is also supported:\n",
      "        \n",
      "        Example\n",
      "        -------\n",
      "        \n",
      "        .. code-block:: python\n",
      "        \n",
      "            with xgb.config_context(verbosity=3):\n",
      "                assert xgb.get_config()[\"verbosity\"] == 3\n",
      "                with xgb.config_context(verbosity=2):\n",
      "                    assert xgb.get_config()[\"verbosity\"] == 2\n",
      "        \n",
      "            xgb.set_config(verbosity=2)\n",
      "            assert xgb.get_config()[\"verbosity\"] == 2\n",
      "            with xgb.config_context(verbosity=3):\n",
      "                assert xgb.get_config()[\"verbosity\"] == 3\n",
      "    \n",
      "    plot_importance(booster: Union[xgboost.sklearn.XGBModel, xgboost.core.Booster, dict], ax: Optional[Any] = None, height: float = 0.2, xlim: Optional[tuple] = None, ylim: Optional[tuple] = None, title: str = 'Feature importance', xlabel: str = 'F score', ylabel: str = 'Features', fmap: Union[str, os.PathLike] = '', importance_type: str = 'weight', max_num_features: Optional[int] = None, grid: bool = True, show_values: bool = True, values_format: str = '{v}', **kwargs: Any) -> Any\n",
      "        Plot importance based on fitted trees.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        booster :\n",
      "            Booster or XGBModel instance, or dict taken by Booster.get_fscore()\n",
      "        ax : matplotlib Axes\n",
      "            Target axes instance. If None, new figure and axes will be created.\n",
      "        grid :\n",
      "            Turn the axes grids on or off.  Default is True (On).\n",
      "        importance_type :\n",
      "            How the importance is calculated: either \"weight\", \"gain\", or \"cover\"\n",
      "        \n",
      "            * \"weight\" is the number of times a feature appears in a tree\n",
      "            * \"gain\" is the average gain of splits which use the feature\n",
      "            * \"cover\" is the average coverage of splits which use the feature\n",
      "              where coverage is defined as the number of samples affected by the split\n",
      "        max_num_features :\n",
      "            Maximum number of top features displayed on plot. If None, all features will be\n",
      "            displayed.\n",
      "        height :\n",
      "            Bar height, passed to ax.barh()\n",
      "        xlim :\n",
      "            Tuple passed to axes.xlim()\n",
      "        ylim :\n",
      "            Tuple passed to axes.ylim()\n",
      "        title :\n",
      "            Axes title. To disable, pass None.\n",
      "        xlabel :\n",
      "            X axis title label. To disable, pass None.\n",
      "        ylabel :\n",
      "            Y axis title label. To disable, pass None.\n",
      "        fmap :\n",
      "            The name of feature map file.\n",
      "        show_values :\n",
      "            Show values on plot. To disable, pass False.\n",
      "        values_format :\n",
      "            Format string for values. \"v\" will be replaced by the value of the feature\n",
      "            importance.  e.g. Pass \"{v:.2f}\" in order to limit the number of digits after\n",
      "            the decimal point to two, for each value printed on the graph.\n",
      "        kwargs :\n",
      "            Other keywords passed to ax.barh()\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ax : matplotlib Axes\n",
      "    \n",
      "    plot_tree(booster: xgboost.core.Booster, fmap: Union[str, os.PathLike] = '', num_trees: int = 0, rankdir: Optional[str] = None, ax: Optional[Any] = None, **kwargs: Any) -> Any\n",
      "        Plot specified tree.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        booster : Booster, XGBModel\n",
      "            Booster or XGBModel instance\n",
      "        fmap: str (optional)\n",
      "           The name of feature map file\n",
      "        num_trees : int, default 0\n",
      "            Specify the ordinal number of target tree\n",
      "        rankdir : str, default \"TB\"\n",
      "            Passed to graphviz via graph_attr\n",
      "        ax : matplotlib Axes, default None\n",
      "            Target axes instance. If None, new figure and axes will be created.\n",
      "        kwargs :\n",
      "            Other keywords passed to to_graphviz\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ax : matplotlib Axes\n",
      "    \n",
      "    set_config(**new_config: Any) -> None\n",
      "        Set global configuration.\n",
      "        \n",
      "        \n",
      "        Global configuration consists of a collection of parameters that can be applied in the\n",
      "        global scope. See :ref:`global_config` for the full list of parameters supported in\n",
      "        the global configuration.\n",
      "        \n",
      "        \n",
      "        \n",
      "        .. versionadded:: 1.4.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        new_config: Dict[str, Any]\n",
      "            Keyword arguments representing the parameters and their values\n",
      "                \n",
      "        Example\n",
      "        -------\n",
      "        \n",
      "        .. code-block:: python\n",
      "        \n",
      "            import xgboost as xgb\n",
      "        \n",
      "            # Show all messages, including ones pertaining to debugging\n",
      "            xgb.set_config(verbosity=2)\n",
      "        \n",
      "            # Get current value of global configuration\n",
      "            # This is a dict containing all parameters in the global configuration,\n",
      "            # including 'verbosity'\n",
      "            config = xgb.get_config()\n",
      "            assert config['verbosity'] == 2\n",
      "        \n",
      "            # Example of using the context manager xgb.config_context().\n",
      "            # The context manager will restore the previous value of the global\n",
      "            # configuration upon exiting.\n",
      "            with xgb.config_context(verbosity=0):\n",
      "                # Suppress warning caused by model generated with XGBoost version < 1.0.0\n",
      "                bst = xgb.Booster(model_file='./old_model.bin')\n",
      "            assert xgb.get_config()['verbosity'] == 2  # old value restored\n",
      "        \n",
      "        Nested configuration context is also supported:\n",
      "        \n",
      "        Example\n",
      "        -------\n",
      "        \n",
      "        .. code-block:: python\n",
      "        \n",
      "            with xgb.config_context(verbosity=3):\n",
      "                assert xgb.get_config()[\"verbosity\"] == 3\n",
      "                with xgb.config_context(verbosity=2):\n",
      "                    assert xgb.get_config()[\"verbosity\"] == 2\n",
      "        \n",
      "            xgb.set_config(verbosity=2)\n",
      "            assert xgb.get_config()[\"verbosity\"] == 2\n",
      "            with xgb.config_context(verbosity=3):\n",
      "                assert xgb.get_config()[\"verbosity\"] == 3\n",
      "    \n",
      "    to_graphviz(booster: Union[xgboost.core.Booster, xgboost.sklearn.XGBModel], fmap: Union[str, os.PathLike] = '', num_trees: int = 0, rankdir: Optional[str] = None, yes_color: Optional[str] = None, no_color: Optional[str] = None, condition_node_params: Optional[dict] = None, leaf_node_params: Optional[dict] = None, **kwargs: Any) -> Any\n",
      "        Convert specified tree to graphviz instance. IPython can automatically plot\n",
      "        the returned graphviz instance. Otherwise, you should call .render() method\n",
      "        of the returned graphviz instance.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        booster :\n",
      "            Booster or XGBModel instance\n",
      "        fmap :\n",
      "           The name of feature map file\n",
      "        num_trees :\n",
      "            Specify the ordinal number of target tree\n",
      "        rankdir :\n",
      "            Passed to graphviz via graph_attr\n",
      "        yes_color :\n",
      "            Edge color when meets the node condition.\n",
      "        no_color :\n",
      "            Edge color when doesn't meet the node condition.\n",
      "        condition_node_params :\n",
      "            Condition node configuration for for graphviz.  Example:\n",
      "        \n",
      "            .. code-block:: python\n",
      "        \n",
      "                {'shape': 'box',\n",
      "                 'style': 'filled,rounded',\n",
      "                 'fillcolor': '#78bceb'}\n",
      "        \n",
      "        leaf_node_params :\n",
      "            Leaf node configuration for graphviz. Example:\n",
      "        \n",
      "            .. code-block:: python\n",
      "        \n",
      "                {'shape': 'box',\n",
      "                 'style': 'filled',\n",
      "                 'fillcolor': '#e48038'}\n",
      "        \n",
      "        kwargs :\n",
      "            Other keywords passed to graphviz graph_attr, e.g. ``graph [ {key} = {value} ]``\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        graph: graphviz.Source\n",
      "    \n",
      "    train(params: Dict[str, Any], dtrain: xgboost.core.DMatrix, num_boost_round: int = 10, *, evals: Optional[Sequence[Tuple[xgboost.core.DMatrix, str]]] = None, obj: Optional[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[numpy.ndarray, numpy.ndarray]]] = None, feval: Optional[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]]] = None, maximize: Optional[bool] = None, early_stopping_rounds: Optional[int] = None, evals_result: Optional[Dict[str, Dict[str, Union[List[float], List[Tuple[float, float]]]]]] = None, verbose_eval: Union[bool, int, NoneType] = True, xgb_model: Union[str, os.PathLike, xgboost.core.Booster, bytearray, NoneType] = None, callbacks: Optional[Sequence[xgboost.callback.TrainingCallback]] = None, custom_metric: Optional[Callable[[numpy.ndarray, xgboost.core.DMatrix], Tuple[str, float]]] = None) -> xgboost.core.Booster\n",
      "        Train a booster with given parameters.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        params :\n",
      "            Booster params.\n",
      "        dtrain :\n",
      "            Data to be trained.\n",
      "        num_boost_round :\n",
      "            Number of boosting iterations.\n",
      "        evals :\n",
      "            List of validation sets for which metrics will evaluated during training.\n",
      "            Validation metrics will help us track the performance of the model.\n",
      "        obj\n",
      "            Custom objective function.  See :doc:`Custom Objective\n",
      "            </tutorials/custom_metric_obj>` for details.\n",
      "        feval :\n",
      "            .. deprecated:: 1.6.0\n",
      "                Use `custom_metric` instead.\n",
      "        maximize :\n",
      "            Whether to maximize feval.\n",
      "        early_stopping_rounds :\n",
      "            Activates early stopping. Validation metric needs to improve at least once in\n",
      "            every **early_stopping_rounds** round(s) to continue training.\n",
      "            Requires at least one item in **evals**.\n",
      "            The method returns the model from the last iteration (not the best one).  Use\n",
      "            custom callback or model slicing if the best model is desired.\n",
      "            If there's more than one item in **evals**, the last entry will be used for early\n",
      "            stopping.\n",
      "            If there's more than one metric in the **eval_metric** parameter given in\n",
      "            **params**, the last metric will be used for early stopping.\n",
      "            If early stopping occurs, the model will have two additional fields:\n",
      "            ``bst.best_score``, ``bst.best_iteration``.\n",
      "        evals_result :\n",
      "            This dictionary stores the evaluation results of all the items in watchlist.\n",
      "        \n",
      "            Example: with a watchlist containing\n",
      "            ``[(dtest,'eval'), (dtrain,'train')]`` and\n",
      "            a parameter containing ``('eval_metric': 'logloss')``,\n",
      "            the **evals_result** returns\n",
      "        \n",
      "            .. code-block:: python\n",
      "        \n",
      "                {'train': {'logloss': ['0.48253', '0.35953']},\n",
      "                 'eval': {'logloss': ['0.480385', '0.357756']}}\n",
      "        \n",
      "        verbose_eval :\n",
      "            Requires at least one item in **evals**.\n",
      "            If **verbose_eval** is True then the evaluation metric on the validation set is\n",
      "            printed at each boosting stage.\n",
      "            If **verbose_eval** is an integer then the evaluation metric on the validation set\n",
      "            is printed at every given **verbose_eval** boosting stage. The last boosting stage\n",
      "            / the boosting stage found by using **early_stopping_rounds** is also printed.\n",
      "            Example: with ``verbose_eval=4`` and at least one item in **evals**, an evaluation metric\n",
      "            is printed every 4 boosting stages, instead of every boosting stage.\n",
      "        xgb_model :\n",
      "            Xgb model to be loaded before training (allows training continuation).\n",
      "        callbacks :\n",
      "            List of callback functions that are applied at end of each iteration.\n",
      "            It is possible to use predefined callbacks by using\n",
      "            :ref:`Callback API <callback_api>`.\n",
      "        \n",
      "            .. note::\n",
      "        \n",
      "               States in callback are not preserved during training, which means callback\n",
      "               objects can not be reused for multiple training sessions without\n",
      "               reinitialization or deepcopy.\n",
      "        \n",
      "            .. code-block:: python\n",
      "        \n",
      "                for params in parameters_grid:\n",
      "                    # be sure to (re)initialize the callbacks before each run\n",
      "                    callbacks = [xgb.callback.LearningRateScheduler(custom_rates)]\n",
      "                    xgboost.train(params, Xy, callbacks=callbacks)\n",
      "        \n",
      "        custom_metric:\n",
      "        \n",
      "            .. versionadded 1.6.0\n",
      "        \n",
      "            Custom metric function.  See :doc:`Custom Metric </tutorials/custom_metric_obj>`\n",
      "            for details.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Booster : a trained booster model\n",
      "\n",
      "DATA\n",
      "    __all__ = ['DMatrix', 'DeviceQuantileDMatrix', 'QuantileDMatrix', 'Boo...\n",
      "\n",
      "VERSION\n",
      "    2.1.1\n",
      "\n",
      "FILE\n",
      "    c:\\users\\saina\\onedrive\\desktop\\100dayscode\\credit risk assessment\\.venv\\lib\\site-packages\\xgboost\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note to myself: Need to apply heyper parameter tuning, looking at feature importance. \n",
    "Note to myself: Need to apply heyper parameter tuning, looking at feature importance. check for multicolinearity, cutting out un necessary features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
